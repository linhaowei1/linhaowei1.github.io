@inproceedings{zhou2025integrating,
  title={Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows},
  author={Zhou, Xiangxin and Xiao, Yi and Lin, Haowei and He, Xinheng and Guan, Jiaqi and Wang, Yang and Liu, Qiang and Zhou, Feng and Wang, Liang and Ma, Jianzhu},
  booktitle={The Thirteenth International Conference on Learning Representations (ICLR 2025)},
  year={2025},
  abbr={ICLR},
  pdf={https://arxiv.org/abs/2503.03989}
}

@article{lu2025uni,
  title={Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens},
  author={Lu*, Shuqi and Lin*, Haowei and Yao*, Lin and Gao, Zhifeng and Ji, Xiaohong and Zhang, Linfeng and Ke, Guolin},
  journal={arXiv preprint arXiv:2503.16278},
  year={2025},
  annotation={* Equal contribution},
  abbr={arXiv},
  pdf={https://arxiv.org/abs/2503.16278},
  code={https://github.com/dptech-corp/Uni-3DAR},
  website={https://uni-3dar.github.io/},
  preview={uni3dar.gif}
}

@article{ying2025neural,
  title={A Neural Symbolic Model for Space Physics},
  author={Ying*, Jie and Lin*, Haowei and Yue*, Chao and Chen, Yajie and Xiao, Chao and Shi, Quanqi and Liang, Yitao and Yau, Shing-Tung and Zhou, Yuan and Ma, Jianzhu},
  journal={arXiv preprint arXiv:2503.07994},
  year={2025},
  annotation={* Equal contribution},
  abbr={arXiv},
  pdf={https://arxiv.org/abs/2503.07994},
  code={https://github.com/Jie0618/PhysicsRegression},
  preview={phye2e.png}
}


@article{wang2024jarvis,
  title={Jarvis-1: Open-World Multi-Task Agents with Memory-Augmented Multimodal Language Models},
  author={Wang, Zihao and Cai, Shaofei and Liu, Anji and Jin, Yonggang and Hou, Jinbing and Zhang, Bowei and Lin, Haowei and He, Zhaofeng and Zheng, Zilong and Yang, Yaodong and Ma, Xiaojian and Liang, Yitao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE},
  abbr={TPAMI},
  doi={10.1109/TPAMI.2024.3382226},
  code={https://github.com/Zihao-Wang/JARVIS-1},
  pdf={https://arxiv.org/abs/2311.05997}
}

@article{wang2024rat,
  title={RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation},
  author={Wang, Zihao and Liu, Anji and Lin, Haowei and Li, Jiaqi and Ma, Xiaojian and Liang, Yitao},
  journal={arXiv preprint arXiv:2403.05313},
  year={2024},
  abbr={arXiv},
  code={https://github.com/Zihao-Wang/RAT},
  pdf={https://arxiv.org/abs/2403.05313}
}

@inproceedings{ke2022continual,
  title={Continual Training of Language Models for Few-Shot Learning},
  author={Ke, Zixuan and Lin, Haowei and Shao, Yijia and Xu, Hu and Shu, Lei and Liu, Bing},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)},
  pages={10205--10216},
  year={2022},
  abbr={EMNLP},
  pdf={https://arxiv.org/abs/2210.05549},
  code={https://github.com/UIC-Liu-Lab/CPT},
  poster={https://vincent950129.github.io/data/cpt.pdf}
}

@inproceedings{ke2022adapting,
  title={Adapting a Language Model While Preserving Its General Knowledge},
  author={Ke, Zixuan and Shao, Yijia and Lin, Haowei and Xu, Hu and Shu, Lei and Liu, Bing},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)},
  pages={570--581},
  year={2022},
  abbr={EMNLP},
  pdf={https://arxiv.org/abs/2301.08986}
}

@inproceedings{lin2025mcu,
  title={MCU: An Evaluation Framework for Open-Ended Game Agents},
  author={Zheng*, Xinyue and Lin*, Haowei and He, Kaichen and Wang, Zihao and Fu, Qiang and Fu, Haobo and Zheng, Zilong and Liang, Yitao},
  booktitle={The Forty-second International Conference on Machine Learning (ICML 2025)},
  year={2025},
  abbr={ICML Spotlight},
  annotation={* Equal contribution},
  pdf={https://arxiv.org/pdf/2310.08367},
  code={https://github.com/CraftJarvis/MCU},
  preview={mcu.png},
  abstract={The first evaluation framework for open-ended game agents, with a task generator to synthesize infinite open-ended tasks and VLM-based evaluator. },
  selected={true}
}

@inproceedings{lin2025tfg,
  title={{TFG-Flow: Training-free Guidance in Multimodal Generative Flow}},
  author={Lin*, Haowei and Li*, Shanda and Ye, Haotian and Yang, Yiming and Ermon, Stefano and Liang, Yitao and Ma, Jianzhu},
  booktitle={The Thirteenth International Conference on Learning Representations (ICLR 2025)},
  year={2025},
  abbr={ICLR},
  annotation={* Equal contribution},
  pdf={https://arxiv.org/abs/2501.14216},
  code={https://github.com/linhaowei1/TFG-Flow},
  preview={tfg-flow.png},
  abstract={Adapting training-free guidance method from continuous diffusion to multimodal flow matching (discrete + continuous).},
  selected={true}
}

@inproceedings{ye2024tfg,
  title={TFG: Unified Training-Free Guidance for Diffusion Models},
  author={Ye*, Haotian and Lin*, Haowei and Han*, Jiaqi and Xu, Minkai and Liu, Sheng and Liang, Yitao and Ma, Jianzhu and Zou, James Y and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems 37 (NeurIPS 2024)},
  pages={22370--22417},
  year={2024},
  annotation={* Equal contribution},
  abbr={NeurIPS Spotlight},
  pdf={https://arxiv.org/abs/2409.15761},
  code={https://github.com/YWolfeee/Training-Free-Guidance},
  preview={TFG.png},
  abstract={The first unified framework for training-free guidance in diffusion models and comprehensive benchmarks on image, audio, molecules.},
  selected={true}
}


@inproceedings{wang2024omnijarvis,
  title={OmniJarvis: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents},
  author={Wang, Zihao and Cai, Shaofei and Mu, Zhancun and Lin, Haowei and Zhang, Ceyao and Liu, Xuejie and Li, Qing and Liu, Anji and Ma, Xiaojian Shawn and Liang, Yitao},
  booktitle={Advances in Neural Information Processing Systems 37},
  pages={73278--73308},
  year={2024},
  abbr={NeurIPS},
  pdf={https://arxiv.org/abs/2407.00114}
}

@inproceedings{lin2024selecting,
  title={Selecting Large Language Model to Fine-tune via Rectified Scaling Law},
  author={Lin*, Haowei and Huang*, Baizhou and Ye*, Haotian and Chen, Qinyu and Wang, Zihao and Li, Sujian and Ma, Jianzhu and Wan, Xiaojun and Zou, James and Liang, Yitao},
  booktitle={The Forty-first International Conference on Machine Learning (ICML 2024)},
  year={2024},
  annotation={* Equal contribution},
  abbr={ICML},
  pdf={https://arxiv.org/pdf/2402.02314.pdf},
  website={https://rectified-scaling-law.github.io},
  preview={llm-selection.png},
  selected={true},
  abstract={The first paper to introduce the problem of LLM selection. Proposed to use scaling law for LLM selection. Rectified vanilla power law in LLM fine-tuning scaling.}
}

@inproceedings{wang2022cmg,
  title={CMG: A Class-Mixed Generation Approach to Out-of-Distribution Detection},
  author={Wang, Mengyu and Shao, Yijia and Lin, Haowei and Hu, Wenpeng and Liu, Bing},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={502--518},
  year={2022},
  organization={Springer Nature Switzerland},
  abbr={ECML},
  pdf={https://www.cs.uic.edu/~liub/publications/ECML-2022-OOD-detection.pdf}

}

@inproceedings{lin2023flats,
  title={{FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score}},
  author={Lin, Haowei and Gu, Yuntian},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)},
  year={2023},
  abbr={EMNLP},
  pdf={https://arxiv.org/abs/2310.05083},
  code={https://github.com/linhaowei1/FLatS}
}

@inproceedings{cai2024groot,
  title={{GROOT-2: Weakly Supervised Multi-Modal Instruction Following Agents}},
  author={Cai, Shaofei and Zhang, Bowei and Wang, Zihao and Lin, Haowei and Ma, Xiaojian and Liu, Anji and Liang, Yitao},
  booktitle={The Twelfth International Conference on Learning Representations (ICLR 2024)},
  year={2024},
  abbr={ICLR},
  pdf={https://arxiv.org/abs/2412.10410}

}


@article{zhang2025data,
  title={A Data-Driven Group Retrosynthesis Planning Model Inspired by Neurosymbolic Programming},
  author={Zhang, Xuefeng and Lin, Haowei and Zhang, Muhan and Zhou, Yuan and Ma, Jianzhu},
  journal={Nature Communications},
  volume={16},
  number={1},
  pages={192},
  year={2025},
  publisher={Nature Publishing Group UK},
  abbr={Nat. Commun.},
  pdf={https://www.nature.com/articles/s41467-024-55374-9},
  code={https://github.com/osu-zxf/DreamRetroer}
}

@inproceedings{ye2025efficient,
  title={Efficient and Asymptotically Unbiased Constrained Decoding for Large Language Models},
  author={Ye, Haotian and Jain, Himanshu and You, Chong and Suresh, Ananda Theertha and Lin, Haowei and Zou, James and Yu, Felix},
  booktitle={The Twenty-Eighth International Conference on Artificial Intelligence and Statistics (AISTATS 2025)},
  year={2025},
  abbr={AISTATS},
  pdf={https://arxiv.org/abs/2504.09135}
}

@article{lin2025generative,
  title={Generative Evaluation of Complex Reasoning in Large Language Models},
  author={Lin*, Haowei and Wang*, Xiangyu and Yan*, Ruilin and Huang, Baizhou and Ye, Haotian and Zhu, Jianhua and Wang, Zihao and Zou, James and Ma, Jianzhu and Liang, Yitao},
  journal={arXiv preprint arXiv:2504.02810},
  year={2025},
  abbr={arXiv},
  annotation={* Equal contribution},
  pdf={https://arxiv.org/pdf/2504.02810},
  code={https://github.com/linhaowei1/kumo},
  website={https://craftjarvis.github.io/Kumo}
}


@article{kong2025peptide,
  title={Peptide Design through Binding Interface Mimicry},
  author={Kong, Xiangzhe and Jiao, Rui and Lin, Haowei and Guo, Ruihan and Huang, Wenbing and Ma, Wei-Ying and Wang, Zihua and Liu, Yang and Ma, Jianzhu},
  journal={Nature Biomedical Engineering},
  pages={2025.01.21.634006},
  year={2025},
  publisher={Cold Spring Harbor Laboratory},
  abbr={Nat. Biomed. Eng.},
  pdf={https://www.biorxiv.org/content/10.1101/2025.01.21.634006v1},
  code={https://github.com/kxz18/PepMimic}
}


@inproceedings{lin2024class,
  title={Class Incremental Learning via Likelihood Ratio-Based Task Prediction},
  author={Lin, Haowei and Shao, Yijia and Qian, Weinan and Pan, Ningxin and Guo, Yiduo and Liu, Bing},
  booktitle={The Twelfth International Conference on Learning Representations (ICLR 2024)},
  year={2024},
  abbr={ICLR},
  pdf={https://arxiv.org/abs/2309.15048},
  code={https://github.com/linhaowei1/TPLR},
  preview={tpl.png},
  abstract={A theory-guided class incremental learning method, being state-of-the-art for more than 3 years (almost reaching performance upper bound).},
  selected={true}
}

@inproceedings{ke2023continual,
  title={Continual Pre-Training of Language Models},
  author={Ke*, Zixuan and Shao*, Yijia and Lin*, Haowei and Konishi, Tatsuya and Kim, Gyuhak and Liu, Bing},
  booktitle={The Eleventh International Conference on Learning Representations (ICLR 2023)},
  year={2023},
  abbr={ICLR},
  url={https://openreview.net/forum?id=2T8C12A3iC},
  pdf={https://openreview.net/pdf?id=m_GDIItaI3o},
  code={https://github.com/UIC-Liu-Lab/ContinualLM},
  poster={https://iclr.cc/Conferences/2023/Schedule?showEvent=10858},
  abstract={The first paper to introduce the concept of continual pre-training (CPT), with comprehensive benchmarks and a new method motivated by model sparsity.},
  annotation={* Equal contribution},
  preview={cpt.png},
  selected={true}
}