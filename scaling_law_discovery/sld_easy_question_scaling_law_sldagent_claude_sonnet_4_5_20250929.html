<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - U-shaped Scaling Law - SLDAgent + Claude Sonnet 4.5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>U-shaped Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">SLDAgent</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">Claude Sonnet 4.5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        0.729173
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.639993</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">0.488091</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        R² = 0.729173
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Robust U-shaped scaling law using logarithmic-quadratic form.
Captures double descent with better numerical stability.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    U-shaped scaling with stable log-quadratic form:
    y = a0 + a1*(x-a2)^2 + a3*log(1+a4*|x-a2|) + a5*x
    
    Parameters:
    - a0: baseline offset
    - a1: quadratic strength (creates U-shape)
    - a2: location of U minimum
    - a3: logarithmic modulation amplitude
    - a4: logarithmic scale factor
    - a5: linear trend
    
    The log term provides smooth asymmetry while remaining stable.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x = X[:, 0]
    
    params = np.atleast_2d(params)
    pred = np.zeros((len(x), params.shape[0]))
    
    for i in range(params.shape[0]):
        p = params[i]
        
        # Centered distance from minimum
        dx = x - p[2]
        
        # Quadratic U-shape
        quad = p[1] * dx**2
        
        # Logarithmic asymmetry (stable for all dx)
        log_term = p[3] * np.log1p(np.abs(p[4] * dx))
        
        # Linear trend
        linear = p[5] * x
        
        pred[:, i] = p[0] + quad + log_term + linear
    
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Robust fitting with adaptive multi-start strategy.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.atleast_2d(loss_values).T if np.asarray(loss_values).ndim == 1 else loss_values
    
    x = X[:, 0]
    x_min, x_max = np.min(x), np.max(x)
    x_range = x_max - x_min
    
    y_mean = np.mean(y, axis=0)
    y_std = np.std(y, axis=0)
    y_range = np.ptp(y, axis=0)
    
    all_params = []
    
    for t in range(y.shape[1]):
        yt = y[:, t]
        
        # Find data-driven U minimum
        min_idx = np.argmin(yt)
        x_min_loc = x[min_idx]
        
        # Tighter, data-informed bounds
        bounds = [
            (y_mean[t] - 1.5*y_std[t], y_mean[t] + 1.5*y_std[t]),  # a0
            (0, 2*y_range[t]/x_range**2),                           # a1 (&gt;0 for U)
            (x_min - 0.3, x_max + 0.3),                            # a2
            (-y_range[t], y_range[t]),                             # a3
            (0.1, 5.0),                                            # a4 (&gt;0 for stability)
            (-y_range[t]/x_range, y_range[t]/x_range)              # a5
        ]
        
        def objective(p):
            try:
                pred = scaling_law_func(X, p)
                mse = np.mean((pred - yt)**2)
                # Minimal regularization
                reg = 1e-7 * np.sum(p**2)
                return mse + reg
            except:
                return 1e10
        
        # Smart initializations based on data
        inits = [
            # Conservative: U at observed minimum
            [y_mean[t], 0.3*y_range[t]/x_range**2, x_min_loc, 0.0, 1.0, 0.0],
            # Stronger quadratic
            [y_mean[t], 0.6*y_range[t]/x_range**2, x_min_loc, 0.1*y_std[t], 1.5, 0.0],
            # With asymmetry
            [y_mean[t], 0.4*y_range[t]/x_range**2, x_min_loc, -0.15*y_std[t], 2.0, 0.02*y_range[t]/x_range],
            # Shifted minimum
            [y_mean[t], 0.35*y_range[t]/x_range**2, (x_min_loc+x_max)/2, 0.08*y_std[t], 1.2, -0.01*y_range[t]/x_range]
        ]
        
        best_p, best_loss = None, np.inf
        
        # Multi-start local optimization
        for init in inits:
            res = minimize(objective, init, method=&#x27;L-BFGS-B&#x27;, bounds=bounds,
                          options={&#x27;maxiter&#x27;: 1000, &#x27;ftol&#x27;: 1e-9})
            if res.fun &lt; best_loss:
                best_p, best_loss = res.x, res.fun
        
        # Global search only if local search struggled
        if best_loss &gt; 0.3 * y_std[t]**2:
            res_de = differential_evolution(
                objective, bounds=bounds, maxiter=70, seed=42,
                atol=1e-7, tol=1e-7, workers=1, polish=True,
                strategy=&#x27;best1bin&#x27;, init=&#x27;latinhypercube&#x27;
            )
            if res_de.fun &lt; best_loss:
                best_p, best_loss = res_de.x, res_de.fun
                
                # Final polish
                res_final = minimize(objective, best_p, method=&#x27;L-BFGS-B&#x27;,
                                   bounds=bounds, options={&#x27;maxiter&#x27;: 500, &#x27;ftol&#x27;: 1e-10})
                if res_final.success and res_final.fun &lt; best_loss:
                    best_p = res_final.x
        
        all_params.append(best_p if best_p is not None else inits[0])
    
    params_array = np.array(all_params)
    return params_array[0] if y.shape[1] == 1 else params_array
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        R² = 0.722180
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Streamlined U-shaped scaling law with proven functional form
Simplified optimization focused on stability and accuracy
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Centered quadratic with exponential correction (6 parameters):
    f(x) = a*(x-b)^2 + c*x + d + e*exp(-f*|x-b|)
    
    - a*(x-b)^2: U-shaped parabola centered at b
    - c*x: linear trend (NOT centered for flexibility)
    - d: baseline offset
    - e*exp(-f*|x-b|): localized exponential correction
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    log_flops = X[:, 0]
    
    params = np.asarray(params)
    if params.ndim == 1:
        params = params[None, :]
    
    if params.shape[1] &lt; 6:
        params = np.pad(params, ((0, 0), (0, 6 - params.shape[1])), 
                       constant_values=0)
    
    a = params[:, 0]
    b = params[:, 1]
    c = params[:, 2]
    d = params[:, 3]
    e = params[:, 4]
    f = params[:, 5]
    
    centered = log_flops[:, None] - b[None, :]
    quadratic = a[None, :] * (centered ** 2)
    linear = c[None, :] * log_flops[:, None]
    
    exp_arg = np.clip(-f[None, :] * np.abs(centered), -50, 50)
    exponential = e[None, :] * np.exp(exp_arg)
    
    pred = quadratic + linear + d[None, :] + exponential
    
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Simplified robust fitting with focused initialization
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    log_flops = X[:, 0]
    
    if y.ndim == 1:
        y2d = y[:, None]
    else:
        y2d = y
    T = y2d.shape[1]
    
    x_min, x_max = log_flops.min(), log_flops.max()
    x_range = x_max - x_min
    
    all_params = []
    
    for t in range(T):
        y_target = y2d[:, t]
        y_mean = np.mean(y_target)
        y_std = np.std(y_target)
        y_range = np.max(y_target) - np.min(y_target)
        
        min_idx = np.argmin(y_target)
        x_at_min = log_flops[min_idx]
        
        def objective(p):
            pred = scaling_law_func(X, p)
            if pred.ndim &gt; 1:
                pred = pred[:, 0]
            mse = np.mean((pred - y_target) ** 2)
            reg = 1e-7 * (p[0]**2 + p[5]**2)
            return mse + reg
        
        bounds = [
            (0.0, 2.5 * y_range / (x_range**2)),
            (x_min - 0.5, x_max + 0.5),
            (-1.5 * y_range / x_range, 1.5 * y_range / x_range),
            (y_mean - 2.5*y_std, y_mean + 2.5*y_std),
            (-1.2 * abs(y_mean), 1.2 * abs(y_mean)),
            (0.1, 3.5)
        ]
        
        # Three strategic initializations
        inits = [
            np.array([0.25 * y_range / (x_range**2), x_at_min, 0.0, 
                     y_mean, -0.6 * y_std, 1.2]),
            np.array([0.35 * y_range / (x_range**2), x_at_min, 
                     0.03 * y_range / x_range, y_mean, -0.5 * y_std, 0.9]),
            np.array([0.15 * y_range / (x_range**2), 
                     0.5 * (x_min + x_max), -0.02 * y_range / x_range, 
                     y_mean, -0.7 * y_std, 1.5])
        ]
        
        best_params = None
        best_loss = float(&#x27;inf&#x27;)
        
        # Try differential evolution first
        try:
            result_de = differential_evolution(
                objective, bounds, maxiter=180, popsize=15,
                seed=42, atol=1e-8, tol=1e-8, polish=True,
                init=&#x27;latinhypercube&#x27;, workers=1, strategy=&#x27;best1bin&#x27;
            )
            if result_de.fun &lt; best_loss:
                best_params = result_de.x
                best_loss = result_de.fun
        except:
            pass
        
        # Try local optimizations from multiple starts
        for init in inits:
            try:
                result = minimize(objective, init, method=&#x27;L-BFGS-B&#x27;,
                                bounds=bounds, 
                                options={&#x27;maxiter&#x27;: 400, &#x27;ftol&#x27;: 1e-10})
                if result.success and result.fun &lt; best_loss:
                    best_params = result.x
                    best_loss = result.fun
            except:
                continue
        
        if best_params is None:
            best_params = inits[0]
        
        all_params.append(best_params)
    
    params_array = np.array(all_params)
    return params_array[0] if T == 1 else params_array
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        R² = 0.631388
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Simplified U-shaped scaling law using proven rational function
f(x) = (a + b*x + c*x^2) / (1 + d*x + e*x^2) + f
Focus on robust optimization with minimal complexity
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution, minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Rational function: (a + b*x + c*x^2) / (1 + d*x + e*x^2) + f
    6 parameters for U-shaped double descent
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    log_flops = X[:, 0]
    
    params = np.asarray(params)
    if params.ndim == 1:
        params = params[None, :]
    
    x = log_flops[:, None]
    
    # Extract 6 parameters
    a, b, c, d, e, f = [params[:, i] for i in range(6)]
    
    # Rational function
    numerator = a + b * x + c * x**2
    denominator = 1.0 + d * x + e * x**2
    
    # Stabilize denominator
    eps = 1e-10
    denominator = np.where(np.abs(denominator) &lt; eps,
                          np.sign(denominator) * eps,
                          denominator)
    
    pred = numerator / denominator + f
    
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fit with polynomial initialization and adaptive optimization
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    log_flops = X[:, 0]
    
    y2d = y[:, None] if y.ndim == 1 else y
    T = y2d.shape[1]
    
    # Data statistics
    y_mean = np.mean(y2d, axis=0)
    y_std = np.std(y2d, axis=0)
    x_std = np.std(log_flops)
    
    def objective(params_flat):
        params = params_flat.reshape(T, 6)
        pred = scaling_law_func(X, params)
        pred = pred[:, None] if pred.ndim == 1 else pred
        
        mse = np.mean((pred - y2d) ** 2)
        # Light regularization on denominator
        reg = 1e-5 * (params[:, 3]**2 + params[:, 4]**2).sum()
        return mse + reg
    
    # Initialize via polynomial fit
    init_params = []
    bounds = []
    
    for t in range(T):
        y_task = y2d[:, t]
        
        # Fit quadratic for numerator initialization
        try:
            poly_coef = np.polyfit(log_flops, y_task, 2)
            init_c, init_b, init_a = poly_coef
        except:
            init_a, init_b, init_c = y_mean[t], 0.0, 0.0
        
        # [a, b, c, d, e, f]
        init_params.extend([init_a, init_b, init_c, 0.0, 0.0, 0.0])
        
        # Bounds
        bounds.extend([
            (y_mean[t] - 3*y_std[t], y_mean[t] + 3*y_std[t]),  # a
            (-5*y_std[t]/x_std, 5*y_std[t]/x_std),             # b
            (-2*y_std[t]/x_std**2, 2*y_std[t]/x_std**2),       # c
            (-3/x_std, 3/x_std),                                # d
            (-1/x_std**2, 1/x_std**2),                          # e
            (y_mean[t] - 2*y_std[t], y_mean[t] + 2*y_std[t])   # f
        ])
    
    init_params = np.array(init_params)
    
    # Local optimization from smart initialization
    result_local = minimize(
        objective,
        init_params,
        method=&#x27;L-BFGS-B&#x27;,
        bounds=bounds,
        options={&#x27;maxiter&#x27;: 1000, &#x27;ftol&#x27;: 1e-9}
    )
    
    # Global search if local result insufficient
    threshold = 0.05 * np.var(y2d)
    if not result_local.success or result_local.fun &gt; threshold:
        result_global = differential_evolution(
            objective,
            bounds=bounds,
            strategy=&#x27;best1bin&#x27;,
            maxiter=400,
            popsize=20,
            tol=1e-7,
            seed=42,
            workers=1
        )
        
        # Refine global result
        result_final = minimize(
            objective,
            result_global.x,
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds,
            options={&#x27;maxiter&#x27;: 1000, &#x27;ftol&#x27;: 1e-10}
        )
        
        # Choose best
        if result_final.success and result_final.fun &lt; min(result_local.fun, result_global.fun):
            params_opt = result_final.x
        elif result_global.fun &lt; result_local.fun:
            params_opt = result_global.x
        else:
            params_opt = result_local.x
    else:
        params_opt = result_local.x
    
    params_opt = params_opt.reshape(T, 6)
    
    return params_opt[0] if T == 1 else params_opt
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        R² = 0.629132
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
U-shaped scaling law using stabilized asymmetric rational function.
f(x) = (a*x^2 + b*x + c) / (1 + d*x^2 + e*x) + f
Uses mixed quadratic/linear denominator for stability and natural U-shape.
6 parameters with robust optimization.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Stabilized rational function for U-shaped pattern (6 params):
    f(x) = (a*x^2 + b*x + c) / (1 + d*x^2 + e*x) + f
    Denominator 1 + d*x^2 + e*x provides stability while allowing asymmetry.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    params = np.asarray(params)
    
    if params.ndim == 1:
        params = params[None, :]
    T, P = params.shape
    
    x = X[:, 0]  # log_flops
    
    # Extract parameters
    a, b, c, d, e, f = [params[:, i] for i in range(6)]
    
    # Numerator: quadratic polynomial captures U-shape
    numerator = (a[None, :] * x[:, None]**2 + 
                 b[None, :] * x[:, None] + 
                 c[None, :])
    
    # Denominator: 1 + d*x^2 + e*x provides stability and asymmetry
    # Always positive when d &gt; 0 and e is bounded
    denominator = 1.0 + d[None, :] * x[:, None]**2 + e[None, :] * x[:, None]
    
    # Add small epsilon for numerical safety
    denominator = np.maximum(denominator, 1e-10)
    
    pred = numerator / denominator + f[None, :]
    
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fit stabilized rational using robust multi-stage optimization.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    P = 6
    
    y2d = y[:, None] if y.ndim == 1 else y
    T = y2d.shape[1]
    
    y_mean, y_std = np.mean(y), np.std(y)
    y_range = np.max(y) - np.min(y)
    x_range = np.ptp(X[:, 0])
    
    # Analyze data for better initialization
    idx_sorted = np.argsort(X[:, 0])
    x_sorted = X[idx_sorted, 0]
    y_sorted = y[idx_sorted]
    
    # Estimate slopes
    n = len(X)
    if n &gt; 10:
        early_slope = (y_sorted[5] - y_sorted[0]) / (x_sorted[5] - x_sorted[0] + 1e-8)
        late_slope = (y_sorted[-1] - y_sorted[-6]) / (x_sorted[-1] - x_sorted[-6] + 1e-8)
    else:
        early_slope = 0
        late_slope = 0
    
    # Bounds with tighter constraints for stability
    bounds = [
        (-1.5*y_range/x_range**2, 1.5*y_range/x_range**2),  # a: quadratic num
        (-1.5*y_range/x_range, 1.5*y_range/x_range),        # b: linear num
        (y_mean-2*y_std, y_mean+2*y_std),                   # c: const num
        (0, 3/x_range**2),                                   # d: x^2 denom (positive)
        (-2/x_range, 2/x_range),                             # e: x denom
        (y_mean-y_std, y_mean+y_std)                         # f: offset
    ]
    
    def objective(flat_params):
        params = flat_params.reshape(T, P)
        pred = scaling_law_func(X, params)
        mse = np.mean((pred - y2d) ** 2)
        # Light regularization for smoothness
        reg = 1e-7 * (params[:, 0]**2 + params[:, 3]**2)
        return mse + np.sum(reg)
    
    # Smart initialization based on data
    init = np.zeros((T, P))
    init[:, 0] = 0.08 * y_range / x_range**2      # Small positive quadratic
    init[:, 1] = 0.5 * (early_slope + late_slope) # Average slope
    init[:, 2] = y_mean                            # Center at mean
    init[:, 3] = 0.3 / x_range**2                  # Moderate width control
    init[:, 4] = 0.1 / x_range                     # Small asymmetry
    init[:, 5] = 0                                 # No initial offset
    
    best_params = None
    best_loss = float(&#x27;inf&#x27;)
    
    # Stage 1: Local optimization with good starting point
    try:
        result = minimize(
            objective,
            init.ravel(),
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds * T,
            options={&#x27;maxiter&#x27;: 600, &#x27;ftol&#x27;: 1e-11, &#x27;gtol&#x27;: 1e-8}
        )
        if result.success:
            best_loss = result.fun
            best_params = result.x.reshape(T, P)
    except Exception:
        pass
    
    # Stage 2: Global search with focused parameters
    try:
        result_de = differential_evolution(
            objective,
            bounds * T,
            maxiter=120,
            popsize=15,
            seed=42,
            atol=1e-9,
            tol=1e-9,
            workers=1,
            polish=True,
            strategy=&#x27;best1bin&#x27;,
            mutation=(0.5, 1.5),
            recombination=0.7
        )
        if result_de.fun &lt; best_loss:
            best_loss = result_de.fun
            best_params = result_de.x.reshape(T, P)
    except Exception:
        pass
    
    # Stage 3: Final refinement if we have a good solution
    if best_params is not None and best_loss &lt; float(&#x27;inf&#x27;):
        try:
            result_final = minimize(
                objective,
                best_params.ravel(),
                method=&#x27;L-BFGS-B&#x27;,
                bounds=bounds * T,
                options={&#x27;maxiter&#x27;: 300, &#x27;ftol&#x27;: 1e-12}
            )
            if result_final.success and result_final.fun &lt; best_loss:
                best_params = result_final.x.reshape(T, P)
        except Exception:
            pass
    
    # Fallback to initialization
    if best_params is None:
        best_params = init
    
    return best_params[0] if T == 1 else best_params
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        R² = 0.488091
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Compact U-shaped scaling law with centered quadratic and exponential correction
Optimized for accuracy with minimal code complexity
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    U-shaped pattern: a*(x-b)^2 + c*x + d + e*exp(f*x)
    Centered quadratic for valley, exponential for rapid initial changes
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    params = np.atleast_2d(np.asarray(params))
    
    x = X[:, 0, None]
    
    if params.shape[1] &gt;= 6:
        a, b, c, d, e, f = [params[:, i] for i in range(6)]
        
        # Centered quadratic + linear + exponential + offset
        pred = (a * (x - b)**2 + c * x + d + 
                e * np.exp(np.clip(f * x, -15, 10)))
    else:
        pred = np.zeros((X.shape[0], params.shape[0]))
    
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Two-stage optimization with data-driven initialization
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    y2d = y[:, None] if y.ndim == 1 else y
    T = y2d.shape[1]
    P = 6
    
    # Extract data statistics
    x = X[:, 0]
    x_min, x_max, x_mean = x.min(), x.max(), x.mean()
    x_range = x_max - x_min
    y_min, y_max, y_mean, y_std = y.min(), y.max(), y.mean(), y.std()
    
    # Find valley (best performance - max since brier_score is negative)
    valley_x = x[np.argmax(y)]
    
    def objective(flat_params):
        params = flat_params.reshape(T, P)
        pred = scaling_law_func(X, params)
        mse = np.mean((pred - y2d) ** 2)
        # Differentiated regularization
        reg = 1e-7 * (np.sum(params[:, [0, 2, 4]]**2) + 
                      0.01 * np.sum(params[:, [1, 3, 5]]**2))
        return mse + reg
    
    # Smart bounds based on data
    bounds = [
        (0.01, 20),                          # a: positive for U
        (x_min - x_range, x_max + x_range),  # b: valley center
        (-20, 20),                           # c: linear trend
        (y_min - 3*y_std, y_max + 3*y_std),  # d: offset
        (-20, 20),                           # e: exp amplitude
        (-4, 3),                             # f: exp rate
    ] * T
    
    # Data-driven initialization
    init = np.tile([1.0, valley_x, 0.0, y_mean, -0.5, -1.0], (T, 1))
    
    # Global search
    result_de = differential_evolution(
        objective,
        bounds,
        maxiter=120,
        seed=42,
        atol=1e-7,
        tol=1e-7,
        init=&#x27;latinhypercube&#x27;,
        popsize=15,
        workers=1
    )
    
    # Local refinement
    result = minimize(
        objective,
        result_de.x,
        method=&#x27;L-BFGS-B&#x27;,
        bounds=bounds,
        options={&#x27;maxiter&#x27;: 1500, &#x27;ftol&#x27;: 1e-10}
    )
    
    params_opt = result.x.reshape(T, P) if result.success else result_de.x.reshape(T, P)
    return params_opt[0] if T == 1 else params_opt
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>