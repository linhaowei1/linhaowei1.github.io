<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - Parallel Scaling Law - opencode + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>Parallel Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">opencode</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">GPT-5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        0.999953
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.999554</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">0.999298</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.999953
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0">from typing import List, Dict

# Discovered scaling law (same functional form for all groups):
#   loss = c + a * num_params**(-alpha) + b * parallel_size**(-beta)
# Coefficients are fitted per group.

_PARAMS = {
    # Fitted on provided dataset
    &quot;stack&quot;: {
        &quot;c&quot;: 0.7711276768482299,
        &quot;a&quot;: 82.70170857310372,
        &quot;alpha&quot;: 0.27272727272727276,
        &quot;b&quot;: 0.0560743949982965,
        &quot;beta&quot;: 0.643939393939394,
    },
    &quot;pile&quot;: {
        &quot;c&quot;: 1.3473420493745163,
        &quot;a&quot;: 94.8923034356369,
        &quot;alpha&quot;: 0.24797979797979802,
        &quot;b&quot;: 0.11068492806080414,
        &quot;beta&quot;: 0.445959595959596,
    },
}

# Fallback parameters (simple average of known groups) for unseen groups
if _PARAMS:
    _FALLBACK = {
        k: sum(d[k] for d in _PARAMS.values()) / len(_PARAMS)
        for k in (&quot;c&quot;, &quot;a&quot;, &quot;alpha&quot;, &quot;b&quot;, &quot;beta&quot;)
    }
else:
    _FALLBACK = {&quot;c&quot;: 1.0, &quot;a&quot;: 1.0, &quot;alpha&quot;: 0.5, &quot;b&quot;: 0.1, &quot;beta&quot;: 0.5}


def _predict_one(x: Dict[str, float], p: Dict[str, float]) -&gt; float:
    n = float(x.get(&quot;num_params&quot;, 0.0))
    psize = float(x.get(&quot;parallel_size&quot;, 1.0))
    # Guard against non-positive inputs
    if n &lt;= 0:
        # Degenerate case: return intercept + parallel contribution
        n_term = 0.0
    else:
        n_term = n ** (-p[&quot;alpha&quot;])  # type: ignore
    if psize &lt;= 0:
        p_term = 0.0
    else:
        p_term = psize ** (-p[&quot;beta&quot;])  # type: ignore
    return p[&quot;c&quot;] + p[&quot;a&quot;] * n_term + p[&quot;b&quot;] * p_term


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    params = _PARAMS.get(group, _FALLBACK)
    preds = []
    for x in input_data:
        y = _predict_one(x, params)
        preds.append({&quot;loss&quot;: float(y)})
    return preds</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.999658
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1">from typing import List, Dict

# Discovered scaling law (same functional form for all groups):
#   loss = L_inf + k * (num_params ** (-alpha)) * (parallel_size ** (-beta))
# Coefficients are fitted per experimental group.

_PARAMS_BY_GROUP = {
    # group: (L_inf, k, alpha, beta)
    &quot;stack&quot;: (0.7511996419, 37.2725851817, 0.2229794195, 0.0719784665),
    &quot;pile&quot;:  (1.3518854109, 56.2975799228, 0.2142921940, 0.0605769454),
}


def _predict_loss(num_params: float, parallel_size: float, coeffs: tuple[float, float, float, float]) -&gt; float:
    L_inf, k, alpha, beta = coeffs
    # Guard against non-positive inputs (should not occur in valid data)
    if num_params &lt;= 0 or parallel_size &lt;= 0:
        raise ValueError(&quot;num_params and parallel_size must be positive&quot;)
    return float(L_inf + k * (num_params ** (-alpha)) * (parallel_size ** (-beta)))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys: &#x27;num_params&#x27;, &#x27;parallel_size&#x27;.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s). Keys: &#x27;loss&#x27;.
    &quot;&quot;&quot;
    # Select coefficients for the given group; if unknown, fallback to average of known groups
    if group in _PARAMS_BY_GROUP:
        coeffs = _PARAMS_BY_GROUP[group]
    else:
        # Fallback: simple average to remain robust to unseen groups
        import statistics as _stats
        L_inf = _stats.fmean(v[0] for v in _PARAMS_BY_GROUP.values())
        k = _stats.fmean(v[1] for v in _PARAMS_BY_GROUP.values())
        alpha = _stats.fmean(v[2] for v in _PARAMS_BY_GROUP.values())
        beta = _stats.fmean(v[3] for v in _PARAMS_BY_GROUP.values())
        coeffs = (L_inf, k, alpha, beta)

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        n = float(row[&quot;num_params&quot;])  # type: ignore[index]
        p = float(row[&quot;parallel_size&quot;])  # type: ignore[index]
        pred = _predict_loss(n, p, coeffs)
        outputs.append({&quot;loss&quot;: pred})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.999473
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2">from typing import List, Dict

# Fitted parameters for a power-law-with-offset scaling law per group
# Formula: loss = L0 + A * num_params^(-alpha) * parallel_size^(-beta)
_PARAMS: Dict[str, Dict[str, float]] = {
    &quot;stack&quot;: {
        &quot;L0&quot;: 0.746346,
        &quot;A&quot;: 34.954458,
        &quot;alpha&quot;: 0.21919,
        &quot;beta&quot;: 0.07275,
    },
    &quot;pile&quot;: {
        &quot;L0&quot;: 1.4938,
        &quot;A&quot;: 188.643207,
        &quot;alpha&quot;: 0.284241,
        &quot;beta&quot;: 0.083347,
    },
    # Fallback if an unknown group is provided
    &quot;__global__&quot;: {
        &quot;L0&quot;: 0.6906,
        &quot;A&quot;: 14.742912,
        &quot;alpha&quot;: 0.143482,
        &quot;beta&quot;: 0.04563,
    },
}


def _get_params(group: str) -&gt; Dict[str, float]:
    return _PARAMS.get(group, _PARAMS[&quot;__global__&quot;])


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys: &#x27;num_params&#x27;, &#x27;parallel_size&#x27;.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s): {&#x27;loss&#x27;: float}.
    &quot;&quot;&quot;
    p = _get_params(group)
    L0 = float(p[&quot;L0&quot;])  # asymptotic loss floor
    A = float(p[&quot;A&quot;])    # scale factor
    alpha = float(p[&quot;alpha&quot;])  # exponent for num_params
    beta = float(p[&quot;beta&quot;])    # exponent for parallel_size

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        N = float(row.get(&quot;num_params&quot;, 0.0))
        P = float(row.get(&quot;parallel_size&quot;, 0.0))
        # Guard against invalid inputs
        if N &lt;= 0 or P &lt;= 0:
            pred = float(&quot;nan&quot;)
        else:
            pred = L0 + A * (N ** (-alpha)) * (P ** (-beta))
        outputs.append({&quot;loss&quot;: float(pred)})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.999387
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict, List


#
# Scaling law discovered on the provided dataset
# Form:  loss = exp(a_g + b * ln(num_params) + c * ln(parallel_size))
#       = K_g * num_params**b * parallel_size**c
# with group-specific intercepts a_g and shared exponents b, c.
#

# Group-specific intercepts (a_g) in log space
_A_BY_GROUP: Dict[str, float] = {
    &quot;pile&quot;: 2.0598440555061694,
    &quot;stack&quot;: 1.4677491154318025,
}

# Shared exponents on num_params and parallel_size (log-linear coefficients)
_B_LOG_NUM_PARAMS: float = -0.06544312287562122
_C_LOG_PARALLEL: float = -0.02049343910349899


def _get_group_intercept(group: str) -&gt; float:
    if group in _A_BY_GROUP:
        return _A_BY_GROUP[group]
    # Fallback: mean intercept if an unknown group is requested
    return sum(_A_BY_GROUP.values()) / len(_A_BY_GROUP)


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    a_g = _get_group_intercept(group)
    b = _B_LOG_NUM_PARAMS
    c = _C_LOG_PARALLEL

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        # Pull inputs with basic validation/guarding for logs
        n_params = float(row.get(&quot;num_params&quot;, 0.0))
        p_size = float(row.get(&quot;parallel_size&quot;, 0.0))

        # Avoid log of zero or negatives
        n_params = max(n_params, 1e-12)
        p_size = max(p_size, 1e-12)

        pred_log = a_g + b * math.log(n_params) + c * math.log(p_size)
        pred_loss = math.exp(pred_log)

        outputs.append({&quot;loss&quot;: pred_loss})

    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.999298
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4">from __future__ import annotations

from typing import Dict, List

# Discovered scaling law (shared functional form across groups):
#   loss(N, P; g) = L_inf[g] + A[g] / (N**alpha[g] * P**beta[g])
# where
#   N = num_params, P = parallel_size, g = group name
# Coefficients were fitted per group on the provided dataset.

_COEFFICIENTS: Dict[str, Dict[str, float]] = {
    # group: {L_inf, A, alpha, beta}
    &quot;pile&quot;: {
        &quot;L_inf&quot;: 1.5938,
        &quot;A&quot;: 927.7951136423936,
        &quot;alpha&quot;: 0.3714475799060386,
        &quot;beta&quot;: 0.10974874419589042,
    },
    &quot;stack&quot;: {
        &quot;L_inf&quot;: 0.7906,
        &quot;A&quot;: 63.84810455867431,
        &quot;alpha&quot;: 0.25439743787254915,
        &quot;beta&quot;: 0.08449977586585611,
    },
}

# Fallback (used if an unseen group is requested): simple average of known groups
_DEFAULT = {
    k: sum(v[k] for v in _COEFFICIENTS.values()) / len(_COEFFICIENTS)
    for k in (&quot;L_inf&quot;, &quot;A&quot;, &quot;alpha&quot;, &quot;beta&quot;)
}


def _predict_loss(num_params: float, parallel_size: float, coeffs: Dict[str, float]) -&gt; float:
    N = float(num_params)
    P = float(parallel_size)
    if N &lt;= 0 or P &lt;= 0:
        # Guard against invalid inputs; return asymptotic value if invalid
        return float(coeffs[&quot;L_inf&quot;])
    return float(coeffs[&quot;L_inf&quot;] + coeffs[&quot;A&quot;] / (N ** coeffs[&quot;alpha&quot;] * P ** coeffs[&quot;beta&quot;]))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coeffs = _COEFFICIENTS.get(group, _DEFAULT)
    outputs: List[Dict[str, float]] = []
    for row in input_data:
        n = row.get(&quot;num_params&quot;)
        p = row.get(&quot;parallel_size&quot;)
        if n is None or p is None:
            raise KeyError(&quot;Each input row must contain &#x27;num_params&#x27; and &#x27;parallel_size&#x27;.&quot;)
        y = _predict_loss(float(n), float(p), coeffs)
        outputs.append({&quot;loss&quot;: float(y)})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>