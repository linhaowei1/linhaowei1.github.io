<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - LR & Batch Size Scaling Law - goose + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>LR & Batch Size Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">goose</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #d2691e; color: white"> 0.353682 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.279512</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">-0.015979</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #d2691e; color: white"> R² = 0.353682 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Functional form (shared across groups):
    Let x1 = log10(lr), x2 = log10(bsz), x3 = log10(data_size), x4 = log10(non_embedding_param_size).
    Then
        lm_loss = β0
                  + β1 x1 + β2 x2 + β3 x3 + β4 x4
                  + β5 x1^2 + β6 x2^2 + β7 x3^2 + β8 x4^2
                  + β9 x1 x2 + β10 x1 x3 + β11 x1 x4
                  + β12 x2 x3 + β13 x2 x4 + β14 x3 x4

    Coefficients β are group-specific when available; unknown groups fall back to a default set fit on all data.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s): {&#x27;lm_loss&#x27;: &lt;float&gt;}.
    &quot;&quot;&quot;
    import math

    # Coefficients per group (only &#x27;all_data&#x27; available in fitting). Fallback to &#x27;all_data&#x27;.
    COEFFICIENTS = {
        &quot;all_data&quot;: [
            16.80946515,  # β0 (bias)
            0.26248593,   # β1 * x1
            0.90495135,   # β2 * x2
            -2.14184167,  # β3 * x3
            -0.34843091,  # β4 * x4
            0.14852876,   # β5 * x1^2
            0.12695513,   # β6 * x2^2
            0.13572582,   # β7 * x3^2
            0.07861034,   # β8 * x4^2
            -0.08196004,  # β9 * x1*x2
            -0.02476690,  # β10 * x1*x3
            0.12229106,   # β11 * x1*x4
            -0.12308856,  # β12 * x2*x3
            -0.05300373,  # β13 * x2*x4
            -0.08072360,  # β14 * x3*x4
        ]
    }

    beta = COEFFICIENTS.get(group, COEFFICIENTS[&quot;all_data&quot;])

    outputs: list[dict[str, float]] = []
    eps = 1e-30  # guard for logs
    for row in input_data:
        x1 = math.log10(max(float(row[&quot;lr&quot;]), eps))
        x2 = math.log10(max(float(row[&quot;bsz&quot;]), eps))
        x3 = math.log10(max(float(row[&quot;data_size&quot;]), eps))
        x4 = math.log10(max(float(row[&quot;non_embedding_param_size&quot;]), eps))

        feats = [
            1.0,
            x1, x2, x3, x4,
            x1 * x1, x2 * x2, x3 * x3, x4 * x4,
            x1 * x2, x1 * x3, x1 * x4,
            x2 * x3, x2 * x4, x3 * x4,
        ]
        pred = 0.0
        for b, f in zip(beta, feats):
            pred += b * f
        outputs.append({&quot;lm_loss&quot;: float(pred)})

    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #d2691e; color: white"> R² = 0.353289 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1">from __future__ import annotations

from math import log10
from typing import Dict, List

# Quadratic-in-log scaling law with key interactions for language modeling loss.
#
# Let ld = log10(data_size), lp = log10(non_embedding_param_size),
#     llr = log10(lr), lb = log10(bsz).
#
# lm_loss = c0 \
#           + c1 * ld \
#           + c2 * lp \
#           + c3 * llr \
#           + c4 * lb \
#           + c5 * (llr)**2 \
#           + c6 * ld * lp \
#           + c7 * (ld)**2 \
#           + c8 * (lp)**2 \
#           + c9  * llr * ld \
#           + c10 * llr * lp \
#           + c11 * lb * ld \
#           + c12 * lb * lp \
#           + c13 * lb * llr \
#           + c14 * (lb)**2
#
# Coefficients are fitted per experimental group. If an unknown group is
# requested, we fall back to the &#x27;all_data&#x27; coefficients.

_COEFFS_BY_GROUP: Dict[str, List[float]] = {
    # Order:
    # [c0, c1(ld), c2(lp), c3(llr), c4(lb), c5(llr^2), c6(ld*lp), c7(ld^2), c8(lp^2),
    #  c9(llr*ld), c10(llr*lp), c11(lb*ld), c12(lb*lp), c13(lb*llr), c14(lb^2)]
    # Fitted on the provided dataset (/app/data)
    # Using least squares on 2702 points, R^2 ≈ 0.977 (5-fold CV ≈ 0.976)
    &quot;all_data&quot;: [
        1.681388886e01,  # c0
        -2.14226036e00,  # c1 (ld)
        -3.48992730e-01, # c2 (lp)
        2.62425420e-01,  # c3 (llr)
        9.04917660e-01,  # c4 (lb)
        1.48530750e-01,  # c5 (llr^2)
        -8.06989200e-02, # c6 (ld*lp)
        1.35736300e-01,  # c7 (ld^2)
        7.86298100e-02,  # c8 (lp^2)
        -2.47657100e-02, # c9 (llr*ld)
        1.22298120e-01,  # c10 (llr*lp)
        -1.23088430e-01, # c11 (lb*ld)
        -5.30003800e-02, # c12 (lb*lp)
        -8.19605000e-02, # c13 (lb*llr)
        1.26955570e-01,  # c14 (lb^2)
    ],
}

# Default/fallback coefficients
_DEFAULT_GROUP = &quot;all_data&quot;


def _safe_log10(x: float) -&gt; float:
    &quot;&quot;&quot;Compute log10 with a tiny positive floor for numerical safety.

    The dataset and expected inputs should be strictly positive for all variables,
    but we guard against accidental non-positive inputs by flooring to a tiny
    positive value to avoid math domain errors and keep the function robust.
    &quot;&quot;&quot;
    # Floor near double-precision minimum, but not too extreme to avoid inf
    tiny = 1e-300
    if not isinstance(x, (int, float)):
        raise TypeError(f&quot;Expected a number, got {type(x)}&quot;)
    if x &lt;= 0 or x != x:  # also handles NaN
        x = tiny
    return log10(x)


def _predict_row(row: Dict[str, float], coeffs: List[float]) -&gt; float:
    ld = _safe_log10(float(row[&quot;data_size&quot;]))
    lp = _safe_log10(float(row[&quot;non_embedding_param_size&quot;]))
    llr = _safe_log10(float(row[&quot;lr&quot;]))
    lb = _safe_log10(float(row[&quot;bsz&quot;]))

    (
        c0, c1, c2, c3, c4,
        c5, c6, c7, c8,
        c9, c10, c11, c12, c13, c14,
    ) = coeffs
    y = (
        c0
        + c1 * ld
        + c2 * lp
        + c3 * llr
        + c4 * lb
        + c5 * (llr ** 2)
        + c6 * ld * lp
        + c7 * (ld ** 2)
        + c8 * (lp ** 2)
        + c9 * llr * ld
        + c10 * llr * lp
        + c11 * lb * ld
        + c12 * lb * lp
        + c13 * lb * llr
        + c14 * (lb ** 2)
    )
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Required keys per dict:
                      - &#x27;lr&#x27;
                      - &#x27;bsz&#x27;
                      - &#x27;data_size&#x27;
                      - &#x27;non_embedding_param_size&#x27;
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups, but
                the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries with one key:
          - &#x27;lm_loss&#x27;: the predicted language modeling loss.
    &quot;&quot;&quot;
    coeffs = _COEFFS_BY_GROUP.get(group, _COEFFS_BY_GROUP[_DEFAULT_GROUP])

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        y = _predict_row(row, coeffs)
        outputs.append({&quot;lm_loss&quot;: y})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #d2691e; color: white"> R² = 0.353284 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2">from __future__ import annotations

import math
from typing import Dict, List


# Quadratic polynomial in the natural logs of inputs:
# Let x1 = ln(lr), x2 = ln(bsz), x3 = ln(data_size), x4 = ln(non_embedding_param_size).
# The law predicts lm_loss as:
# y = c0
#     + c1*x1 + c2*x2 + c3*x3 + c4*x4
#     + c5*x1^2 + c6*x2^2 + c7*x3^2 + c8*x4^2
#     + c9*x1*x2 + c10*x1*x3 + c11*x1*x4 + c12*x2*x3 + c13*x2*x4 + c14*x3*x4
# Coefficients can vary by group, but the functional form is fixed across groups.
# The coefficients below were fit via ordinary least squares on the provided training data.

_COEFFICIENTS_BY_GROUP: Dict[str, Dict[str, float]] = {
    # Fitted on the entire dataset available in /app/data at build time.
    # Keys correspond to the terms in the quadratic expansion defined above.
    &quot;all_data&quot;: {
        &quot;1&quot;: 16.813888860056007,
        &quot;Lr&quot;: 0.11396991227465522,
        &quot;Lb&quot;: 0.39300074777132327,
        &quot;Ld&quot;: -0.9303718536256446,
        &quot;Ln&quot;: -0.15156561752798173,
        &quot;Lr2&quot;: 0.02801463700508827,
        &quot;Lb2&quot;: 0.023945306016463035,
        &quot;Ld2&quot;: 0.02560145363651052,
        &quot;Ln2&quot;: 0.014830501411815829,
        &quot;LrLb&quot;: -0.015458709002005744,
        &quot;LrLd&quot;: -0.004671103503437297,
        &quot;LrLn&quot;: 0.02306685530058676,
        &quot;LbLd&quot;: -0.023215917228054137,
        &quot;LbLn&quot;: -0.009996491172168451,
        &quot;LdLn&quot;: -0.015220759923710097,
    }
}

# If an unknown group is requested, fall back to this group.
_FALLBACK_GROUP = &quot;all_data&quot;


def _predict_single(values: Dict[str, float], coefs: Dict[str, float]) -&gt; float:
    # Safeguard: ensure strictly positive inputs for logarithms
    eps = 1e-300
    lr = max(float(values.get(&quot;lr&quot;, 0.0)), eps)
    bsz = max(float(values.get(&quot;bsz&quot;, 0.0)), eps)
    data_size = max(float(values.get(&quot;data_size&quot;, 0.0)), eps)
    non_emb = max(float(values.get(&quot;non_embedding_param_size&quot;, 0.0)), eps)

    Lr = math.log(lr)
    Lb = math.log(bsz)
    Ld = math.log(data_size)
    Ln = math.log(non_emb)

    # Quadratic terms
    Lr2 = Lr * Lr
    Lb2 = Lb * Lb
    Ld2 = Ld * Ld
    Ln2 = Ln * Ln

    # Pairwise interactions
    LrLb = Lr * Lb
    LrLd = Lr * Ld
    LrLn = Lr * Ln
    LbLd = Lb * Ld
    LbLn = Lb * Ln
    LdLn = Ld * Ln

    y = (
        coefs[&quot;1&quot;]
        + coefs[&quot;Lr&quot;] * Lr
        + coefs[&quot;Lb&quot;] * Lb
        + coefs[&quot;Ld&quot;] * Ld
        + coefs[&quot;Ln&quot;] * Ln
        + coefs[&quot;Lr2&quot;] * Lr2
        + coefs[&quot;Lb2&quot;] * Lb2
        + coefs[&quot;Ld2&quot;] * Ld2
        + coefs[&quot;Ln2&quot;] * Ln2
        + coefs[&quot;LrLb&quot;] * LrLb
        + coefs[&quot;LrLd&quot;] * LrLd
        + coefs[&quot;LrLn&quot;] * LrLn
        + coefs[&quot;LbLd&quot;] * LbLd
        + coefs[&quot;LbLn&quot;] * LbLn
        + coefs[&quot;LdLn&quot;] * LdLn
    )
    return float(y)


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys per item:
                    - &#x27;lr&#x27;
                    - &#x27;bsz&#x27;
                    - &#x27;data_size&#x27;
                    - &#x27;non_embedding_param_size&#x27;
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups, but
                coefficients can differ per group. Unknown groups fall back to
                a default set of coefficients fit on the full dataset.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s) under key &#x27;lm_loss&#x27;.
    &quot;&quot;&quot;
    coefs = _COEFFICIENTS_BY_GROUP.get(group, _COEFFICIENTS_BY_GROUP[_FALLBACK_GROUP])
    results: List[Dict[str, float]] = []
    for row in input_data:
        yhat = _predict_single(row, coefs)
        results.append({&quot;lm_loss&quot;: yhat})
    return results</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #d2691e; color: white"> R² = 0.353284 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict, List

# Discovered scaling law:
# Quadratic polynomial in the logarithms of the inputs with all pairwise interactions.
# y = c0 + c1*L + c2*B + c3*D + c4*P
#     + c5*L^2 + c6*B^2 + c7*D^2 + c8*P^2
#     + c9*L*B + c10*L*D + c11*L*P + c12*B*D + c13*B*P + c14*D*P
# where L=log(lr), B=log(bsz), D=log(data_size), P=log(non_embedding_param_size)
#
# Coefficients are per-group. If an unknown group is provided, fall back to &#x27;all_data&#x27;.

COEFS: Dict[str, List[float]] = {
    # Fitted on the provided dataset (single group: &#x27;all_data&#x27;)
    # Order: [c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14]
    &quot;all_data&quot;: [
        16.813888860056007,
        0.11396991227465522,
        0.39300074777132327,
        -0.9303718536256446,
        -0.15156561752798173,
        0.02801463700508827,
        0.023945306016463035,
        0.02560145363651052,
        0.014830501411815829,
        -0.015458709002005744,
        -0.004671103503437297,
        0.02306685530058676,
        -0.023215917228054137,
        -0.009996491172168451,
        -0.015220759923710097,
    ],
}

DEFAULT_GROUP = &quot;all_data&quot;


def _predict_one(x: Dict[str, float], coeffs: List[float]) -&gt; float:
    try:
        L = math.log(float(x[&quot;lr&quot;]))
        B = math.log(float(x[&quot;bsz&quot;]))
        D = math.log(float(x[&quot;data_size&quot;]))
        P = math.log(float(x[&quot;non_embedding_param_size&quot;]))
    except KeyError as e:
        raise KeyError(f&quot;Missing required key in input data: {e}&quot;)
    except ValueError:
        raise ValueError(&quot;All input values must be positive to take logarithms.&quot;)

    c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14 = coeffs

    y = (
        c0
        + c1 * L
        + c2 * B
        + c3 * D
        + c4 * P
        + c5 * (L * L)
        + c6 * (B * B)
        + c7 * (D * D)
        + c8 * (P * P)
        + c9 * (L * B)
        + c10 * (L * D)
        + c11 * (L * P)
        + c12 * (B * D)
        + c13 * (B * P)
        + c14 * (D * P)
    )
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coeffs = COEFS.get(group, COEFS[DEFAULT_GROUP])

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        y = _predict_one(row, coeffs)
        outputs.append({&quot;lm_loss&quot;: y})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #b22222; color: white"> R² = -0.015979 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4">from __future__ import annotations
from typing import Dict, List
import math

# Coefficients fitted on the provided dataset (group: &#x27;all_data&#x27;)
# Functional form (log10 domain):
# lm_loss = a0 + a1*z + a2*z^2 + a3*s + a4*p + a5*b
# where z = log10(lr), s = log10(data_size), p = log10(non_embedding_param_size), b = log10(bsz)

PARAMS: Dict[str, Dict[str, float]] = {
    &quot;all_data&quot;: {
        &quot;a0&quot;: 9.02029713,
        &quot;a1&quot;: 0.777093486,
        &quot;a2&quot;: 0.134036623,
        &quot;a3&quot;: -0.281303442,
        &quot;a4&quot;: -0.302704433,
        &quot;a5&quot;: 0.000603497861,
    },
}

# Fallback to use if an unknown group is requested
DEFAULT_GROUP = &quot;all_data&quot;


def _safe_log10(x: float) -&gt; float:
    # Guard against numerical issues; inputs in data are strictly positive by design
    # but we still clamp to avoid log of non-positive values.
    eps = 1e-12
    return math.log10(max(x, eps))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    params = PARAMS.get(group, PARAMS.get(DEFAULT_GROUP, next(iter(PARAMS.values()))))
    a0 = params[&quot;a0&quot;]; a1 = params[&quot;a1&quot;]; a2 = params[&quot;a2&quot;]; a3 = params[&quot;a3&quot;]; a4 = params[&quot;a4&quot;]; a5 = params[&quot;a5&quot;]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        lr = float(row.get(&quot;lr&quot;, 0.0))
        bsz = float(row.get(&quot;bsz&quot;, 0.0))
        data_size = float(row.get(&quot;data_size&quot;, 0.0))
        non_embed_params = float(row.get(&quot;non_embedding_param_size&quot;, 0.0))

        z = _safe_log10(lr)
        s = _safe_log10(data_size)
        p = _safe_log10(non_embed_params)
        b = _safe_log10(bsz)

        lm_loss = a0 + a1 * z + a2 * (z ** 2) + a3 * s + a4 * p + a5 * b
        outputs.append({&quot;lm_loss&quot;: float(lm_loss)})

    return outputs</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
