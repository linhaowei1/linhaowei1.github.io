% Table 1: GPT-5 agents
\begin{table*}[t]

\centering

\vspace{-0.2em}

\caption{Performance on SLDBench for agents using GPT-5. Scores are $R^2$ averaged over five runs. The \textbf{best} and \underline{second-best} scores for each task are highlighted. ``NA'' indicates no valid output.}

\label{tab:gpt5}

\Huge

\renewcommand{\arraystretch}{1.2}

\resizebox{\textwidth}{!}{%

\begin{tabular}{lccccccccc}

\toprule

& \texttt{parallel}$\uparrow$ & \texttt{vocab_size}$\uparrow$ & \texttt{SFT}$\uparrow$ & \texttt{domain_mix}$\uparrow$ & \texttt{moe}$\uparrow$ & \texttt{d_constrain}$\uparrow$ & \texttt{lr\&bsz}$\uparrow$ & \texttt{u_shape}$\uparrow$ & \textbf{Avg. R$^2$}$\uparrow$ \\

\midrule

Aider & 0.991 & 0.132 & 0.131 & 0.514 & 0.119 & 0.718 & -0.659 & -0.474 & 0.184 \\

Terminus-2 & 1.000 & 0.533 & 0.114 & 0.502 & 0.186 & 0.366 & -0.754 & -0.604 & 0.168 \\

Mini-SWE-Agent & 0.997 & 0.554 & 0.853 & 0.873 & 0.352 & 0.903 & -0.269 & -0.491 & 0.471 \\

OpenCode & 1.000 & 0.889 & 0.845 & \textbf{0.960} & 0.240 & \textbf{0.920} & -0.368 & -0.480 & 0.501 \\

OpenHands & 1.000 & 0.182 & 0.640 & 0.899 & 0.466 & 0.534 & -0.909 & \underline{-0.278} & 0.317 \\

CodeX & 0.999 & \textbf{0.977} & 0.855 & 0.933 & 0.649 & 0.763 & -0.039 & -0.740 & 0.550 \\

Goose & 1.000 & 0.962 & 0.899 & \underline{0.944} & \textbf{0.813} & 0.894 & \underline{0.280} & \textbf{-0.232} & \underline{0.695} \\

SLDAgent & \underline{1.000} & \underline{0.974} & \textbf{0.993} & 0.917 & \underline{0.751} & \underline{0.915} & \textbf{0.497} & -0.539 & \textbf{0.689} \\

Human & \textbf{1.000} & 0.966 & \underline{0.957} & 0.671 & 0.703 & 0.911 & -0.076 & -1.000 & 0.517 \\

\bottomrule

\end{tabular}%

}

\end{table*}

% Table 2: Provider-specific agents
\begin{table*}[t]

\centering

\vspace{-0.2em}

\caption{SLDBench performance of provider-specific agents together with reference rows for {SLDAgent} paired with the corresponding provider models. ``G-2.5-Flash'' denotes Gemini-2.5-Flash, ``G-3-Pro'' denotes Gemini-3-Pro-Preview, ``C-Haiku-4.5'' denotes Claude-Haiku-4.5, and ``C-Sonnet-4.5'' denotes Claude-Sonnet-4.5. Scores report $R^2$, averaged over five runs. Bold denotes the best value within each model family.}

\label{tab:non_o4}

\Huge

\renewcommand{\arraystretch}{1.2}

\resizebox{\textwidth}{!}{%

\begin{tabular}{lccccccccc}

\toprule

& \texttt{parallel}$\uparrow$ & \texttt{vocab_size}$\uparrow$ & \texttt{SFT}$\uparrow$ & \texttt{domain_mix}$\uparrow$ & \texttt{moe}$\uparrow$ & \texttt{d_constrain}$\uparrow$ & \texttt{lr\&bsz}$\uparrow$ & \texttt{u_shape}$\uparrow$ & \textbf{Avg. R$^2$}$\uparrow$ \\

\midrule

Gemini-CLI (G-2.5-Flash) & 0.200 & 0.485 & 0.787 & 0.530 & 0.273 & 0.011 & -0.873 & \textbf{-0.794} & 0.077 \\

SLDAgent (G-2.5-Flash) & \textbf{1.000} & \textbf{0.960} & \textbf{0.981} & \textbf{0.991} & \textbf{0.705} & \textbf{0.929} & \textbf{-0.871} & -1.000 & \textbf{0.462} \\

\midrule

Gemini-CLI (G-3-Pro) & 0.600 & 0.578 & 0.462 & \textbf{0.978} & \textbf{0.833} & \textbf{0.783} & -0.332 & \textbf{-0.847} & 0.382 \\

SLDAgent (G-3-Pro) & \textbf{1.000} & \textbf{0.978} & \textbf{0.989} & 0.771 & 0.755 & 0.709 & \textbf{0.356} & -1.000 & \textbf{0.570} \\

\midrule

Claude Code (C-Haiku-4.5) & 1.000 & 0.895 & 0.894 & 0.905 & \textbf{0.394} & \textbf{0.778} & \textbf{-0.511} & -1.000 & 0.419 \\

SLDAgent (C-Haiku-4.5) & \textbf{1.000} & \textbf{0.956} & \textbf{0.958} & \textbf{0.924} & 0.386 & 0.517 & -0.782 & \textbf{-0.800} & \textbf{0.395} \\

\midrule

Claude Code (C-Sonnet-4.5) & 0.998 & 0.962 & 0.916 & \textbf{0.971} & \textbf{0.858} & \textbf{0.916} & -0.846 & -1.000 & 0.472 \\

SLDAgent (C-Sonnet-4.5) & \textbf{1.000} & \textbf{0.978} & \textbf{0.955} & 0.938 & 0.763 & 0.751 & \textbf{-0.497} & \textbf{-0.912} & \textbf{0.497} \\

\midrule

CodeX (o4-mini) & 1.000 & 0.861 & 0.883 & 0.553 & 0.468 & 0.805 & -0.773 & \textbf{-1.000} & 0.349 \\

SLDAgent (o4-mini) & \textbf{1.000} & \textbf{0.971} & \textbf{0.992} & \textbf{0.957} & \textbf{0.742} & \textbf{0.914} & \textbf{-0.457} & -1.000 & \textbf{0.515} \\

\midrule

CodeX (GPT-5) & 0.999 & \textbf{0.977} & 0.855 & \textbf{0.933} & 0.649 & 0.763 & -0.039 & -0.740 & 0.550 \\

SLDAgent (GPT-5) & \textbf{1.000} & 0.974 & \textbf{0.993} & 0.917 & \textbf{0.751} & \textbf{0.915} & \textbf{0.497} & \textbf{-0.539} & \textbf{0.689} \\

Human & 1.000 & 0.966 & 0.957 & 0.671 & 0.703 & 0.911 & -0.076 & -1.000 & 0.517 \\

\bottomrule

\end{tabular}%

}

\end{table*}