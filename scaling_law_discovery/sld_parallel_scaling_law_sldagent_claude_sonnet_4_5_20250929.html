<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Parallel Scaling Law - SLDAgent + Claude Sonnet 4.5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Parallel Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">SLDAgent</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">Claude Sonnet 4.5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.999957 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.999907</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.999885</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">

        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999957 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Enhanced parallel scaling law with multiplicative interaction:
L = C * N^(-alpha) / (1 + beta * log(P)) + gamma
This form captures the diminishing returns of parallelization more naturally.
4 parameters: alpha, beta, gamma, C
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution, minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law with logarithmic parallel benefit:
    L = C * N^(-alpha) / (1 + beta * log(P)) + gamma
    params = [alpha, beta, gamma, C]
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    params = np.asarray(params)
    
    if params.ndim == 1:
        params = params[None, :]
    
    N, P = X[:, 0], X[:, 1]
    
    results = []
    for p in params:
        alpha, beta, gamma, C = p
        N_safe = np.maximum(N, 1e6)
        P_safe = np.maximum(P, 1.0)
        
        # Logarithmic parallel scaling with diminishing returns
        log_P = np.log(P_safe)
        parallel_factor = 1.0 + beta * log_P
        parallel_factor = np.maximum(parallel_factor, 0.1)  # Numerical stability
        
        pred = C * np.power(N_safe, -alpha) / parallel_factor + gamma
        results.append(pred)
    
    result = np.array(results).T
    return result[:, 0] if result.shape[1] == 1 else result


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Robust optimization with expanded search space for new formulation
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    
    if y.ndim == 1:
        y = y[:, None]
    
    N_samples, N_outputs = y.shape
    all_params = []
    
    for i in range(N_outputs):
        y_i = y[:, i]
        y_std = np.std(y_i)
        
        def objective(params):
            pred = scaling_law_func(X, params)
            if pred.ndim &gt; 1:
                pred = pred[:, i]
            mse = np.mean((pred - y_i) ** 2)
            # Normalize regularization by data scale
            reg = (1e-4 * y_std) * (params[0]**2 + params[1]**2)
            return mse + reg
        
        # Adjusted bounds for logarithmic formulation
        # beta now scales log(P) instead of P directly
        bounds = [
            (0.01, 0.50),    # alpha: parameter scaling exponent
            (0.01, 0.40),    # beta: log-parallel scaling coefficient
            (0.50, 2.50),    # gamma: asymptotic loss floor
            (1e-4, 1e5)      # C: scaling constant
        ]
        
        # Multi-restart global optimization
        best_score = float(&#x27;inf&#x27;)
        best_x = None
        
        # Try more seeds for robustness with new formulation
        for seed in [42, 123, 256, 789]:
            result = differential_evolution(
                objective,
                bounds,
                maxiter=350,
                popsize=16,
                seed=seed,
                strategy=&#x27;best1bin&#x27;,
                atol=1e-9,
                tol=1e-9,
                mutation=(0.5, 1.5),
                recombination=0.8,
                polish=False,
                workers=1
            )
            
            if result.fun &lt; best_score:
                best_score = result.fun
                best_x = result.x
        
        # Multi-method local refinement
        methods = [&#x27;L-BFGS-B&#x27;, &#x27;TNC&#x27;]
        best_local_score = best_score
        best_local_x = best_x
        
        for method in methods:
            try:
                result_local = minimize(
                    objective,
                    best_x,
                    method=method,
                    bounds=bounds,
                    options={&#x27;maxiter&#x27;: 2000, &#x27;ftol&#x27;: 1e-11}
                )
                
                if result_local.success and result_local.fun &lt; best_local_score:
                    best_local_score = result_local.fun
                    best_local_x = result_local.x
            except:
                continue
        
        final_params = best_local_x if best_local_score &lt; best_score else best_x
        all_params.append(final_params)
    
    params_array = np.array(all_params)
    return params_array[0] if N_outputs == 1 else params_array
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999911 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Optimized scaling law: L = a * N^b + c * P^d
Additive power law with normalized inputs for stability
4 parameters: [a, b, c, d]
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution, minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: L = a * (N/1e9)^b + c * P^d
    Normalized N for numerical stability
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    a, b, c, d = params[:4]
    
    N = X[:, 0] / 1e9  # Normalize to billions
    P = X[:, 1]
    
    # Ensure numerical stability
    N = np.maximum(N, 1e-8)
    P = np.maximum(P, 1.0)
    
    return a * np.power(N, b) + c * np.power(P, d)


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fit using differential evolution + local refinement
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values).flatten()
    
    P = X[:, 1]
    
    # Analyze parallel effect
    y_mean = np.mean(y)
    p_losses = {}
    for p in np.unique(P):
        p_losses[p] = np.mean(y[P == p])
    
    # Estimate parallel delta
    if len(p_losses) &gt; 1:
        p_sorted = sorted(p_losses.keys())
        parallel_delta = p_losses[p_sorted[0]] - p_losses[p_sorted[-1]]
    else:
        parallel_delta = 0.05
    
    def objective(params):
        pred = scaling_law_func(X, params)
        return np.mean((pred - y) ** 2) + 1e-9 * np.sum(params ** 2)
    
    # Tight bounds based on top performers
    bounds = [
        (0.1, 4.5),      # a: main coefficient
        (-0.3, 0.3),     # b: param exponent
        (-2.0, 2.0),     # c: parallel coefficient
        (-0.7, 0.2)      # d: parallel exponent
    ]
    
    # Global search
    result = differential_evolution(
        objective,
        bounds,
        seed=42,
        maxiter=400,
        popsize=15,
        atol=1e-11,
        tol=1e-11,
        polish=True
    )
    
    # Local refinement
    result = minimize(
        objective,
        result.x,
        method=&#x27;L-BFGS-B&#x27;,
        bounds=bounds,
        options={&#x27;maxiter&#x27;: 2000, &#x27;ftol&#x27;: 1e-13}
    )
    
    return result.x
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999894 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Compact multiplicative scaling law: loss = a * num_params^b * parallel_size^c * (1 + d/parallel_size)
Simpler form capturing parameter decay and parallel efficiency with fewer operations.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution, minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: loss = a * num_params^b * parallel_size^c * (1 + d/parallel_size)
    params: [a, b, c, d] - base, param exp, parallel exp, interaction term
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    params = np.asarray(params).ravel()
    
    num_params = data_points[:, 0] / 1e9  # Normalize to billions
    parallel_size = data_points[:, 1]
    
    a, b, c, d = params
    
    # Multiplicative form with interaction term
    return a * np.power(num_params, b) * np.power(parallel_size, c) * (1 + d / parallel_size)


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Compact two-stage fitting: global + local refinement.
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    loss_values = np.asarray(loss_values).ravel()
    
    def objective(params):
        try:
            pred = scaling_law_func(data_points, params)
            if not np.all(np.isfinite(pred)):
                return 1e10
            return np.mean((pred - loss_values) ** 2) + 0.0001 * (params[1]**2 + params[2]**2)
        except:
            return 1e10
    
    # Adjusted bounds for multiplicative form
    bounds = [(0.3, 10.0), (-0.6, 0.1), (-0.5, 0.1), (-0.5, 0.5)]
    
    # Global optimization
    result = differential_evolution(
        objective,
        bounds,
        strategy=&#x27;best1bin&#x27;,
        maxiter=500,
        popsize=24,
        mutation=(0.5, 1.2),
        recombination=0.8,
        seed=42,
        atol=1e-9,
        tol=1e-9,
        polish=True
    )
    
    best_params = result.x
    best_score = result.fun
    
    # Local refinement
    if result.success:
        try:
            local = minimize(
                objective,
                result.x,
                method=&#x27;L-BFGS-B&#x27;,
                bounds=bounds,
                options={&#x27;maxiter&#x27;: 1800, &#x27;ftol&#x27;: 1e-12}
            )
            if local.success and local.fun &lt; best_score:
                best_params = local.x
                best_score = local.fun
        except:
            pass
        
        # Final polish
        try:
            final = minimize(
                objective,
                best_params,
                method=&#x27;L-BFGS-B&#x27;,
                bounds=bounds,
                options={&#x27;maxiter&#x27;: 2200, &#x27;ftol&#x27;: 1e-13, &#x27;gtol&#x27;: 1e-11}
            )
            if final.success and final.fun &lt; best_score:
                best_params = final.x
        except:
            pass
    
    return best_params
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999889 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Simplified power-log scaling law
Uses 4 parameters: [a, b, c, d]
Form: loss = a * N^b - c * log(1 + d * (P - 1))
where N = num_params (normalized), P = parallel_size

Theoretical basis:
- Power law for parameter scaling (Chinchilla, GPT-3)
- Logarithmic benefit from parallel aggregation (information theory)
- Subtractive form: parallel copies independently reduce loss
- Minimal complexity for robust fitting
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Compute: loss = a * N^b - c * log(1 + d * (P - 1))
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    params = np.asarray(params).ravel()
    
    N = np.maximum(data_points[:, 0] / 1e9, 1e-3)  # Normalize to billions
    P = np.maximum(data_points[:, 1], 1.0)
    
    a, b, c, d = params
    
    base = a * np.power(N, b)
    benefit = c * np.log1p(d * (P - 1.0))
    
    return base - benefit


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fit via differential evolution with refined bounds
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    loss_values = np.asarray(loss_values).ravel()
    
    def objective(params):
        try:
            pred = scaling_law_func(data_points, params)
            if not np.all(np.isfinite(pred)):
                return 1e10
            return np.mean((pred - loss_values) ** 2) + 1e-10 * np.sum(params**2)
        except:
            return 1e10
    
    bounds = [
        (0.3, 6.0),      # a: base coefficient  
        (-0.6, -0.03),   # b: parameter exponent (negative)
        (0.0, 0.4),      # c: parallel benefit magnitude
        (0.05, 4.0)      # d: parallel efficiency rate
    ]
    
    # Multi-start for robustness
    best_params = None
    best_loss = float(&#x27;inf&#x27;)
    
    for seed in [42, 123, 789]:
        result = differential_evolution(
            objective,
            bounds=bounds,
            seed=seed,
            maxiter=600,
            atol=1e-12,
            tol=1e-12,
            popsize=25,
            strategy=&#x27;best1bin&#x27;,
            mutation=(0.6, 1.8),
            recombination=0.8,
            polish=True,
            workers=1
        )
        
        if result.fun &lt; best_loss:
            best_loss = result.fun
            best_params = result.x
    
    return best_params
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999885 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Optimized scaling law: loss = a * N^b + c / (1 + d * P)
Uses hyperbolic decay for parallel benefits with streamlined fitting
Key: Simpler code with better parameter estimation
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: loss = a * (N/1e9)^b + c / (1 + d * P)
    
    params[0] = a: base scale for power law
    params[1] = b: power exponent (negative)
    params[2] = c: parallel benefit scale
    params[3] = d: parallel saturation rate
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    params = np.asarray(params).ravel()
    
    N_norm = np.maximum(data_points[:, 0] / 1e9, 0.1)
    P = np.maximum(data_points[:, 1], 1.0)
    
    a, b, c, d = params
    
    # Power law + hyperbolic parallel benefit
    loss = a * np.power(N_norm, b) + c / (1.0 + d * P)
    
    return loss


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Streamlined hybrid optimization
    &quot;&quot;&quot;
    data_points = np.atleast_2d(np.asarray(data_points))
    loss_values = np.asarray(loss_values).ravel()
    
    P = data_points[:, 1]
    
    # Data-driven estimates
    high_p = P &gt;= np.percentile(P, 70)
    low_p = P &lt;= np.percentile(P, 30)
    
    baseline = np.mean(loss_values[high_p]) if np.any(high_p) else np.min(loss_values)
    parallel_gain = (np.mean(loss_values[low_p]) - baseline) if np.any(low_p) and np.any(high_p) else np.std(loss_values) * 0.5
    parallel_gain = max(parallel_gain, 0.01)
    
    mean_loss = np.mean(loss_values)
    max_loss = np.max(loss_values)
    
    def objective(params):
        pred = scaling_law_func(data_points, params)
        mse = np.mean((pred - loss_values) ** 2)
        reg = 1e-8 * (params[0]**2 + params[2]**2)
        return mse + reg
    
    # Optimized bounds
    bounds = [
        (baseline * 0.3, max_loss * 2),    # a
        (-0.4, 0.05),                       # b
        (0.001, parallel_gain * 3),         # c
        (0.001, 5.0)                        # d
    ]
    
    best_params = None
    best_score = float(&#x27;inf&#x27;)
    
    # Global search
    try:
        res = differential_evolution(
            objective, bounds, seed=42,
            maxiter=400, popsize=15,
            atol=1e-10, tol=1e-10,
            workers=1, polish=True
        )
        best_params = res.x
        best_score = res.fun
    except:
        pass
    
    # Strategic local searches
    inits = [
        [baseline * 1.05, -0.06, parallel_gain * 0.9, 0.35],
        [baseline * 0.95, -0.08, parallel_gain * 1.1, 0.45],
        [mean_loss * 0.9, -0.05, parallel_gain * 0.7, 0.25],
        [baseline * 1.2, -0.09, parallel_gain * 1.3, 0.6],
    ]
    
    if best_params is not None:
        inits.insert(0, best_params)
    
    for init in inits:
        try:
            res = minimize(
                objective, init,
                method=&#x27;L-BFGS-B&#x27;, bounds=bounds,
                options={&#x27;maxiter&#x27;: 2000, &#x27;ftol&#x27;: 1e-12, &#x27;gtol&#x27;: 1e-9}
            )
            if res.fun &lt; best_score:
                best_score = res.fun
                best_params = res.x
        except:
            continue
    
    # Final polish
    if best_params is not None:
        try:
            res = minimize(
                objective, best_params,
                method=&#x27;L-BFGS-B&#x27;, bounds=bounds,
                options={&#x27;maxiter&#x27;: 1500, &#x27;ftol&#x27;: 1e-13}
            )
            if res.fun &lt; best_score:
                best_params = res.x
        except:
            pass
    
    # Fallback
    if best_params is None:
        best_params = np.array([baseline * 1.05, -0.06, parallel_gain * 0.9, 0.35])
    
    return best_params
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>