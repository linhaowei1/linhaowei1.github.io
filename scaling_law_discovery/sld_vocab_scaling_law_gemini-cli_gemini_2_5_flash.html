<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Vocabulary Scaling Law - gemini-cli + Gemini 2.5 Flash</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Vocabulary Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">gemini-cli</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">Gemini 2.5 Flash</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #228b22; color: white"> 0.933603 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.485317</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">-1.000000</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.933603 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fitted parameters for the &#x27;all_data&#x27; group
    # A (asymptotic minimum loss): -5.695759
    # B (coefficient): 6.175213e+03
    # C_v (vocab_size exponent): -0.000000
    # C_np (non_vocab_parameters exponent): -0.040118
    # C_nc (num_characters exponent): -0.336321

    # In a real scenario with multiple groups, you would have a dictionary
    # mapping group names to their respective parameter sets.
    # For this problem, &#x27;group&#x27; is always &#x27;all_data&#x27;.
    
    # Using parameters directly from the fitting script
    # These values were obtained from /app/fitted_params.py
    # and confirmed in the previous step&#x27;s output.
    A = -5.695759
    B = 6.175213e+03
    C_v = -0.000000 # Effectively 0
    C_np = -0.040118
    C_nc = -0.336321

    predictions = []
    for data_point in input_data:
        vocab_size = data_point[&#x27;vocab_size&#x27;]
        non_vocab_parameters = data_point[&#x27;non_vocab_parameters&#x27;]
        num_characters = data_point[&#x27;num_characters&#x27;]

        predicted_loss = A + B * (vocab_size**C_v) * (non_vocab_parameters**C_np) * (num_characters**C_nc)
        predictions.append({&#x27;unigram_normalized_loss&#x27;: predicted_loss})
    
    return predictions</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.861121 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1">import numpy as np

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fitted parameters for the &#x27;all_data&#x27; group
    # A + B * log(non_vocab_parameters) + C * log(vocab_size) + D * log(num_characters)
    # These parameters were obtained by fitting the model to the provided dataset.
    # For this specific dataset, only one group &#x27;all_data&#x27; was present.
    fitted_params = {
        &#x27;all_data&#x27;: {
            &#x27;A&#x27;: 6.380590666656606,
            &#x27;B&#x27;: 0.016411077894625814,
            &#x27;C&#x27;: 0.06340182538033912,
            &#x27;D&#x27;: -0.501700641788903
        }
    }

    if group not in fitted_params:
        raise ValueError(f&quot;Parameters for group &#x27;{group}&#x27; not found.&quot;)

    params = fitted_params[group]
    predictions = []

    for data_point in input_data:
        N = data_point[&#x27;non_vocab_parameters&#x27;]
        V = data_point[&#x27;vocab_size&#x27;]
        Ch = data_point[&#x27;num_characters&#x27;]

        # Ensure inputs are positive for log, although they should be for this problem context.
        # Add a small epsilon if inputs can be zero to avoid log(0) issues, but typically not needed for LM parameters.
        if N &lt;= 0 or V &lt;= 0 or Ch &lt;= 0:
            # Handle invalid input, perhaps by returning NaN or raising an error
            # For now, let&#x27;s assume valid positive inputs as per typical LM scaling laws.
            # Or, for safety, one could add a small epsilon: np.log(max(1e-9, N))
            raise ValueError(&quot;Input variables (non_vocab_parameters, vocab_size, num_characters) must be positive.&quot;)

        predicted_loss = params[&#x27;A&#x27;] + \
                         params[&#x27;B&#x27;] * np.log(N) + \
                         params[&#x27;C&#x27;] * np.log(V) + \
                         params[&#x27;D&#x27;] * np.log(Ch)
        predictions.append({&#x27;unigram_normalized_loss&#x27;: predicted_loss})

    return predictions</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.861121 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2">import numpy as np

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fitted parameters for the &#x27;all_data&#x27; group
    # These were derived from a linear regression on log-transformed input variables.
    params = {
        &#x27;all_data&#x27;: {
            &#x27;intercept&#x27;: 6.380591236629035,
            &#x27;coeff_log_vocab_size&#x27;: 0.06340183,
            &#x27;coeff_log_non_vocab_parameters&#x27;: 0.01641106,
            &#x27;coeff_log_num_characters&#x27;: -0.50170066
        }
    }

    if group not in params:
        raise ValueError(f&quot;Group &#x27;{group}&#x27; not found in fitted parameters.&quot;)

    group_params = params[group]
    predictions = []

    for data_point in input_data:
        vocab_size = data_point[&#x27;vocab_size&#x27;]
        non_vocab_parameters = data_point[&#x27;non_vocab_parameters&#x27;]
        num_characters = data_point[&#x27;num_characters&#x27;]

        # Apply the logarithmic transformation and the linear model
        predicted_loss = (
            group_params[&#x27;intercept&#x27;] +
            (group_params[&#x27;coeff_log_vocab_size&#x27;] * np.log(vocab_size)) +
            (group_params[&#x27;coeff_log_non_vocab_parameters&#x27;] * np.log(non_vocab_parameters)) +
            (group_params[&#x27;coeff_log_num_characters&#x27;] * np.log(num_characters))
        )
        predictions.append({&#x27;unigram_normalized_loss&#x27;: predicted_loss})

    return predictions</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #daa520; color: white"> R² = 0.770740 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fitted parameters for the &#x27;all_data&#x27; group
    # A (coefficient for entire term): 0.2608838337933339
    # B (exponent for vocab_size): -0.023068770836020696
    # C (exponent for non_vocab_parameters): -0.028815143477267144
    # D (exponent for num_characters): 0.15345185239044845
    
    # Since only one group &#x27;all_data&#x27; was found, we use these parameters for all predictions.
    # If multiple groups were present, this dictionary would contain parameters for each.
    fitted_params = {
        &#x27;all_data&#x27;: {
            &#x27;A&#x27;: 0.2608838337933339,
            &#x27;B&#x27;: -0.023068770836020696,
            &#x27;C&#x27;: -0.028815143477267144,
            &#x27;D&#x27;: 0.15345185239044845
        }
    }

    # Retrieve parameters for the specified group
    params = fitted_params.get(group)
    if not params:
        raise ValueError(f&quot;No fitted parameters found for group: {group}&quot;)

    A = params[&#x27;A&#x27;]
    B = params[&#x27;B&#x27;]
    C = params[&#x27;C&#x27;]
    D = params[&#x27;D&#x27;]

    predictions = []
    for data_point in input_data:
        vocab_size = data_point[&#x27;vocab_size&#x27;]
        non_vocab_parameters = data_point[&#x27;non_vocab_parameters&#x27;]
        num_characters = data_point[&#x27;num_characters&#x27;]

        # The discovered mathematical formula
        predicted_loss = -A * (vocab_size**B) * (non_vocab_parameters**C) * (num_characters**D)
        
        predictions.append({&#x27;unigram_normalized_loss&#x27;: predicted_loss})

    return predictions</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #b22222; color: white"> R² = -1.000000 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4">import math

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Hypothetical fitted parameters (these would be derived from actual data fitting)
    # Exponents are assumed constant across groups
    a = -0.5  # exponent for vocab_size
    b = -0.3  # exponent for non_vocab_parameters
    d = -0.2  # exponent for num_characters

    # Group-specific C values (intercepts in log-log space)
    group_C_values = {
        &quot;group_A&quot;: math.exp(2.0),  # Hypothetical C for group_A
        &quot;group_B&quot;: math.exp(1.8),  # Hypothetical C for group_B
        &quot;group_C&quot;: math.exp(2.2),  # Hypothetical C for group_C
        # Add more groups if necessary, or a default
    }

    if group not in group_C_values:
        # Handle unknown groups - for simplicity, using a default or raising an error
        # For this example, let&#x27;s use a default, or the first group&#x27;s C value.
        # In a real scenario, this would depend on the requirements for unseen groups.
        print(f&quot;Warning: Group &#x27;{group}&#x27; not found in fitted parameters. Using a default C value.&quot;)
        C = math.exp(2.0) # Fallback to a default C
    else:
        C = group_C_values[group]

    predictions = []
    for data_point in input_data:
        vocab_size = data_point[&quot;vocab_size&quot;]
        non_vocab_parameters = data_point[&quot;non_vocab_parameters&quot;]
        num_characters = data_point[&quot;num_characters&quot;]

        # Calculate unigram_normalized_loss using the power law formula
        predicted_loss = C * (vocab_size**a) * (non_vocab_parameters**b) * (num_characters**d)
        predictions.append({&quot;unigram_normalized_loss&quot;: predicted_loss})

    return predictions</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
