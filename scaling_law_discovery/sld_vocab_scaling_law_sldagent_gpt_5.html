<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Vocabulary Scaling Law - SLDAgent + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Vocabulary Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">SLDAgent</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.988557 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.986228</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.984955</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.988557 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def _sp(x):
    x = np.asarray(x, float)
    return np.where(x &gt; 20.0, x, np.log1p(np.exp(-np.abs(x))) + np.maximum(x, 0.0))
def _sg(x):
    x = np.asarray(x, float)
    return 1.0 / (1.0 + np.exp(-x))

def scaling_law_func(data_points, params):
    # Lossu = L + A * S * (1 + lam * t^2 / (1 + S))
    # S = exp(a*(log Pref - log P)) + exp(a*(log Cref - log C)), t = log V - v0
    X = np.atleast_2d(np.asarray(data_points, float))
    P, V, C = X[:, 0], X[:, 1], X[:, 2]
    lP = np.log(np.clip(P, 1.0, np.inf))
    lV = np.log(np.clip(V, 1.0, np.inf))
    lC = np.log(np.clip(C, 1.0, np.inf))

    par = np.asarray(params, float)
    if par.ndim == 1:
        L, A, a, Pref, Cref, lam, v0 = par[:7]
        zP = np.log(np.clip(Pref, 1e-30, np.inf))
        zC = np.log(np.clip(Cref, 1e-30, np.inf))
        sP = np.clip(a * (zP - lP), -60.0, 60.0)
        sC = np.clip(a * (zC - lC), -60.0, 60.0)
        S = np.exp(sP) + np.exp(sC)
        Q = 1.0 + S
        t = lV - v0
        return L + A * S * (1.0 + lam * (t * t) / Q)
    else:
        par = par[:, :7]
        L, A, a, Pref, Cref, lam, v0 = [par[:, i] for i in range(7)]
        zP = np.log(np.clip(Pref, 1e-30, np.inf))[:, None]
        zC = np.log(np.clip(Cref, 1e-30, np.inf))[:, None]
        sP = np.clip(a[:, None] * (zP - lP[None, :]), -60.0, 60.0)
        sC = np.clip(a[:, None] * (zC - lC[None, :]), -60.0, 60.0)
        S = np.exp(sP) + np.exp(sC)
        Q = 1.0 + S
        t = lV[None, :] - v0[:, None]
        return (L[:, None] + A[:, None] * S * (1.0 + lam[:, None] * (t * t) / Q)).T

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points, float))
    y_in = np.asarray(loss_values, float)
    Y = y_in[:, None] if y_in.ndim == 1 else y_in
    lP = np.log(np.clip(X[:, 0], 1.0, np.inf))
    lV = np.log(np.clip(X[:, 1], 1.0, np.inf))
    lC = np.log(np.clip(X[:, 2], 1.0, np.inf))

    def sp_inv(x):
        x = max(float(x), 1e-12)
        return np.log(np.expm1(x))

    def solve(yt):
        med = float(np.median(yt))
        mad = 1.4826 * float(np.median(np.abs(yt - med)))
        scale = max(1e-2, mad if (mad &gt; 0 and np.isfinite(mad)) else float(np.std(yt)) + 1e-2)

        L0 = float(np.min(yt) - 0.1)
        A0 = float(max(np.median(yt) - L0, 1.0))
        a0 = 0.5
        zP0, zC0 = float(np.median(lP)), float(np.median(lC))
        lam0 = 0.03
        v00 = float(np.median(lV))

        def raw_to_params(raw):
            L = raw[0]
            A = _sp(raw[1]) + 1e-8
            a = _sp(raw[2]) + 0.05
            zP = raw[3]
            zC = raw[4]
            lam = _sp(raw[5]) + 1e-10
            v0 = raw[6]
            return L, A, a, zP, zC, lam, v0

        def loss_grad(raw):
            L, A, a, zP, zC, lam, v0 = raw_to_params(raw)
            sP = a * (zP - lP); sC = a * (zC - lC)
            sPc = np.clip(sP, -60.0, 60.0); sCc = np.clip(sC, -60.0, 60.0)
            mP = (sP == sPc); mC = (sC == sCc)
            uP = np.exp(sPc); uC = np.exp(sCc)
            S = uP + uC; Q = 1.0 + S
            t = lV - v0; T2 = t * t
            pred = L + A * S * (1.0 + lam * T2 / Q)

            dL = np.ones_like(pred)
            dA = S * (1.0 + lam * T2 / Q)
            dSd = A * (1.0 + lam * T2 / (Q * Q))
            dSP = dSd * uP * mP
            dSC = dSd * uC * mC
            dAlpha = dSP * (zP - lP) + dSC * (zC - lC)
            dzP = dSP * a
            dzC = dSC * a
            dLam = A * S * T2 / Q
            dv0 = -2.0 * A * S * lam * t / Q

            J = np.empty((7, pred.size), float)
            J[0, :] = dL
            J[1, :] = dA * _sg(raw[1])
            J[2, :] = dAlpha * _sg(raw[2])
            J[3, :] = dzP
            J[4, :] = dzC
            J[5, :] = dLam * _sg(raw[5])
            J[6, :] = dv0

            r = pred - yt
            z = r / scale
            loss = (scale ** 2) * float(np.mean(np.log(np.cosh(z))))
            w = (scale / pred.size) * np.tanh(z)

            # mild regularization to stabilize fit
            reg = 1e-7 * (raw[1] ** 2 + raw[2] ** 2 + raw[5] ** 2) \
                + 1e-7 * (raw[6] - v00) ** 2 \
                + 1e-8 * ((raw[3] - zP0) ** 2 + (raw[4] - zC0) ** 2)
            grad_reg = np.array([0.0, 2e-7 * raw[1], 2e-7 * raw[2], 2e-8 * (raw[3] - zP0),
                                 2e-8 * (raw[4] - zC0), 2e-7 * raw[5], 2e-7 * (raw[6] - v00)])

            grad = J @ w + grad_reg
            return loss + reg, grad

        raw0 = np.array([L0, sp_inv(A0), sp_inv(a0 - 0.05), zP0, zC0, sp_inv(lam0), v00], float)
        inits = [
            raw0,
            raw0 + np.array([0.0, 0.4, 0.2, 0.5, -0.5, -0.4, 0.0]),
            raw0 + np.array([0.0, -0.4, -0.2, -0.5, 0.5, 0.4, 0.0]),
            raw0 + np.array([0.0, 0.2, 0.3, 0.2, 0.2, 0.2, 0.0])
        ]

        best_raw, best_val = raw0, np.inf
        f = lambda r: loss_grad(r)[0]
        g = lambda r: loss_grad(r)[1]
        for r0 in inits:
            res = minimize(f, r0, jac=g, method=&#x27;L-BFGS-B&#x27;, options={&#x27;maxiter&#x27;: 600, &#x27;ftol&#x27;: 1e-9})
            val = f(res.x) if res.success else f(r0)
            if val &lt; best_val:
                best_val, best_raw = val, (res.x if res.success else r0)

        L, A, a, zP, zC, lam, v0 = raw_to_params(best_raw)
        return np.array([L, A, a, np.exp(zP), np.exp(zC), lam, v0], float)

    T = Y.shape[1]
    if T == 1:
        return solve(Y[:, 0])
    out = np.zeros((T, 7), float)
    for t in range(T):
        out[t, :] = solve(Y[:, t])
    return out
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.986609 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points))
    P,V,C = X[:,0], X[:,1], X[:,2]
    th = np.asarray(params)
    if th.ndim==1: th = th[None,:]

    def sp(z):
        z = np.asarray(z)
        return np.log1p(np.exp(-np.abs(z))) + np.maximum(z,0.0)  # softplus

    def ecl(z):
        return np.exp(np.clip(z,-80.0,80.0))

    lnP = np.log(np.clip(P,1e-12,None))
    lnC = np.log(np.clip(C,1e-12,None))
    lnV = np.log(np.clip(V,1e-12,None))

    L  = th[:,0]           # asymptotic best Lossu
    A  = sp(th[:,1])       # scale
    a  = sp(th[:,2])       # P exponent
    b  = sp(th[:,3])       # C exponent
    r  = sp(th[:,4])       # trade-off
    v0 = th[:,5]           # optimal lnV center
    g  = sp(th[:,6])       # curvature for vocab

    # Smooth joint saturation: (P^{a/2} + sqrt(r) C^{b/2})^2
    PA2 = ecl(0.5*np.outer(lnP,a))
    CB2 = ecl(0.5*np.outer(lnC,b))
    denom = np.maximum((PA2 + np.sqrt(r)[None,:]*CB2)**2, 1e-12)

    # Multiplicative vocab efficiency on numerator (worse away from v0)
    Vfac = np.exp(np.clip(g[None,:]*(lnV[:,None]-v0[None,:])**2, -30.0, 30.0))

    num = A[None,:]*Vfac
    pred = L[None,:] + num/denom
    return pred[:,0] if th.shape[0]==1 else pred

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values).ravel()
    P,V,C = X[:,0], X[:,1], X[:,2]
    lnP = np.log(np.clip(P,1e-12,None))
    lnC = np.log(np.clip(C,1e-12,None))
    lnV = np.log(np.clip(V,1e-12,None))

    # Seed v0,g via quadratic fit in lnV
    Xq = np.column_stack([np.ones_like(lnV), lnV, lnV**2])
    beta = np.linalg.solve(Xq.T@Xq + 1e-6*np.eye(3), Xq.T@y)
    u0,u1,u2 = map(float,beta)
    if u2&lt;=1e-8:
        v0 = float(np.median(lnV)); g0 = 0.01
    else:
        v0 = float(np.clip(-u1/(2.0*u2), lnV.min(), lnV.max()))
        g0 = max(u2, 1e-3)

    # Seeds for saturation
    a0,b0,r0 = 0.3,0.3,1.0

    # Given initial (a,b,r,v0,g), fit L and A by linear least squares on Z
    def Z_feat(a,b,r,v0,g):
        PA2 = np.exp(np.clip(0.5*lnP*a, -80, 80))
        CB2 = np.exp(np.clip(0.5*lnC*b, -80, 80))
        denom = np.maximum((PA2 + np.sqrt(r)*CB2)**2, 1e-12)
        Vfac = np.exp(np.clip(g*(lnV - v0)**2, -30, 30))
        return Vfac/denom

    Z0 = Z_feat(a0,b0,r0,v0,g0)
    B = np.column_stack([np.ones_like(Z0), Z0])
    th_ls = np.linalg.lstsq(B, y, rcond=None)[0]
    L0, A0raw = map(float, th_ls)
    A0 = max(1e-3, abs(A0raw))

    def sp_inv(u):
        u = max(float(u),1e-12)
        return np.log(np.expm1(u))

    th0 = np.array([L0, sp_inv(A0), sp_inv(a0), sp_inv(b0), sp_inv(r0), v0, sp_inv(g0)], float)

    # Robust Cauchy loss
    mad = np.median(np.abs(y - np.median(y))) + 1e-9
    d = 1.4826*mad

    def obj(th):
        r = scaling_law_func(X, th) - y
        c = np.log1p((r/d)**2)
        reg = 1e-6*(th[0]**2 + th[4]**2 + th[5]**2) + 4e-6*(th[1]**2 + th[2]**2 + th[3]**2 + th[6]**2)
        return np.mean(c) + reg

    best, bestv = th0.copy(), np.inf
    rng = np.random.default_rng(123)
    J = np.array([0.08,0.20,0.20,0.20,0.18,0.06,0.25])
    seeds = [th0] + [th0 + J*rng.standard_normal(7) for _ in range(6)]
    for st in seeds:
        # Refit L and A at start point to reduce bias
        z = Z_feat(np.exp(np.log1p(np.exp(-abs(st[2]))) ),  # a ~ sp(st[2]) approx not available here; use st directly
                   np.exp(np.log1p(np.exp(-abs(st[3]))) ),
                   np.exp(np.log1p(np.exp(-abs(st[4])))),
                   st[5],
                   np.exp(np.log1p(np.exp(-abs(st[6])))))
        B = np.column_stack([np.ones_like(z), z])
        la, aa = np.linalg.lstsq(B, y, rcond=None)[0]
        st2 = st.copy()
        st2[0] = la
        st2[1] = sp_inv(max(1e-3, abs(aa)))
        res = minimize(obj, st2, method=&#x27;L-BFGS-B&#x27;, options=dict(maxiter=700, ftol=1e-10))
        if res.success and res.fun &lt; bestv:
            bestv, best = res.fun, res.x
    if not np.isfinite(bestv):
        res = minimize(obj, th0, method=&#x27;Nelder-Mead&#x27;, options=dict(maxiter=800))
        if res.success: best = res.x
    return best
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.985549 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
import numpy as np

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points, dtype=float))
    P, V, C = X[:,0], X[:,1], X[:,2]
    lp = np.log(np.clip(P,1.0,None)); lv = np.log(np.clip(V,1.0,None)); lc = np.log(np.clip(C,1.0,None))
    r = np.asarray(params, dtype=float).reshape(-1)
    def e(z): return np.exp(np.clip(z, -80.0, 80.0))
    c0, A, a, B, b, Kv0, m = r[0], e(r[1]), e(r[2]), e(r[3]), e(r[4]), e(r[5]), r[6]
    t1 = A * e(-a*lp)
    t2 = B * e(-b*lc)
    g = 0.5*(a + b)
    Kv = Kv0 * e(-g*(lp + lc))
    return c0 + t1 + t2 + Kv * (lv - m)**2

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points, dtype=float))
    y = np.asarray(loss_values, dtype=float).reshape(-1)
    P, V, C = X[:,0], X[:,1], X[:,2]
    lp = np.log(np.clip(P,1.0,None)); lv = np.log(np.clip(V,1.0,None)); lc = np.log(np.clip(C,1.0,None))
    s = lp + lc
    a0 = 0.1; b0 = 0.1; g0 = 0.5*(a0 + b0); m0 = float(np.mean(lv))
    F = np.stack([np.ones_like(lp), np.exp(-a0*lp), np.exp(-b0*lc), np.exp(-g0*s)*(lv - m0)**2], axis=1)
    FtF = F.T@F + 1e-8*np.eye(4); FtY = F.T@y
    try:
        w = np.linalg.solve(FtF, FtY)
    except np.linalg.LinAlgError:
        w = np.linalg.lstsq(F, y, rcond=None)[0]
    c0, Ai, Bi, Kvi = w
    Ai = max(float(Ai),1e-12); Bi = max(float(Bi),1e-12); Kvi = max(float(Kvi),1e-12)
    r = np.array([c0, np.log(Ai), np.log(a0), np.log(Bi), np.log(b0), np.log(Kvi), m0], dtype=float)

    def unpack(rr):
        def e(z): return np.exp(np.clip(z,-50,50))
        return rr[0], e(rr[1]), e(rr[2]), e(rr[3]), e(rr[4]), e(rr[5]), rr[6]

    def pred_jac(rr):
        c0,A,a,B,b,Kv0,m = unpack(rr)
        e1 = np.exp(np.clip(-a*lp,-80,80))
        e2 = np.exp(np.clip(-b*lc,-80,80))
        t1 = A*e1; t2 = B*e2
        g = 0.5*(a+b)
        eg = np.exp(np.clip(-g*s,-80,80))
        Kv = Kv0*eg
        dv = lv - m; dv2 = dv*dv
        yhat = c0 + t1 + t2 + Kv*dv2
        J = np.empty((lp.shape[0],7), float)
        J[:,0] = 1.0
        J[:,1] = t1
        J[:,2] = -a*lp*t1 + (-0.5*s*Kv)*a*dv2
        J[:,3] = t2
        J[:,4] = -b*lc*t2 + (-0.5*s*Kv)*b*dv2
        J[:,5] = Kv*dv2
        J[:,6] = -2.0*Kv*dv
        return yhat, J

    lam = 1e-2
    for _ in range(120):
        yhat, J = pred_jac(r)
        res = y - yhat
        JTJ = J.T@J
        g = J.T@res
        A = JTJ + lam*(np.diag(np.diag(JTJ)) + 1e-12)
        try:
            d = np.linalg.solve(A, g)
        except np.linalg.LinAlgError:
            d = np.linalg.lstsq(A, g, rcond=None)[0]
        r_new = r + d
        yhat_new, _ = pred_jac(r_new)
        if (y - yhat_new @ np.ones_like(yhat_new)).size == 0:  # guard (rare)
            break
        if np.sum((y - yhat_new)**2) &lt; np.sum(res**2):
            r = r_new
            lam *= 0.3
            if np.linalg.norm(d) &lt; 1e-8: break
        else:
            lam *= 8.0
            if lam &gt; 1e12: break
    return r
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.985472 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Lossu scaling with parameter–data synergy and U-shaped vocabulary modulation.

Model (7 params):
  L = L_inf + A / ( (P/P_REF)^alpha + g * (D_eff/C_REF)^beta )
  D_eff = C / (1 + k * (log(V+1) - m)^2)

Parameterization (stability/positivity):
  [0] L_inf, [1] log_A, [2] s_alpha, [3] s_beta, [4] log_g, [5] m, [6] log_k
  alpha = softplus(s_alpha), beta = softplus(s_beta), g = exp(log_g), k = exp(log_k), A = exp(log_A)
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize

_P_REF = 1e8
_C_REF = 1e10
_EPS   = 1e-12

def _softplus(x):
    x = np.asarray(x)
    return np.where(x &gt; 20.0, x, np.log1p(np.exp(x)))

def _inv_softplus(y):
    y = float(max(1e-12, y))
    return np.log(np.exp(y) - 1.0)

def _decode_1d(p):
    p = np.asarray(p).ravel()
    if p.size != 7: raise ValueError(&quot;params must have length 7&quot;)
    return (p[0], np.exp(p[1]), _softplus(p[2]), _softplus(p[3]), np.exp(p[4]), p[5], np.exp(p[6]))

def _decode_2d(P):
    if P.shape[1] != 7: raise ValueError(&quot;params rows must have length 7&quot;)
    return (P[:,0], np.exp(P[:,1]), _softplus(P[:,2]), _softplus(P[:,3]), np.exp(P[:,4]), P[:,5], np.exp(P[:,6]))

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points))
    if X.shape[1] != 3: raise ValueError(&quot;data_points must have shape (N,3)&quot;)
    P, V, C = X[:,0].astype(float), X[:,1].astype(float), X[:,2].astype(float)
    logV = np.log(V + 1.0)
    par = np.asarray(params)
    if par.ndim == 1:
        L0, A, a, b, g, m, k = _decode_1d(par)
        denomV = 1.0 + k * (logV - m)**2
        Deff   = C / (denomV + _EPS)
        Ps = (P / _P_REF) + _EPS
        Ds = (Deff / _C_REF) + _EPS
        return L0 + A / (np.power(Ps, a) + g * np.power(Ds, b) + _EPS)
    elif par.ndim == 2:
        L0, A, a, b, g, m, k = _decode_2d(par)
        Pc, Cc, logVc = P[:,None], C[:,None], logV[:,None]
        denomV = 1.0 + k[None,:] * (logVc - m[None,:])**2
        Deff   = Cc / (denomV + _EPS)
        Ps = (Pc / _P_REF) + _EPS
        Ds = (Deff / _C_REF) + _EPS
        pred = L0[None,:] + A[None,:] / (np.power(Ps, a[None,:]) + g[None,:] * np.power(Ds, b[None,:]) + _EPS)
        return pred if pred.shape[1] &gt; 1 else pred[:,0]
    else:
        raise ValueError(&quot;params must be 1D or 2D array&quot;)

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    if X.shape[1] != 3: raise ValueError(&quot;data_points must have shape (N,3)&quot;)
    Y = y[:,None] if y.ndim == 1 else y
    if Y.shape[0] != X.shape[0]: raise ValueError(&quot;loss_values must align with data_points rows&quot;)

    N = X.shape[0]
    P, V, C = X[:,0].astype(float), X[:,1].astype(float), X[:,2].astype(float)
    logV = np.log(V + 1.0)
    lv_min, lv_max = float(np.min(logV)), float(np.max(logV))
    lv_span = max(1e-6, lv_max - lv_min)

    # Balance vocab groups to prevent dominance by frequent vocab sizes
    uv, cnt = np.unique(V, return_counts=True)
    w_map = dict(zip(uv.tolist(), cnt.tolist()))
    w = np.array([1.0 / w_map[v] for v in V], float)
    w *= N / np.sum(w)

    def huber(r, d):
        a = np.abs(r)
        return np.where(a &lt;= d, 0.5*r*r, d*(a - 0.5*d))

    def phi_from_params(sa, sb, lg, m, lk):
        a = _softplus(sa); b = _softplus(sb)
        g = np.exp(lg);    k = np.exp(lk)
        denomV = 1.0 + k * (logV - m)**2
        Deff   = C / (denomV + _EPS)
        Ps = (P / _P_REF) + _EPS
        Ds = (Deff / _C_REF) + _EPS
        den = np.power(Ps, a) + g * np.power(Ds, b) + _EPS
        return 1.0 / den

    def solve_LA(phi, target):
        sw = np.sqrt(w + _EPS)
        M = np.stack([np.ones_like(phi), phi], 1)
        Mw = sw[:,None] * M
        yw = sw * target
        try:
            theta, _, _, _ = np.linalg.lstsq(Mw, yw, rcond=None)
        except Exception:
            theta = np.array([np.average(target, weights=w), 1e-3], float)
        L, A = float(theta[0]), float(theta[1])
        if A &lt;= 1e-12:
            A = 1e-12
            L = float((np.sum(w*(target - A*phi)) / (np.sum(w) + _EPS)))
        return L, A

    def optimize_column(target):
        ymin, ymax = float(np.min(target)), float(np.max(target))
        med = float(np.median(target))
        mad = float(np.median(np.abs(target - med)) + 1e-8)
        delta = max(0.05, 1.4826 * mad)

        # Seed grid for (m, k) and data/param balance g
        m_grid = np.linspace(lv_min, lv_max, 5)
        k_grid = np.array([0.05, 0.2, 1.0, 5.0, 20.0]) / (lv_span**2 + 1e-12)
        a0, b0 = 0.35, 0.30
        sa0, sb0 = _inv_softplus(a0), _inv_softplus(b0)

        seeds = []
        for m0 in m_grid:
            for lk0 in np.log(k_grid + _EPS):
                # balance g via median branch magnitudes
                denomV = 1.0 + np.exp(lk0) * (logV - m0)**2
                Deff = C / (denomV + _EPS)
                Ps = (P / _P_REF) + _EPS
                Ds = (Deff / _C_REF) + _EPS
                pphi = np.power(Ps, a0); dphi = np.power(Ds, b0)
                g0 = float(np.median(pphi) / (np.median(dphi) + _EPS))
                seeds.append(np.array([sa0, sb0, np.log(max(g0,1e-12)), m0, lk0], float))

        # Score seeds via robust error with closed-form (L_inf, A)
        def score(par5):
            phi = phi_from_params(*par5)
            L, A = solve_LA(phi, target)
            pred = L + A*phi
            return float(np.sum(w * huber(pred - target, delta)) / N)

        seeds.sort(key=score)
        topK = seeds[:6]

        # Local objective only over (s_alpha, s_beta, log_g, m, log_k)
        def obj(par5):
            sa, sb, lg, m, lk = par5
            # mild priors to stabilize exponents, vocab center and width
            a = _softplus(sa); b = _softplus(sb); k = np.exp(lk)
            reg = (1e-4 * ((a - 0.35)**2 + (b - 0.30)**2)
                   + 1e-6 * (np.log(k + 1e-12)**2)
                   + 1e-5 * (max(0.0, m - (lv_max + 0.5))**2 + max(0.0, (lv_min - 0.5) - m)**2))
            phi = phi_from_params(sa, sb, lg, m, lk)
            L, A = solve_LA(phi, target)
            pred = L + A*phi
            loss = np.sum(w * huber(pred - target, delta)) / N
            return loss + reg

        bounds = [
            (None, None),                  # s_alpha
            (None, None),                  # s_beta
            (-20.0, 20.0),                 # log_g
            (lv_min - 1.0, lv_max + 1.0),  # m
            (-20.0, 10.0),                 # log_k
        ]

        rng = np.random.default_rng(2025)
        best_x, best_val = topK[0], obj(topK[0])
        for base in topK:
            for _ in range(3):
                start = base + rng.normal(0, [0.4,0.4,0.4,0.15,0.3])
                res = minimize(obj, start, method=&#x27;L-BFGS-B&#x27;, bounds=bounds, options={&#x27;maxiter&#x27;:700})
                val = res.fun if res.success else obj(res.x)
                if val &lt; best_val: best_val, best_x = val, (res.x if res.success else start)

        # Recover (L_inf, log_A) at optimum via weighted LS
        phi = phi_from_params(*best_x)
        L_opt, A_opt = solve_LA(phi, target)
        return np.array([L_opt, np.log(max(A_opt, 1e-12)), best_x[0], best_x[1], best_x[2], best_x[3], best_x[4]], float)

    T = Y.shape[1]
    pars = np.stack([ optimize_column(Y[:,t]) for t in range(T) ], 0)
    return pars[0] if T == 1 else pars
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.984955 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def _sp(x):
    x = np.asarray(x, float)
    return np.log1p(np.exp(-np.abs(x))) + np.maximum(x, 0.0)

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points, float))
    P, V, C = X[:, 0], X[:, 1], X[:, 2]
    p = np.asarray(params, float).ravel()

    # Params (&lt;=7): [L_inf, raw_Ap, raw_alpha, raw_Ad, raw_beta, raw_k, raw_gamma]
    L_inf = p[0] if p.size &gt; 0 else -2.0
    Ap = _sp(p[1]) + 1e-8 if p.size &gt; 1 else 1.0
    alpha = _sp(p[2]) + 0.05 if p.size &gt; 2 else 0.7
    Ad = _sp(p[3]) + 1e-8 if p.size &gt; 3 else 1.0
    beta = _sp(p[4]) + 0.05 if p.size &gt; 4 else 0.7
    k = _sp(p[5]) + 0.5 if p.size &gt; 5 else 1.0
    gamma = 2.0 * np.tanh((p[6] if p.size &gt; 6 else 0.0) / 2.0)

    # Stable normalizations and vocab-aware effective data
    Pn = np.maximum(P, 1.0) / 1e8
    Vlog = np.log(np.maximum(V, 2.0))
    Vref = np.log(65536.0)
    Deff = np.maximum(C, 1.0) * np.power(np.maximum(Vlog / Vref, 1e-12), gamma)
    Dn = Deff / 1e9

    # Coupled generalized mean: smooth min between params and data contributions
    s1 = np.power(Ap * np.power(Pn, alpha) + 1e-18, 1.0 / k)
    s2 = np.power(Ad * np.power(Dn, beta) + 1e-18, 1.0 / k)
    return L_inf + np.power(s1 + s2 + 1e-18, -k)

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points, float))
    y = np.asarray(loss_values, float).ravel()
    ymin, ymed, ymax = float(np.min(y)), float(np.median(y)), float(np.max(y))

    # Equalize contribution across vocab sizes to improve cross-vocab generalization
    V = X[:, 1]
    uV, inv, cnt = np.unique(V, return_inverse=True, return_counts=True)
    w = 1.0 / cnt[inv]
    w = w / np.sum(w)

    def huber(r, d=0.45):
        a = r / d
        return d * d * (np.sqrt(1.0 + a * a) - 1.0)

    lam_main, lam_gamma = 1e-4, 5e-5
    def objective(p):
        pred = scaling_law_func(X, p)
        if np.any(~np.isfinite(pred)):
            return 1e12
        r = pred - y
        loss = np.sum(w * huber(r, 0.45))
        reg = lam_main * np.sum(p[1:6] * p[1:6]) + (lam_gamma * p[6] * p[6] if p.size &gt; 6 else 0.0)
        return float(loss + reg)

    def sp_inv(t):
        t = float(max(t, 1e-12))
        return np.log(np.expm1(t))
    def spk_inv(kv):
        kv = float(max(kv - 0.5, 1e-12))
        return np.log(np.expm1(kv))

    inits = [
        np.array([ymin - 0.2, sp_inv(1.0), sp_inv(0.7), sp_inv(1.0), sp_inv(0.7), spk_inv(1.0), 0.0]),
        np.array([ymed - 0.5, sp_inv(0.8), sp_inv(0.5), sp_inv(0.8), sp_inv(0.5), spk_inv(0.8), 0.0]),
        np.array([ymin - 0.7, sp_inv(0.9), sp_inv(0.6), sp_inv(1.2), sp_inv(0.9), spk_inv(1.2), 0.8]),
        np.array([ymax - 0.3, sp_inv(1.2), sp_inv(0.9), sp_inv(0.9), sp_inv(0.6), spk_inv(1.2), -0.8]),
        np.array([ymed - 0.3, sp_inv(1.0), sp_inv(0.8), sp_inv(1.0), sp_inv(0.8), spk_inv(1.6), 0.3]),
    ]
    rng = np.random.default_rng(1234)
    for _ in range(2):
        L0 = float(ymed + rng.normal(0, 0.25))
        Ap0 = np.clip(0.6 + rng.normal(0, 0.3), 0.05, 2.0)
        Ad0 = np.clip(0.6 + rng.normal(0, 0.3), 0.05, 2.0)
        al0 = np.clip(0.5 + rng.normal(0, 0.25), 0.1, 1.5)
        be0 = np.clip(0.5 + rng.normal(0, 0.25), 0.1, 1.5)
        k0 = np.clip(1.0 + rng.normal(0, 0.4), 0.6, 2.0)
        g0 = float(np.clip(rng.normal(0, 0.7), -1.5, 1.5))
        inits.append(np.array([L0, sp_inv(Ap0), sp_inv(al0), sp_inv(Ad0), sp_inv(be0), spk_inv(k0), g0]))

    bounds = [(ymin - 2.0, ymax + 2.0)] + [(None, None)] * 6
    best_p, best_f = None, np.inf
    for p0 in inits:
        try:
            res = minimize(objective, p0, method=&quot;L-BFGS-B&quot;, bounds=bounds)
            if res.fun &lt; best_f and np.all(np.isfinite(res.x)):
                best_f, best_p = res.fun, res.x
        except Exception:
            continue

    # Polish with weaker regularization if an optimum was found
    if best_p is not None:
        lam_main, lam_gamma = 5e-5, 1e-5
        try:
            res2 = minimize(objective, best_p, method=&quot;L-BFGS-B&quot;, bounds=bounds)
            if res2.success and np.all(np.isfinite(res2.x)):
                best_p = res2.x
        except Exception:
            pass
        return best_p
    return inits[0]
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
