<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Domain Mixture Scaling Law - codex + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="sld_index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Domain Mixture Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">codex</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.990428 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.933260</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.834132</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.990428 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0">from __future__ import annotations

import math
from typing import Dict, List


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    The law models each domain&#x27;s validation loss as the sum of:
      - a group- and domain-specific intercept a_i,
      - a group- and domain-specific coefficient b_i times log(p_i + eps), capturing
        diminishing returns from allocating more mixture proportion to the same domain,
      - plus a linear combination of the proportions of the other domains (j != i),
        with group- and domain-specific coefficients c_{i,j}.

    Mathematically, for domain i in {1..5}:
        loss_i = a_i + b_i * log(p_i + eps) + sum_{j != i} c_{i,j} * p_j

    where p_k are the mixture proportions (sum_k p_k = 1), and eps is a small constant
    to handle zero proportions inside the logarithm.

    Args:
        input_data: List of dicts with keys &#x27;proportion_domain_1&#x27;..&#x27;proportion_domain_5&#x27;.
        group: One of the experimental groups. The same functional form is used for all
               groups, with coefficients differing per group.

    Returns:
        A list of dicts with keys &#x27;loss_domain_1&#x27;..&#x27;loss_domain_5&#x27;.
    &quot;&quot;&quot;

    # Small constant to avoid log(0)
    EPS = 1e-6

    # Coefficients fitted per group on the provided dataset (/app/data), using the
    # model: loss_i = a_i + b_i * log(p_i + EPS) + sum_{j != i} c_{i,j} * p_j
    # For convenience, linear coefficients are stored as a full 5-length vector per domain
    # with 0.0 for the self-domain (j == i) entry.
    COEFFS = {
        &quot;70M&quot;: {
            1: {&quot;a&quot;: 2.352400, &quot;b&quot;: -0.041342, &quot;c&quot;: [0.000000, 0.552302, 0.679733, 0.457510, 0.478500]},
            2: {&quot;a&quot;: 3.119185, &quot;b&quot;: -0.005609, &quot;c&quot;: [0.733329, 0.000000, 0.567223, 0.760307, 0.571576]},
            3: {&quot;a&quot;: 1.557687, &quot;b&quot;: -0.029500, &quot;c&quot;: [1.776484, 1.574088, 0.000000, 1.672027, 1.590520]},
            4: {&quot;a&quot;: 1.005729, &quot;b&quot;: -0.040741, &quot;c&quot;: [0.682161, 0.804593, 0.768164, 0.000000, 0.680742]},
            5: {&quot;a&quot;: 3.401418, &quot;b&quot;: -0.019938, &quot;c&quot;: [0.282951, 0.204621, 0.280657, 0.244292, 0.000000]},
        },
        &quot;160M&quot;: {
            1: {&quot;a&quot;: 2.084419, &quot;b&quot;: -0.039436, &quot;c&quot;: [0.000000, 0.515541, 0.590549, 0.410446, 0.414215]},
            2: {&quot;a&quot;: 2.848965, &quot;b&quot;: -0.005760, &quot;c&quot;: [0.664815, 0.000000, 0.533358, 0.698111, 0.486927]},
            3: {&quot;a&quot;: 1.375788, &quot;b&quot;: -0.028472, &quot;c&quot;: [1.645880, 1.472320, 0.000000, 1.592583, 1.466833]},
            4: {&quot;a&quot;: 0.822570, &quot;b&quot;: -0.036176, &quot;c&quot;: [0.633280, 0.747330, 0.680942, 0.000000, 0.623930]},
            5: {&quot;a&quot;: 3.044954, &quot;b&quot;: -0.020112, &quot;c&quot;: [0.288934, 0.234711, 0.313982, 0.265677, 0.000000]},
        },
        &quot;305M&quot;: {
            1: {&quot;a&quot;: 1.965386, &quot;b&quot;: -0.039011, &quot;c&quot;: [0.000000, 0.461256, 0.591688, 0.362942, 0.378769]},
            2: {&quot;a&quot;: 2.675656, &quot;b&quot;: -0.004898, &quot;c&quot;: [0.681773, 0.000000, 0.558797, 0.717652, 0.506549]},
            3: {&quot;a&quot;: 1.389474, &quot;b&quot;: -0.030900, &quot;c&quot;: [1.455301, 1.326467, 0.000000, 1.424874, 1.288538]},
            4: {&quot;a&quot;: 0.758123, &quot;b&quot;: -0.034855, &quot;c&quot;: [0.586244, 0.671620, 0.645107, 0.000000, 0.580221]},
            5: {&quot;a&quot;: 2.880988, &quot;b&quot;: -0.021162, &quot;c&quot;: [0.278675, 0.225879, 0.321137, 0.249162, 0.000000]},
        },
        &quot;410M&quot;: {
            1: {&quot;a&quot;: 1.904173, &quot;b&quot;: -0.038724, &quot;c&quot;: [0.000000, 0.497929, 0.520547, 0.389682, 0.371875]},
            2: {&quot;a&quot;: 2.648743, &quot;b&quot;: -0.005145, &quot;c&quot;: [0.632228, 0.000000, 0.458498, 0.688205, 0.451025]},
            3: {&quot;a&quot;: 1.311117, &quot;b&quot;: -0.031575, &quot;c&quot;: [1.474932, 1.346313, 0.000000, 1.429078, 1.297670]},
            4: {&quot;a&quot;: 0.726224, &quot;b&quot;: -0.033638, &quot;c&quot;: [0.560347, 0.717670, 0.657147, 0.000000, 0.569629]},
            5: {&quot;a&quot;: 2.802291, &quot;b&quot;: -0.021963, &quot;c&quot;: [0.276436, 0.261534, 0.247464, 0.274675, 0.000000]},
        },
    }

    # Fallback: if an unknown group is provided, use the closest available group
    # by parameterization (default to the smallest model &quot;70M&quot;).
    params_by_group = COEFFS.get(group)
    if params_by_group is None:
        params_by_group = COEFFS[&quot;70M&quot;]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        # Read proportions in a fixed order
        p = [float(row.get(f&quot;proportion_domain_{i}&quot;, 0.0)) for i in range(1, 6)]
        # Normalize defensively in case inputs are not perfectly normalized
        s = sum(p)
        if s &gt; 0:
            p = [pi / s for pi in p]

        pred: Dict[str, float] = {}
        for i in range(1, 6):
            par = params_by_group[i]
            a = par[&quot;a&quot;]
            b = par[&quot;b&quot;]
            c = par[&quot;c&quot;]  # length-5, zero at index i-1
            log_term = math.log(max(p[i - 1], 0.0) + EPS)
            linear_term = sum(c[j] * p[j] for j in range(5))
            y = a + b * log_term + linear_term
            pred[f&quot;loss_domain_{i}&quot;] = float(y)

        outputs.append(pred)

    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.971446 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1">from __future__ import annotations

import math
from typing import Dict, List


# Shared per-domain offset to make log well-defined at zero proportion.
# Selected via cross-group grid search to maximize average R^2.
_C_BY_DOMAIN: Dict[int, float] = {
    1: 0.003125,
    2: 0.0046875,
    3: 0.0015625,
    4: 0.003125,
    5: 0.0234375,
}

# Per-group, per-domain coefficients for the law:
#   loss_domain_i = a[g,i] + b[g,i] * log(proportion_domain_i + C[i])
_COEFS_BY_GROUP: Dict[str, Dict[int, Dict[str, float]]] = {
    &quot;160M&quot;: {
        1: {&quot;a&quot;: 2.2424684059708717, &quot;b&quot;: -0.1412039367794934},
        2: {&quot;a&quot;: 3.2541456054570035, &quot;b&quot;: -0.0405858087415962},
        3: {&quot;a&quot;: 2.567113771294527, &quot;b&quot;: -0.11102183824132524},
        4: {&quot;a&quot;: 1.167057464525046, &quot;b&quot;: -0.1374903829439023},
        5: {&quot;a&quot;: 3.085896059150068, &quot;b&quot;: -0.13693966564752397},
    },
    &quot;305M&quot;: {
        1: {&quot;a&quot;: 2.101566717029658, &quot;b&quot;: -0.137250480526824},
        2: {&quot;a&quot;: 3.0994046220334157, &quot;b&quot;: -0.03855781421113323},
        3: {&quot;a&quot;: 2.4128405334920684, &quot;b&quot;: -0.11468007010082179},
        4: {&quot;a&quot;: 1.0709224798061698, &quot;b&quot;: -0.13158540389099785},
        5: {&quot;a&quot;: 2.918730301818813, &quot;b&quot;: -0.13736039699677574},
    },
    &quot;410M&quot;: {
        1: {&quot;a&quot;: 2.0433633841009002, &quot;b&quot;: -0.1355817799554127},
        2: {&quot;a&quot;: 3.0302311023376722, &quot;b&quot;: -0.03717104079844086},
        3: {&quot;a&quot;: 2.341569758388262, &quot;b&quot;: -0.11681678106085443},
        4: {&quot;a&quot;: 1.0375379829435523, &quot;b&quot;: -0.1281673168777551},
        5: {&quot;a&quot;: 2.841139982418687, &quot;b&quot;: -0.14126939233946334},
    },
    &quot;70M&quot;: {
        1: {&quot;a&quot;: 2.538957210154492, &quot;b&quot;: -0.15195781604593908},
        2: {&quot;a&quot;: 3.5809102439444924, &quot;b&quot;: -0.044369404452315006},
        3: {&quot;a&quot;: 2.8462143926943795, &quot;b&quot;: -0.11662362761003567},
        4: {&quot;a&quot;: 1.3734832511282675, &quot;b&quot;: -0.15423705944877764},
        5: {&quot;a&quot;: 3.4370247988143974, &quot;b&quot;: -0.13346648082051366},
    },
}

# Fallback coefficients (mean across groups) used if an unknown group is provided.
_FALLBACK_COEFS: Dict[int, Dict[str, float]] = {
    1: {&quot;a&quot;: 2.231588929313981, &quot;b&quot;: -0.1414985033269173},
    2: {&quot;a&quot;: 3.2411728934431463, &quot;b&quot;: -0.040171017050871324},
    3: {&quot;a&quot;: 2.5419346139673094, &quot;b&quot;: -0.11478557925325927},
    4: {&quot;a&quot;: 1.162250294600759, &quot;b&quot;: -0.13787004079035822},
    5: {&quot;a&quot;: 3.0706977855504913, &quot;b&quot;: -0.13725898395106917},
}


def _predict_for_row(row: Dict[str, float], coefs: Dict[int, Dict[str, float]]) -&gt; Dict[str, float]:
    out: Dict[str, float] = {}
    for i in range(1, 6):
        p = float(row.get(f&quot;proportion_domain_{i}&quot;, 0.0))
        c = _C_BY_DOMAIN[i]
        a = coefs[i][&quot;a&quot;]
        b = coefs[i][&quot;b&quot;]
        # Numerically safe log with small positive offset.
        pred = a + b * math.log(max(p, 0.0) + c)
        out[f&quot;loss_domain_{i}&quot;] = float(pred)
    return out


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coefs = _COEFS_BY_GROUP.get(group, _FALLBACK_COEFS)
    return [_predict_for_row(row, coefs) for row in input_data]</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.971092 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2"># Discovered scaling law (shared functional form across groups):
#   loss_domain_k = a_{g,k} + b_{g,k} * (proportion_domain_k + c_{g,k}) ** d_{g,k}
# where g indexes the experimental group and k in {1..5} indexes the domain.


# Fitted parameters per group and per domain (k = 1..5).
# Values were obtained by least squares fitting on the provided dataset.
_PARAMS = {
    &quot;160M&quot;: {
        &quot;domain_1&quot;: {&quot;a&quot;: 3.118296598901631, &quot;b&quot;: -0.8877441483834596, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.2},
        &quot;domain_2&quot;: {&quot;a&quot;: 3.3016069560703,   &quot;b&quot;:  0.0018261061960447534, &quot;c&quot;: 0.09183755102040818, &quot;d&quot;: -1.9},
        &quot;domain_3&quot;: {&quot;a&quot;: 3.312678979117116, &quot;b&quot;: -0.8785517989680411, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.25},
        &quot;domain_4&quot;: {&quot;a&quot;: 1.0034194693515974, &quot;b&quot;: 0.24243472606360897, &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: -0.3},
        &quot;domain_5&quot;: {&quot;a&quot;: 4.118698802652438, &quot;b&quot;: -1.040736728854194,  &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: 0.15},
    },
    &quot;305M&quot;: {
        &quot;domain_1&quot;: {&quot;a&quot;: 2.952929420274062, &quot;b&quot;: -0.8629898487399583, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.2},
        &quot;domain_2&quot;: {&quot;a&quot;: 3.127318377480758, &quot;b&quot;:  0.007202777918698585, &quot;c&quot;: 0.061225367346938786, &quot;d&quot;: -1.15},
        &quot;domain_3&quot;: {&quot;a&quot;: 3.207800159763377, &quot;b&quot;: -0.8322110176673488, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.2},
        &quot;domain_4&quot;: {&quot;a&quot;: 0.9142458490282026, &quot;b&quot;: 0.23205050091886964, &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: -0.3},
        &quot;domain_5&quot;: {&quot;a&quot;: 0.2308748803753971, &quot;b&quot;: 2.689570473211351,  &quot;c&quot;: 0.030613183673469394, &quot;d&quot;: -0.05},
    },
    &quot;410M&quot;: {
        &quot;domain_1&quot;: {&quot;a&quot;: 2.884545514793264, &quot;b&quot;: -0.852803939078441,  &quot;c&quot;: 1e-06, &quot;d&quot;: 0.2},
        &quot;domain_2&quot;: {&quot;a&quot;: 3.0790530221595462, &quot;b&quot;: 0.001307985468446201, &quot;c&quot;: 0.07142942857142857, &quot;d&quot;: -1.8},
        &quot;domain_3&quot;: {&quot;a&quot;: 3.151353366782936, &quot;b&quot;: -0.8477484549673475, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.2},
        &quot;domain_4&quot;: {&quot;a&quot;: 0.884948385285892, &quot;b&quot;: 0.22601551215198246, &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: -0.3},
        &quot;domain_5&quot;: {&quot;a&quot;: 4.3056179059111725, &quot;b&quot;: -1.4673725683803218, &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: 0.1},
    },
    &quot;70M&quot;: {
        &quot;domain_1&quot;: {&quot;a&quot;: 2.00061995681349,  &quot;b&quot;: 0.5657494904538474,  &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: -0.2},
        &quot;domain_2&quot;: {&quot;a&quot;: 3.6141195606157925, &quot;b&quot;: 0.00530072540335944, &quot;c&quot;: 0.10204161224489797, &quot;d&quot;: -1.6},
        &quot;domain_3&quot;: {&quot;a&quot;: 3.6293616626237855, &quot;b&quot;: -0.9227693166043902, &quot;c&quot;: 1e-06, &quot;d&quot;: 0.25},
        &quot;domain_4&quot;: {&quot;a&quot;: 1.1898035159399545, &quot;b&quot;: 0.2720101134529132, &quot;c&quot;: 0.010205061224489796, &quot;d&quot;: -0.3},
        &quot;domain_5&quot;: {&quot;a&quot;: 3.249380658214184,  &quot;b&quot;: 0.2049354477567703,  &quot;c&quot;: 0.11224567346938777, &quot;d&quot;: -0.55},
    },
}

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Select parameters for the group; if unseen, use average across known groups.
    if group in _PARAMS:
        params = _PARAMS[group]
    else:
        domains = [f&quot;domain_{i}&quot; for i in range(1, 6)]
        params = {}
        for d in domains:
            acc = {&quot;a&quot;: 0.0, &quot;b&quot;: 0.0, &quot;c&quot;: 0.0, &quot;d&quot;: 0.0}
            for g in _PARAMS.values():
                pd = g[d]
                acc[&quot;a&quot;] += pd[&quot;a&quot;]
                acc[&quot;b&quot;] += pd[&quot;b&quot;]
                acc[&quot;c&quot;] += pd[&quot;c&quot;]
                acc[&quot;d&quot;] += pd[&quot;d&quot;]
            n = float(len(_PARAMS))
            params[d] = {k: v / n for k, v in acc.items()}

    outputs: list[dict[str, float]] = []
    for row in input_data:
        out: dict[str, float] = {}
        for k in range(1, 6):
            p = float(row.get(f&quot;proportion_domain_{k}&quot;, 0.0))
            par = params[f&quot;domain_{k}&quot;]
            a, b, c, d = par[&quot;a&quot;], par[&quot;b&quot;], par[&quot;c&quot;], par[&quot;d&quot;]
            # Ensure numerical stability for zero proportions
            pred = a + b * (p + c) ** d
            out[f&quot;loss_domain_{k}&quot;] = float(pred)
        outputs.append(out)
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.899201 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict, List


# Per-group, per-target coefficients fitted on /app/data using OLS.
# Model: loss_k = b0 + sum_j b_j * log(proportion_j + eps)
_EPS = 1e-6
_COEFS: Dict[str, Dict[int, List[float]]] = {
    &quot;160M&quot;: {
        1: [
            2.4042025803406553,
            -0.04878456902733,
            -0.001374141990715709,
            0.00425143168670042,
            -0.004036425589256114,
            0.007660516801797778,
        ],
        2: [
            3.329935868696654,
            0.002613273350161564,
            -0.011891996557419415,
            2.5572674116154508e-05,
            0.003256629390122456,
            -0.005952205705195364,
        ],
        3: [
            2.8006343825165314,
            0.0038463371713819104,
            0.0010271048724917586,
            -0.03834514983761013,
            0.003370871701657902,
            -0.004992444549614571,
        ],
        4: [
            1.3842254371292473,
            0.0001770125184695076,
            0.0019008052563317707,
            0.00040985897229494966,
            -0.04321725706040489,
            0.005203775943861618,
        ],
        5: [
            3.22070848376419,
            0.005681276339156933,
            0.004826630941776033,
            -0.00156340623248917,
            0.005473022220321205,
            -0.030039287316337895,
        ],
    },
    &quot;305M&quot;: {
        1: [
            2.254097761686427,
            -0.047618308465165196,
            -0.0013550046237553216,
            0.004003192579882288,
            -0.0042909223510698554,
            0.006758159630738282,
        ],
        2: [
            3.166848403701224,
            0.0023474329227610603,
            -0.011422287483401284,
            4.890168638858063e-06,
            0.0026987505976661923,
            -0.006498741023938888,
        ],
        3: [
            2.6500359123770685,
            0.0035548451771600445,
            0.0011888369505355075,
            -0.03964115398330717,
            0.0028959099742507494,
            -0.004828358464409514,
        ],
        4: [
            1.2751944568968825,
            -0.00024923215104993846,
            0.0015693015233153626,
            0.0004352251902864513,
            -0.041431801189773,
            0.00487564464080058,
        ],
        5: [
            3.0477226649403506,
            0.005424541586794049,
            0.004752807485933067,
            -0.0015473014680650466,
            0.004775541162988269,
            -0.030879417992197157,
        ],
    },
    &quot;410M&quot;: {
        1: [
            2.1969109104720936,
            -0.04711053566759858,
            -0.0005929598868873091,
            0.0032935545744610275,
            -0.0034299883497122844,
            0.006245418652814477,
        ],
        2: [
            3.096774846113359,
            0.002683578481767577,
            -0.01079532012122322,
            -0.0006061709329291659,
            0.003289915492216653,
            -0.007059325448456723,
        ],
        3: [
            2.5854698484676923,
            0.0036493802056689617,
            0.0014981486567392278,
            -0.04057579585320029,
            0.003422309711002145,
            -0.005304641068008599,
        ],
        4: [
            1.2374283294627488,
            -0.0007019754734980677,
            0.0023220834389344196,
            0.00022483249867104974,
            -0.040255057354183485,
            0.0043998574943246395,
        ],
        5: [
            2.9734625677861892,
            0.005474979456664107,
            0.005292433569369652,
            -0.0021983339298417347,
            0.005328130514437292,
            -0.031848404298810445,
        ],
    },
    &quot;70M&quot;: {
        1: [
            2.709753097020149,
            -0.05223448519596348,
            -0.002096832291136182,
            0.0049309629806633245,
            -0.005121637241168704,
            0.008582633603168494,
        ],
        2: [
            3.6589940901202946,
            0.0024594854221674217,
            -0.013037306540415955,
            0.00018013301869309603,
            0.0025694674548725075,
            -0.0055192991657138785,
        ],
        3: [
            3.0882519411499176,
            0.004138978755961604,
            0.000999612740187218,
            -0.040138664176247195,
            0.002610113875372775,
            -0.00489486237526904,
        ],
        4: [
            1.6123830068952152,
            -0.0002626923872205353,
            0.001840626589019361,
            0.0004871656033250259,
            -0.048580221686945084,
            0.0053741041526707105,
        ],
        5: [
            3.567736623439916,
            0.005906206376564464,
            0.00463119283202685,
            -0.0015851069219014631,
            0.004999662780701288,
            -0.029220774259506147,
        ],
    },
}


def _predict_row(props: List[float], coefs: List[float]) -&gt; float:
    # coefs: [b0, b1..b5], props: [p1..p5]
    x = [1.0] + [math.log(max(p, 0.0) + _EPS) for p in props]
    return sum(c * xi for c, xi in zip(coefs, x))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Choose coefficients for the requested group; if unseen, fall back to the
    # average of known groups to remain robust.
    if group in _COEFS:
        group_coefs = _COEFS[group]
    else:
        # Average coefficients across groups
        group_coefs = {}
        for k in range(1, 6):
            # Collect coefs per group for this k
            mats = [v[k] for v in _COEFS.values()]
            avg = [sum(col) / len(mats) for col in zip(*mats)]
            group_coefs[k] = avg

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        props = [
            float(row.get(f&quot;proportion_domain_{i}&quot;, 0.0)) for i in range(1, 6)
        ]
        pred = {}
        for k in range(1, 6):
            yk = _predict_row(props, group_coefs[k])
            pred[f&quot;loss_domain_{k}&quot;] = float(yk)
        outputs.append(pred)
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.834132 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4">from __future__ import annotations
import math
from typing import Dict, List


# Coefficients fitted on the provided dataset using
# least squares for the model:
#   loss_domain_i = c_{g,i} + b_{g,i} * log(1 / (proportion_domain_i + eps))
# where g is the experimental group.
_COEFFS: Dict[str, Dict[int, tuple[float, float]]] = {
    &quot;160M&quot;: {
        1: (2.437447, 0.022863),
        2: (3.321687, 0.005456),
        3: (2.834681, 0.016343),
        4: (1.410384, 0.020125),
        5: (3.155392, 0.016970),
    },
    &quot;305M&quot;: {
        1: (2.290583, 0.022284),
        2: (3.163720, 0.005168),
        3: (2.688818, 0.016917),
        4: (1.303708, 0.019271),
        5: (2.988093, 0.017195),
    },
    &quot;410M&quot;: {
        1: (2.229470, 0.022088),
        2: (3.091907, 0.005016),
        3: (2.622653, 0.017235),
        4: (1.264438, 0.018752),
        5: (2.912269, 0.017788),
    },
    &quot;70M&quot;: {
        1: (2.750293, 0.024420),
        2: (3.655117, 0.005927),
        3: (3.127444, 0.017154),
        4: (1.646486, 0.022572),
        5: (3.504848, 0.016495),
    },
}


def _get_group_coeffs(group: str) -&gt; Dict[int, tuple[float, float]]:
    &quot;&quot;&quot;Return per-domain (c, b) coefficients for the given group.

    If the group is unknown, fall back to the average of known groups.
    &quot;&quot;&quot;
    if group in _COEFFS:
        return _COEFFS[group]
    # Fallback: average coefficients across all known groups
    avg: Dict[int, List[float]] = {i: [0.0, 0.0] for i in range(1, 6)}
    n = float(len(_COEFFS))
    for g in _COEFFS.values():
        for i in range(1, 6):
            c, b = g[i]
            avg[i][0] += c / n
            avg[i][1] += b / n
    return {i: (avg[i][0], avg[i][1]) for i in range(1, 6)}


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coeffs = _get_group_coeffs(group)
    eps = 1e-9

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        pred: Dict[str, float] = {}
        for i in range(1, 6):
            q = float(row.get(f&quot;proportion_domain_{i}&quot;, 0.0))
            c, b = coeffs[i]
            pred[f&quot;loss_domain_{i}&quot;] = c + b * math.log(1.0 / (q + eps))
        outputs.append(pred)
    return outputs</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
