<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - LR & Batch Size Scaling Law - codex + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="sld_index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>LR & Batch Size Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">codex</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #daa520; color: white"> 0.545767 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">-0.039211</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">-1.000000</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #daa520; color: white"> R² = 0.545767 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0">from __future__ import annotations

import math
from typing import Dict, List


# Coefficients learned on the provided dataset for group &#x27;all_data&#x27;.
# Feature order:
# [1, x1, x2, x3, x4, x1^2, x2^2, x3^2, x4^2, x1*x2, x1*x3, x1*x4, x2*x3, x2*x4, x3*x4]
_COEFS_BY_GROUP: Dict[str, List[float]] = {
    &quot;all_data&quot;: [
        15.408655757208578,
        0.1479904624134041,
        0.925576816730592,
        -2.0155807017749745,
        -0.21074365992568728,
        0.1445807182504939,
        0.12570943660274597,
        0.13477282782648167,
        0.07811997175906828,
        -0.0778445730877946,
        -0.02359921758963033,
        0.1304365497600781,
        -0.12590176704259384,
        -0.050041748839094104,
        -0.09213648452069143,
    ]
}


def _predict_single(sample: Dict[str, float], coefs: List[float]) -&gt; float:
    # Extract inputs
    lr = float(sample.get(&quot;lr&quot;, 0.0))
    bsz = float(sample.get(&quot;bsz&quot;, 0.0))
    data_size = float(sample.get(&quot;data_size&quot;, 0.0))
    non_embed_params = float(sample.get(&quot;non_embedding_param_size&quot;, 0.0))

    # Guard against non-positive values before log
    eps = 1e-300
    x1 = math.log10(max(lr, eps))
    x2 = math.log10(max(bsz, eps))
    x3 = math.log10(max(data_size, eps))
    x4 = math.log10(max(non_embed_params, eps))

    # Build feature vector in the fixed order
    feats = [
        1.0,
        x1,
        x2,
        x3,
        x4,
        x1 * x1,
        x2 * x2,
        x3 * x3,
        x4 * x4,
        x1 * x2,
        x1 * x3,
        x1 * x4,
        x2 * x3,
        x2 * x4,
        x3 * x4,
    ]

    # Linear combination
    pred = 0.0
    for f, c in zip(feats, coefs):
        pred += f * c
    return float(pred)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Select coefficient set; default to &#x27;all_data&#x27; when group is unknown
    coefs = _COEFS_BY_GROUP.get(group, _COEFS_BY_GROUP[&quot;all_data&quot;]) 
    outputs: List[Dict[str, float]] = []
    for row in input_data:
        lm_loss = _predict_single(row, coefs)
        outputs.append({&quot;lm_loss&quot;: lm_loss})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #d2691e; color: white"> R² = 0.353284 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1">from typing import List, Dict
import math


def _features(example: Dict[str, float]) -&gt; List[float]:
    &quot;&quot;&quot;Construct quadratic features in log-space for the scaling law.&quot;&quot;&quot;
    x1 = math.log10(float(example[&quot;lr&quot;]))
    x2 = math.log10(float(example[&quot;bsz&quot;]))
    x3 = math.log10(float(example[&quot;data_size&quot;]))
    x4 = math.log10(float(example[&quot;non_embedding_param_size&quot;]))

    return [
        1.0,
        x1,
        x2,
        x3,
        x4,
        x1 * x1,
        x2 * x2,
        x3 * x3,
        x4 * x4,
        x1 * x2,
        x1 * x3,
        x1 * x4,
        x2 * x3,
        x2 * x4,
        x3 * x4,
    ]


# Per-group coefficients for the quadratic-in-log model
# y = sum_i c[i] * feature[i]
_COEFFICIENTS: Dict[str, List[float]] = {
    # Fitted on /app/data (2702 rows)
    # Metrics (fit on all data): R2 ≈ 0.9766, MAE ≈ 0.0198, RMSE ≈ 0.0303
    &quot;all_data&quot;: [
        16.8138888600552,
        0.2624254210535559,
        0.9049176633537738,
        -2.142260361099579,
        -0.34899273153026433,
        0.14853075100299007,
        0.12695557272351365,
        0.13573629866090617,
        0.07862980741271874,
        -0.08196050004815598,
        -0.024765714838695822,
        0.12229811653279878,
        -0.12308842768445863,
        -0.05300037765711738,
        -0.08069891827953539,
    ],
}


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fallback to a default set of coefficients if an unknown group is provided.
    # This preserves a single functional form while allowing per-group constants.
    coeffs = _COEFFICIENTS.get(group) or _COEFFICIENTS.get(&quot;all_data&quot;)
    if coeffs is None:
        raise ValueError(f&quot;No coefficients available for group &#x27;{group}&#x27;.&quot;)

    outputs: List[Dict[str, float]] = []
    for ex in input_data:
        phi = _features(ex)
        # Dot product between features and coefficients
        y_hat = 0.0
        for c, f in zip(coeffs, phi):
            y_hat += c * f
        outputs.append({&quot;lm_loss&quot;: float(y_hat)})

    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #b22222; color: white"> R² = -0.015989 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2">import math
from typing import Dict, List


# Coefficients fitted on the provided dataset (group: &#x27;all_data&#x27;).
# Model form:
#   lm_loss = c0
#             + c1 * log10(lr)
#             + c2 * (log10(lr))^2
#             + c3 * log10(bsz)
#             + c4 * log10(data_size)
#             + c5 * log10(non_embedding_param_size)
COEFS: Dict[str, List[float]] = {
    &quot;all_data&quot;: [
        9.0203054787606,    # c0 (intercept)
        0.7770969500785967, # c1 (log10(lr))
        0.1340372639030306, # c2 (log10(lr))^2
        0.0006034889974823782, # c3 (log10(bsz))
        -0.2813035622782266,   # c4 (log10(data_size))
        -0.3027047341882954,   # c5 (log10(non_embedding_param_size))
    ]
}


def _predict_single(row: Dict[str, float], coefs: List[float]) -&gt; float:
    eps = 1e-12
    c0, c1, c2, c3, c4, c5 = coefs

    lr = max(float(row.get(&quot;lr&quot;, 0.0)), eps)
    bsz = max(float(row.get(&quot;bsz&quot;, 0.0)), eps)
    data_size = max(float(row.get(&quot;data_size&quot;, 0.0)), eps)
    params = max(float(row.get(&quot;non_embedding_param_size&quot;, 0.0)), eps)

    llr = math.log10(lr)
    lbsz = math.log10(bsz)
    ldata = math.log10(data_size)
    lparams = math.log10(params)

    return (
        c0
        + c1 * llr
        + c2 * (llr ** 2)
        + c3 * lbsz
        + c4 * ldata
        + c5 * lparams
    )


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys are: &#x27;lr&#x27;, &#x27;bsz&#x27;,
                    &#x27;data_size&#x27;, and &#x27;non_embedding_param_size&#x27;.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fallback to &#x27;all_data&#x27; coefficients if the provided group is unknown.
    coefs = COEFS.get(group, COEFS[&quot;all_data&quot;])

    outputs: list[dict[str, float]] = []
    for row in input_data:
        y = _predict_single(row, coefs)
        outputs.append({&quot;lm_loss&quot;: float(y)})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #b22222; color: white"> R² = -0.079115 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict, List


# Quadratic-in-logs scaling law fitted on the provided dataset.
# Variables (natural log):
#   x_lr = ln(lr)
#   x_b  = ln(bsz)
#   x_d  = ln(data_size)
#   x_n  = ln(non_embedding_param_size)
# Features order:
#   [x_lr, x_b, x_d, x_n,
#    x_lr^2, x_b^2, x_d^2, x_n^2,
#    x_lr*x_b, x_lr*x_d, x_lr*x_n,
#    x_b*x_d, x_b*x_n, x_d*x_n]


# Group-specific coefficients (same functional form across groups).
# Trained group available in the dataset: &quot;all_data&quot;.
# If an unseen group is requested, we fall back to &quot;all_data&quot;.
COEFFICIENTS: Dict[str, Dict[str, List[float]]] = {
    &quot;all_data&quot;: {
        &quot;intercept&quot;: [9.845717554648825],
        &quot;coefs&quot;: [
            # linear terms
            0.06750242463128774,      # x_lr
            0.28796007724354983,      # x_b
            -0.40647200488009333,     # x_d
            -0.042787852040177925,    # x_n
            # squares
            0.02725586768292816,      # x_lr^2
            0.02407125998953225,      # x_b^2
            0.019730879533995164,     # x_d^2
            0.01893085387016256,      # x_n^2
            # interactions
            -0.014007732297484152,    # x_lr*x_b
            -0.0041614490016316195,   # x_lr*x_d
            0.023898037701275493,     # x_lr*x_n
            -0.022390145708785815,    # x_b*x_d
            -0.0052130124893074985,   # x_b*x_n
            -0.02799258320900191,     # x_d*x_n
        ],
    }
}


def _predict_single(sample: Dict[str, float], params: Dict[str, List[float]]) -&gt; float:
    # Extract and validate inputs
    try:
        lr = float(sample[&quot;lr&quot;])  # learning rate
        bsz = float(sample[&quot;bsz&quot;])  # batch size
        data_size = float(sample[&quot;data_size&quot;])  # tokens/examples seen
        n_params = float(sample[&quot;non_embedding_param_size&quot;])  # non-embedding params
    except KeyError as e:
        raise KeyError(f&quot;Missing required key: {e}&quot;)

    if lr &lt;= 0 or bsz &lt;= 0 or data_size &lt;= 0 or n_params &lt;= 0:
        raise ValueError(&quot;All inputs must be positive to compute logarithms.&quot;)

    x_lr = math.log(lr)
    x_b = math.log(bsz)
    x_d = math.log(data_size)
    x_n = math.log(n_params)

    # Construct feature vector in the fixed order
    feats = [
        x_lr, x_b, x_d, x_n,
        x_lr * x_lr,
        x_b * x_b,
        x_d * x_d,
        x_n * x_n,
        x_lr * x_b,
        x_lr * x_d,
        x_lr * x_n,
        x_b * x_d,
        x_b * x_n,
        x_d * x_n,
    ]

    coefs = params[&quot;coefs&quot;]
    intercept = params[&quot;intercept&quot;][0]
    pred = intercept + sum(c * f for c, f in zip(coefs, feats))
    return float(pred)


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Must include keys: &#x27;lr&#x27;, &#x27;bsz&#x27;,
                    &#x27;data_size&#x27;, and &#x27;non_embedding_param_size&#x27;. All values must be positive.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups, but
                the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s): {&#x27;lm_loss&#x27;: float}.
    &quot;&quot;&quot;

    # Choose group parameters, fallback to &#x27;all_data&#x27; if unknown
    params = COEFFICIENTS.get(group)
    if params is None:
        params = COEFFICIENTS[&quot;all_data&quot;]

    outputs: List[Dict[str, float]] = []
    for sample in input_data:
        y = _predict_single(sample, params)
        outputs.append({&quot;lm_loss&quot;: y})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #b22222; color: white"> R² = -1.000000 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4">from __future__ import annotations

from math import log
from typing import Dict, List


# Discovered scaling-law functional form (shared across groups):
# Let x1 = log(lr), x2 = log(bsz), x3 = log(data_size), x4 = log(non_embedding_param_size).
#   lm_loss = c0
#             + c1*x1 + c2*x2 + c3*x3 + c4*x4
#             + c5*(x1*x2) + c6*(x1*x3) + c7*(x1*x4)
#             + c8*(x2*x3) + c9*(x2*x4) + c10*(x3*x4)
#             + c11*(x1**2) + c12*(x2**2)
#
# Coefficients were fit per-group; if an unknown group is requested,
# we fall back to the &#x27;default&#x27; set which mirrors the coefficients fit
# on the available training data.


_GROUP_COEFFICIENTS: Dict[str, List[float]] = {
    # Coefficients order:
    # [c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12]
    # Fitted on the provided dataset (group: &#x27;all_data&#x27;) using ridge regression with
    # a log-polynomial + pairwise interaction basis; see explain.md for details.
    &quot;all_data&quot;: [
        0.02829860941068967,
        0.12477378907814929,
        0.29255278340861196,
        0.14949345652091237,
        0.32198741157393185,
        -0.014034212974161742,
        -0.002950229952215042,
        0.01917469948099148,
        -0.013977620291087227,
        -0.015096689742574953,
        -0.0111514016675562,
        0.026822329255043645,
        0.023125093454824875,
    ],
}

# Fallback coefficients for any unseen group (kept identical to &#x27;all_data&#x27;).
_GROUP_COEFFICIENTS[&quot;default&quot;] = _GROUP_COEFFICIENTS[&quot;all_data&quot;]


def _predict_one(sample: Dict[str, float], coefs: List[float]) -&gt; float:
    # Safe log transform; clamp at a tiny epsilon to avoid log(&lt;=0) if encountered.
    eps = 1e-12
    lr = float(sample.get(&quot;lr&quot;, 0.0))
    bsz = float(sample.get(&quot;bsz&quot;, 0.0))
    data_size = float(sample.get(&quot;data_size&quot;, 0.0))
    non_emb = float(sample.get(&quot;non_embedding_param_size&quot;, 0.0))

    lr = lr if lr &gt; 0.0 else eps
    bsz = bsz if bsz &gt; 0.0 else eps
    data_size = data_size if data_size &gt; 0.0 else eps
    non_emb = non_emb if non_emb &gt; 0.0 else eps

    x1 = log(lr)
    x2 = log(bsz)
    x3 = log(data_size)
    x4 = log(non_emb)

    (
        c0,
        c1,
        c2,
        c3,
        c4,
        c5,
        c6,
        c7,
        c8,
        c9,
        c10,
        c11,
        c12,
    ) = coefs

    y = (
        c0
        + c1 * x1
        + c2 * x2
        + c3 * x3
        + c4 * x4
        + c5 * (x1 * x2)
        + c6 * (x1 * x3)
        + c7 * (x1 * x4)
        + c8 * (x2 * x3)
        + c9 * (x2 * x4)
        + c10 * (x3 * x4)
        + c11 * (x1 ** 2)
        + c12 * (x2 ** 2)
    )
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Select coefficients for the requested group, defaulting if not present.
    coefs = _GROUP_COEFFICIENTS.get(group, _GROUP_COEFFICIENTS[&quot;default&quot;])

    outputs: List[Dict[str, float]] = []
    for sample in input_data:
        y = _predict_one(sample, coefs)
        outputs.append({&quot;lm_loss&quot;: y})
    return outputs</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
