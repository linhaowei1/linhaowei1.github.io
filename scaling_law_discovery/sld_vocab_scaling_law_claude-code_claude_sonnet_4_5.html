<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - Vocabulary Scaling Law - claude-code + claude-sonnet-4-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>Vocabulary Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">claude-code</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">claude-sonnet-4-5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        0.986447
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.962215</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">0.900809</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.986447
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;

    # Parameters fitted for each group
    # Model: unigram_normalized_loss = A + B * vocab_size^alpha / (non_vocab_parameters^beta * num_characters^gamma)

    group_params = {
        &#x27;all_data&#x27;: {
            &#x27;A&#x27;: -5.6710314467673895,
            &#x27;B&#x27;: 3997.4900001850224,
            &#x27;alpha&#x27;: 0.060389341616412094,
            &#x27;beta&#x27;: 0.035426879627548834,
            &#x27;gamma&#x27;: 0.34778022803102326
        }
    }

    # Get parameters for the specified group
    # If group not found, use &#x27;all_data&#x27; as default
    params = group_params.get(group, group_params[&#x27;all_data&#x27;])

    A = params[&#x27;A&#x27;]
    B = params[&#x27;B&#x27;]
    alpha = params[&#x27;alpha&#x27;]
    beta = params[&#x27;beta&#x27;]
    gamma = params[&#x27;gamma&#x27;]

    # Make predictions for each input data point
    predictions = []
    for data_point in input_data:
        V = data_point[&#x27;vocab_size&#x27;]
        N = data_point[&#x27;non_vocab_parameters&#x27;]
        D = data_point[&#x27;num_characters&#x27;]

        # Apply scaling law formula
        loss = A + B * (V ** alpha) / ((N ** beta) * (D ** gamma))

        predictions.append({
            &#x27;unigram_normalized_loss&#x27;: loss
        })

    return predictions</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.980335
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1">import numpy as np


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Model parameters (fitted on &#x27;all_data&#x27; group)
    # These parameters are specific to the group but the functional form remains the same

    # Polynomial degree-2 model in log-space
    # loss = intercept + c1*log(N) + c2*log(V) + c3*log(D)
    #        + c4*log²(N) + c5*log(N)*log(V) + c6*log(N)*log(D)
    #        + c7*log²(V) + c8*log(V)*log(D) + c9*log²(D)

    # Parameters for &#x27;all_data&#x27; group (the only group in training data)
    params = {
        &#x27;all_data&#x27;: {
            &#x27;intercept&#x27;: 43.653023,
            &#x27;c1&#x27;: 0.584601,      # log(N)
            &#x27;c2&#x27;: 0.779496,      # log(V)
            &#x27;c3&#x27;: -4.504395,     # log(D)
            &#x27;c4&#x27;: 0.025814,      # log²(N)
            &#x27;c5&#x27;: 0.022593,      # log(N)*log(V)
            &#x27;c6&#x27;: -0.081356,     # log(N)*log(D)
            &#x27;c7&#x27;: 0.028554,      # log²(V)
            &#x27;c8&#x27;: -0.073865,     # log(V)*log(D)
            &#x27;c9&#x27;: 0.137360,      # log²(D)
        }
    }

    # Get parameters for the specified group (default to &#x27;all_data&#x27; if group not found)
    group_params = params.get(group, params[&#x27;all_data&#x27;])

    # Extract coefficients
    intercept = group_params[&#x27;intercept&#x27;]
    c1 = group_params[&#x27;c1&#x27;]
    c2 = group_params[&#x27;c2&#x27;]
    c3 = group_params[&#x27;c3&#x27;]
    c4 = group_params[&#x27;c4&#x27;]
    c5 = group_params[&#x27;c5&#x27;]
    c6 = group_params[&#x27;c6&#x27;]
    c7 = group_params[&#x27;c7&#x27;]
    c8 = group_params[&#x27;c8&#x27;]
    c9 = group_params[&#x27;c9&#x27;]

    # Prepare output
    results = []

    for data_point in input_data:
        # Extract input variables
        N = data_point[&#x27;non_vocab_parameters&#x27;]  # Non-vocabulary parameters
        V = data_point[&#x27;vocab_size&#x27;]             # Vocabulary size
        D = data_point[&#x27;num_characters&#x27;]         # Number of characters in training data

        # Compute log transformations
        log_N = np.log(N)
        log_V = np.log(V)
        log_D = np.log(D)

        # Apply the polynomial scaling law
        predicted_loss = (
            intercept
            + c1 * log_N
            + c2 * log_V
            + c3 * log_D
            + c4 * log_N**2
            + c5 * log_N * log_V
            + c6 * log_N * log_D
            + c7 * log_V**2
            + c8 * log_V * log_D
            + c9 * log_D**2
        )

        # Return the predicted output
        results.append({
            &#x27;unigram_normalized_loss&#x27;: predicted_loss
        })

    return results</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.973920
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;

    # Parameters for the scaling law, fitted to the &#x27;all_data&#x27; group
    # Formula: L = a + b/N^α + c/D^β + d*V
    # where:
    #   L = unigram_normalized_loss
    #   N = non_vocab_parameters
    #   D = num_characters
    #   V = vocab_size

    params = {
        &#x27;all_data&#x27;: {
            &#x27;a&#x27;: -5.7257846952760705,
            &#x27;b&#x27;: 14225.684466145338,
            &#x27;alpha&#x27;: 0.6378870596985718,
            &#x27;c&#x27;: 5553.040069198156,
            &#x27;beta&#x27;: 0.36932125490284595,
            &#x27;d&#x27;: 2.6514193787820294e-06
        }
    }

    # Get parameters for the specified group
    # If group not found, use &#x27;all_data&#x27; as default
    if group not in params:
        group = &#x27;all_data&#x27;

    p = params[group]

    # Apply the scaling law to each input data point
    results = []
    for data_point in input_data:
        N = data_point[&#x27;non_vocab_parameters&#x27;]
        D = data_point[&#x27;num_characters&#x27;]
        V = data_point[&#x27;vocab_size&#x27;]

        # Calculate predicted loss using the scaling law
        unigram_normalized_loss = (
            p[&#x27;a&#x27;] +
            p[&#x27;b&#x27;] / (N ** p[&#x27;alpha&#x27;]) +
            p[&#x27;c&#x27;] / (D ** p[&#x27;beta&#x27;]) +
            p[&#x27;d&#x27;] * V
        )

        results.append({
            &#x27;unigram_normalized_loss&#x27;: unigram_normalized_loss
        })

    return results</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.969565
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3">import math


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Model parameters for each group
    # The model is a polynomial in log-space:
    # loss = a + b₁·log(C) + b₂·log(N) + b₃·log(V)
    #        + c₁·log(C)² + c₂·log(N)² + c₃·log(V)²
    #        + d·log(C)·log(N)
    # where C=num_characters, N=non_vocab_parameters, V=vocab_size

    params = {
        &#x27;all_data&#x27;: {
            &#x27;intercept&#x27;: 55.034742478160304,
            &#x27;log_chars&#x27;: -4.985542273029513,
            &#x27;log_non_vocab&#x27;: 0.5431887031961984,
            &#x27;log_vocab&#x27;: -0.3290853205882094,
            &#x27;log_chars_sq&#x27;: 0.1205166281173205,
            &#x27;log_non_vocab_sq&#x27;: 0.0162115590376144,
            &#x27;log_vocab_sq&#x27;: 0.01962529579067221,
            &#x27;log_c_x_log_nv&#x27;: -0.05358364971911641
        }
    }

    # Get parameters for the specified group
    if group not in params:
        raise ValueError(f&quot;Unknown group: {group}. Available groups: {list(params.keys())}&quot;)

    p = params[group]

    # Make predictions for each data point
    results = []
    for data_point in input_data:
        # Extract input variables
        num_characters = data_point[&#x27;num_characters&#x27;]
        non_vocab_parameters = data_point[&#x27;non_vocab_parameters&#x27;]
        vocab_size = data_point[&#x27;vocab_size&#x27;]

        # Compute log-transformed features
        log_chars = math.log(num_characters)
        log_non_vocab = math.log(non_vocab_parameters)
        log_vocab = math.log(vocab_size)

        # Compute derived features
        log_chars_sq = log_chars ** 2
        log_non_vocab_sq = log_non_vocab ** 2
        log_vocab_sq = log_vocab ** 2
        log_c_x_log_nv = log_chars * log_non_vocab

        # Apply the scaling law
        unigram_normalized_loss = (
            p[&#x27;intercept&#x27;] +
            p[&#x27;log_chars&#x27;] * log_chars +
            p[&#x27;log_non_vocab&#x27;] * log_non_vocab +
            p[&#x27;log_vocab&#x27;] * log_vocab +
            p[&#x27;log_chars_sq&#x27;] * log_chars_sq +
            p[&#x27;log_non_vocab_sq&#x27;] * log_non_vocab_sq +
            p[&#x27;log_vocab_sq&#x27;] * log_vocab_sq +
            p[&#x27;log_c_x_log_nv&#x27;] * log_c_x_log_nv
        )

        results.append({&#x27;unigram_normalized_loss&#x27;: unigram_normalized_loss})

    return results</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.900809
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4">import math


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Coefficients for the &#x27;all_data&#x27; group
    # These were obtained by fitting a quadratic model in log space:
    # loss = a0 + a1*log(N) + a2*log(V) + a3*log(P) + a4*log(V)^2 + a5*log(P)^2 + a6*log(V)*log(P)
    # where N = num_characters, V = vocab_size, P = non_vocab_parameters

    coefficients = {
        &#x27;all_data&#x27;: {
            &#x27;a0&#x27;: 40.1852863461,      # intercept
            &#x27;a1&#x27;: -0.5147260634,      # log(num_characters)
            &#x27;a2&#x27;: 0.2811177220,       # log(vocab_size)
            &#x27;a3&#x27;: -3.6353177267,      # log(non_vocab_parameters)
            &#x27;a4&#x27;: 0.0197370270,       # log(vocab_size)^2
            &#x27;a5&#x27;: 0.1038993151,       # log(non_vocab_parameters)^2
            &#x27;a6&#x27;: -0.0312617648       # log(vocab_size) * log(non_vocab_parameters)
        }
    }

    # Get coefficients for the specified group
    if group not in coefficients:
        raise ValueError(f&quot;Unknown group: {group}. Available groups: {list(coefficients.keys())}&quot;)

    coeffs = coefficients[group]

    # Compute predictions
    predictions = []
    for data_point in input_data:
        # Extract input variables
        num_characters = data_point[&#x27;num_characters&#x27;]
        vocab_size = data_point[&#x27;vocab_size&#x27;]
        non_vocab_parameters = data_point[&#x27;non_vocab_parameters&#x27;]

        # Compute log features
        log_chars = math.log(num_characters)
        log_vocab = math.log(vocab_size)
        log_params = math.log(non_vocab_parameters)

        # Apply the scaling law formula
        predicted_loss = (
            coeffs[&#x27;a0&#x27;]
            + coeffs[&#x27;a1&#x27;] * log_chars
            + coeffs[&#x27;a2&#x27;] * log_vocab
            + coeffs[&#x27;a3&#x27;] * log_params
            + coeffs[&#x27;a4&#x27;] * log_vocab ** 2
            + coeffs[&#x27;a5&#x27;] * log_params ** 2
            + coeffs[&#x27;a6&#x27;] * log_vocab * log_params
        )

        predictions.append({
            &#x27;unigram_normalized_loss&#x27;: predicted_loss
        })

    return predictions</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>