<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - SFT Scaling Law - claude-code + claude-sonnet-4-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>SFT Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">claude-code</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">claude-sonnet-4-5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        0.948364
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.916139</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">0.787239</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.948364
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0">import json
import math

# Load fitted parameters from the training data
# These parameters were obtained by fitting L(N) = a * log(N) + b to each group
FITTED_PARAMS = {
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.2858284253987973, &quot;b&quot;: 5.988265549351065},
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.2633818402656468, &quot;b&quot;: 4.737755542012152},
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.1380796078939516, &quot;b&quot;: 3.391898490213529},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.21223122991733276, &quot;b&quot;: 4.783598287214052},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.23807369821093685, &quot;b&quot;: 4.2045733043013165},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.09602793909920557, &quot;b&quot;: 2.652870267456121},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.12168554599239426, &quot;b&quot;: 3.4606313079569837},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.19060958285317242, &quot;b&quot;: 3.820355959611436},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.10204513742983291, &quot;b&quot;: 2.950335143562661},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.14467116003927433, &quot;b&quot;: 4.210632462544093},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.22564133332553715, &quot;b&quot;: 4.218447739736505},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.16694369363861158, &quot;b&quot;: 3.9284497987057874},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.27885014029903604, &quot;b&quot;: 5.722811837645894},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.3347248647552073, &quot;b&quot;: 5.410755825604152},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.2413552868912743, &quot;b&quot;: 4.4926337354168595},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.19814331941245988, &quot;b&quot;: 4.453518961526505},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.3339209236977352, &quot;b&quot;: 5.242535980974371},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.10813142202742225, &quot;b&quot;: 2.7193492499816334},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.10226900935941804, &quot;b&quot;: 3.0035271247006574},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.22503850880208404, &quot;b&quot;: 4.067383747817735},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.06738256744904991, &quot;b&quot;: 2.227609751673505},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.1567771098875299, &quot;b&quot;: 4.096427281007177},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.28416051180558977, &quot;b&quot;: 4.789217216189481},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.10931922565009441, &quot;b&quot;: 2.969051299001184},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.035974453233156484, &quot;b&quot;: 2.2060635294933304},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.027858065828614262, &quot;b&quot;: 2.1626361790690503},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.05153332226677372, &quot;b&quot;: 1.9623193491235948},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.16562129412487037, &quot;b&quot;: 4.0988075329513345},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.08234869176487448, &quot;b&quot;: 3.3355539218016768},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.19493726211114437, &quot;b&quot;: 3.861648173041152},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.11550187851501488, &quot;b&quot;: 3.2282318950626876},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.09533853604323887, &quot;b&quot;: 3.4146676286886763},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.15291379226040927, &quot;b&quot;: 3.353099664653985},
    &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.29617705608594097, &quot;b&quot;: 6.179866386147315},
    &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.28087485939518764, &quot;b&quot;: 4.8171995484035675},
    &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.14749971599228653, &quot;b&quot;: 3.4933775691623454},
    &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.11717228671842463, &quot;b&quot;: 3.2855166649939935},
    &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.0696292965522014, &quot;b&quot;: 1.480251152476475},
    &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.06785004652930211, &quot;b&quot;: 2.132300508433401},
    &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {&quot;a&quot;: -0.13444290860067154, &quot;b&quot;: 3.752075115263242},
    &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {&quot;a&quot;: -0.07229854246705678, &quot;b&quot;: 1.6089334546678618},
    &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {&quot;a&quot;: -0.09053553061557014, &quot;b&quot;: 2.594400260204647},
}


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    The discovered scaling law follows a logarithmic relationship:
        L(N) = a * log(N) + b

    where:
        - L is the predicted SFT loss (sft_loss)
        - N is the number of examples in the fine-tuning dataset (sft_data_size)
        - a and b are group-specific parameters fitted from training data
        - log is the natural logarithm

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Get the parameters for this group
    if group not in FITTED_PARAMS:
        raise ValueError(f&quot;Unknown group: {group}. Available groups: {list(FITTED_PARAMS.keys())}&quot;)

    params = FITTED_PARAMS[group]
    a = params[&quot;a&quot;]
    b = params[&quot;b&quot;]

    # Make predictions for each input data point
    predictions = []
    for data_point in input_data:
        # Extract the input variable (sft_data_size)
        N = data_point[&quot;sft_data_size&quot;]

        # Apply the scaling law: L(N) = a * log(N) + b
        sft_loss = a * math.log(N) + b

        # Return the prediction
        predictions.append({&quot;sft_loss&quot;: sft_loss})

    return predictions</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.948364
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1">import json
import math
import os

# Load fitted parameters from JSON file
PARAMETERS_FILE = os.path.join(os.path.dirname(__file__), &#x27;parameters.json&#x27;)

with open(PARAMETERS_FILE, &#x27;r&#x27;) as f:
    PARAMETERS = json.load(f)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    The scaling law follows a log-linear relationship:
        sft_loss = a * log(sft_data_size) + b

    where:
        - a and b are group-specific parameters
        - log is the natural logarithm
        - sft_data_size is the number of examples in the fine-tuning dataset
        - sft_loss is the final fine-tuning loss

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Get parameters for this group
    if group not in PARAMETERS:
        raise ValueError(f&quot;Unknown group: {group}. Available groups: {list(PARAMETERS.keys())}&quot;)

    params = PARAMETERS[group]
    a = params[&#x27;a&#x27;]
    b = params[&#x27;b&#x27;]

    # Make predictions for each input data point
    predictions = []
    for data_point in input_data:
        # Extract the input variable
        sft_data_size = data_point[&#x27;sft_data_size&#x27;]

        # Apply the scaling law: L = a * log(N) + b
        sft_loss = a * math.log(sft_data_size) + b

        # Return prediction as a dictionary
        predictions.append({&#x27;sft_loss&#x27;: sft_loss})

    return predictions</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.948364
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2">import math

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Discovered scaling law: loss = A - B * ln(N)
    # where N is the SFT data size

    # Parameters fitted for each group
    parameters = {
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 5.988266, &#x27;B&#x27;: 0.285828},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 4.783598, &#x27;B&#x27;: 0.212231},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 4.210632, &#x27;B&#x27;: 0.144671},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 3.460631, &#x27;B&#x27;: 0.121686},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 5.722812, &#x27;B&#x27;: 0.278850},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 4.453519, &#x27;B&#x27;: 0.198143},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 3.003527, &#x27;B&#x27;: 0.102269},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 4.096427, &#x27;B&#x27;: 0.156777},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 2.206064, &#x27;B&#x27;: 0.035974},
        &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 6.179866, &#x27;B&#x27;: 0.296177},
        &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 3.285517, &#x27;B&#x27;: 0.117172},
        &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 3.752075, &#x27;B&#x27;: 0.134443},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 4.098808, &#x27;B&#x27;: 0.165621},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: 3.228232, &#x27;B&#x27;: 0.115502},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.737756, &#x27;B&#x27;: 0.263382},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.204573, &#x27;B&#x27;: 0.238074},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.218448, &#x27;B&#x27;: 0.225641},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 3.820356, &#x27;B&#x27;: 0.190610},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 5.410756, &#x27;B&#x27;: 0.334725},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 5.242536, &#x27;B&#x27;: 0.333921},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.067384, &#x27;B&#x27;: 0.225039},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.789217, &#x27;B&#x27;: 0.284161},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 2.162636, &#x27;B&#x27;: 0.027858},
        &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 4.817200, &#x27;B&#x27;: 0.280875},
        &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 1.480251, &#x27;B&#x27;: 0.069629},
        &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 1.608933, &#x27;B&#x27;: 0.072299},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 3.335554, &#x27;B&#x27;: 0.082349},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 3.414668, &#x27;B&#x27;: 0.095339},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 3.391898, &#x27;B&#x27;: 0.138080},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.652870, &#x27;B&#x27;: 0.096028},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 3.928450, &#x27;B&#x27;: 0.166944},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.950335, &#x27;B&#x27;: 0.102045},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 4.492634, &#x27;B&#x27;: 0.241355},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.719349, &#x27;B&#x27;: 0.108131},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.227610, &#x27;B&#x27;: 0.067383},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.969051, &#x27;B&#x27;: 0.109319},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 1.962319, &#x27;B&#x27;: 0.051533},
        &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 3.493378, &#x27;B&#x27;: 0.147500},
        &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.132301, &#x27;B&#x27;: 0.067850},
        &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 2.594400, &#x27;B&#x27;: 0.090536},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 3.861648, &#x27;B&#x27;: 0.194937},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 3.353100, &#x27;B&#x27;: 0.152914}
    }

    # Get parameters for this group
    if group not in parameters:
        raise ValueError(f&quot;Unknown group: {group}&quot;)

    params = parameters[group]
    A = params[&#x27;A&#x27;]
    B = params[&#x27;B&#x27;]

    # Apply the scaling law to each data point
    results = []
    for data_point in input_data:
        N = data_point[&#x27;sft_data_size&#x27;]
        predicted_loss = A - B * math.log(N)
        results.append({&#x27;sft_loss&#x27;: predicted_loss})

    return results</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.948364
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3">import math

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;

    # Fitted parameters for each group
    # Formula: sft_loss = a * log(sft_data_size) + b
    params = {
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.285828, &#x27;b&#x27;: 5.988266},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.263382, &#x27;b&#x27;: 4.737756},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.138080, &#x27;b&#x27;: 3.391898},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.212231, &#x27;b&#x27;: 4.783598},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.238074, &#x27;b&#x27;: 4.204573},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.096028, &#x27;b&#x27;: 2.652870},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.121686, &#x27;b&#x27;: 3.460631},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.190610, &#x27;b&#x27;: 3.820356},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.102045, &#x27;b&#x27;: 2.950335},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.144671, &#x27;b&#x27;: 4.210632},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.225641, &#x27;b&#x27;: 4.218448},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.166944, &#x27;b&#x27;: 3.928450},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.278850, &#x27;b&#x27;: 5.722812},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.334725, &#x27;b&#x27;: 5.410756},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.241355, &#x27;b&#x27;: 4.492634},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.198143, &#x27;b&#x27;: 4.453519},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.333921, &#x27;b&#x27;: 5.242536},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.108131, &#x27;b&#x27;: 2.719349},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.102269, &#x27;b&#x27;: 3.003527},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.225039, &#x27;b&#x27;: 4.067384},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.067383, &#x27;b&#x27;: 2.227610},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.156777, &#x27;b&#x27;: 4.096427},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.284161, &#x27;b&#x27;: 4.789217},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.109319, &#x27;b&#x27;: 2.969051},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.035974, &#x27;b&#x27;: 2.206064},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.027858, &#x27;b&#x27;: 2.162636},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.051533, &#x27;b&#x27;: 1.962319},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.165621, &#x27;b&#x27;: 4.098808},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.082349, &#x27;b&#x27;: 3.335554},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.194937, &#x27;b&#x27;: 3.861648},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.115502, &#x27;b&#x27;: 3.228232},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.095339, &#x27;b&#x27;: 3.414668},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.152914, &#x27;b&#x27;: 3.353100},
        &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.296177, &#x27;b&#x27;: 6.179866},
        &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.280875, &#x27;b&#x27;: 4.817200},
        &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.147500, &#x27;b&#x27;: 3.493378},
        &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.117172, &#x27;b&#x27;: 3.285517},
        &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.069629, &#x27;b&#x27;: 1.480251},
        &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.067850, &#x27;b&#x27;: 2.132301},
        &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: -0.134443, &#x27;b&#x27;: 3.752075},
        &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: -0.072299, &#x27;b&#x27;: 1.608933},
        &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: -0.090536, &#x27;b&#x27;: 2.594400},
    }

    # Get parameters for the specified group
    if group not in params:
        raise ValueError(f&quot;Unknown group: {group}&quot;)

    a = params[group][&#x27;a&#x27;]
    b = params[group][&#x27;b&#x27;]

    # Make predictions for each input data point
    predictions = []
    for data_point in input_data:
        sft_data_size = data_point[&#x27;sft_data_size&#x27;]

        # Apply the logarithmic scaling law
        sft_loss = a * math.log(sft_data_size) + b

        predictions.append({&#x27;sft_loss&#x27;: sft_loss})

    return predictions</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #DAA520; color: white;">
                        R² = 0.787239
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4">def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fitted parameters for each group (from curve fitting on training data)
    # Scaling law: sft_loss = a * (sft_data_size)^(-b) + c

    parameters = {
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 6.9738879587354985, &#x27;b&#x27;: 0.0813415811372061, &#x27;c&#x27;: 6.209360061651158e-11},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 5.416194164267256, &#x27;b&#x27;: 0.0720358167338764, &#x27;c&#x27;: 7.8874180375913e-12},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 4.497775144341002, &#x27;b&#x27;: 0.0491972775293856, &#x27;c&#x27;: 1.955613448956228e-11},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 3.726687324322024, &#x27;b&#x27;: 0.0513362241087863, &#x27;c&#x27;: 7.71038788371925e-12},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 6.796594760907895, &#x27;b&#x27;: 0.0855017025058688, &#x27;c&#x27;: 3.5644296141167816e-12},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 5.121314344755191, &#x27;b&#x27;: 0.0740782998112432, &#x27;c&#x27;: 1.3640633310585388e-11},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 3.21710353273244, &#x27;b&#x27;: 0.0490507139907979, &#x27;c&#x27;: 1.0557194948504606e-11},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 4.468174350569338, &#x27;b&#x27;: 0.0576116621246158, &#x27;c&#x27;: 3.8573586034728045e-11},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 2.233967790682599, &#x27;b&#x27;: 0.0191483651848653, &#x27;c&#x27;: 1.9412693674780712e-11},
        &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 7.198398164068978, &#x27;b&#x27;: 0.0817204499072352, &#x27;c&#x27;: 3.2510296974217244e-12},
        &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 3.5430516811202155, &#x27;b&#x27;: 0.0522550981730723, &#x27;c&#x27;: 1.1068146399395571e-11},
        &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 4.052493019544314, &#x27;b&#x27;: 0.052691031082205, &#x27;c&#x27;: 6.746480749474824e-12},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 4.571149014484463, &#x27;b&#x27;: 0.0636171899686622, &#x27;c&#x27;: 9.026631196760658e-12},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;a&#x27;: 3.492798575656628, &#x27;b&#x27;: 0.0528118147665376, &#x27;c&#x27;: 1.0836333814545436e-11},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 5.923744647294182, &#x27;b&#x27;: 0.1052086313123345, &#x27;c&#x27;: 1.5788841830932776e-11},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 5.350688480941363, &#x27;b&#x27;: 0.1095237488864338, &#x27;c&#x27;: 5.272610698686065e-12},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 5.237426477009148, &#x27;b&#x27;: 0.1000412217663205, &#x27;c&#x27;: 7.1741015201617725e-12},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 4.601802086260434, &#x27;b&#x27;: 0.0893794216309777, &#x27;c&#x27;: 7.841164216874931e-12},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 7.594465198757044, &#x27;b&#x27;: 0.1333097873907668, &#x27;c&#x27;: 1.3554385113419691e-11},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 7.683920586651666, &#x27;b&#x27;: 0.1431066056707549, &#x27;c&#x27;: 8.407693574380672e-12},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 5.229994743123611, &#x27;b&#x27;: 0.1080529832595854, &#x27;c&#x27;: 1.787133563253055e-11},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 6.499201552078441, &#x27;b&#x27;: 0.123318476159955, &#x27;c&#x27;: 1.4467022271584628e-11},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 2.1770797673846456, &#x27;b&#x27;: 0.0144985156639429, &#x27;c&#x27;: 1.3240519791679617e-12},
        &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 6.339049368674285, &#x27;b&#x27;: 0.1172559464274163, &#x27;c&#x27;: 3.282936462150453e-11},
        &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 1.823379316613078, &#x27;b&#x27;: 0.1674599551268627, &#x27;c&#x27;: 0.4167409405994949},
        &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 1.775741745120599, &#x27;b&#x27;: 0.1343979198744542, &#x27;c&#x27;: 0.4009175915675014},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 3.4396037497251, &#x27;b&#x27;: 0.0316506222790409, &#x27;c&#x27;: 1.851582046346298e-11},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;a&#x27;: 3.5492577898997597, &#x27;b&#x27;: 0.0368812645537255, &#x27;c&#x27;: 3.0984992301047484e-11},
        &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 3.7815960318544137, &#x27;b&#x27;: 0.0640731112559584, &#x27;c&#x27;: 5.133338198959336e-12},
        &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 2.8815066741907813, &#x27;b&#x27;: 0.0539025472962201, &#x27;c&#x27;: 1.1417422562942647e-11},
        &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 4.45601962837555, &#x27;b&#x27;: 0.0690574152830047, &#x27;c&#x27;: 9.361215376952394e-12},
        &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 3.167052217392773, &#x27;b&#x27;: 0.0501048229949453, &#x27;c&#x27;: 6.587842000399508e-13},
        &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 5.86196054927262, &#x27;b&#x27;: 0.1201853857867522, &#x27;c&#x27;: 0.2505119015404434},
        &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 2.620750839880945, &#x27;b&#x27;: 0.115203713227391, &#x27;c&#x27;: 0.7814633075466515},
        &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 2.349129117465099, &#x27;b&#x27;: 0.0417628773316036, &#x27;c&#x27;: 7.147060465007951e-12},
        &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 3.241838816258498, &#x27;b&#x27;: 0.0554639976201082, &#x27;c&#x27;: 2.0400472816702877e-11},
        &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 1.7881053529873807, &#x27;b&#x27;: 0.0422082813415794, &#x27;c&#x27;: 0.2693284658571291},
        &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 3.9462672178497136, &#x27;b&#x27;: 0.0681165715966697, &#x27;c&#x27;: 7.881931987611646e-12},
        &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 2.259872089331568, &#x27;b&#x27;: 0.0445738697036901, &#x27;c&#x27;: 9.790168427672564e-12},
        &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 2.7905737239350903, &#x27;b&#x27;: 0.0507995311827284, &#x27;c&#x27;: 1.8161462756396424e-12},
        &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 4.7344533518491385, &#x27;b&#x27;: 0.0926126262618999, &#x27;c&#x27;: 9.943976438405106e-13},
        &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;a&#x27;: 3.9262973834353896, &#x27;b&#x27;: 0.0781626896765455, &#x27;c&#x27;: 1.0543787441757105e-12},
    }

    # Check if the group exists in our trained parameters
    if group not in parameters:
        # If group is unseen, we could use average parameters or raise an error
        # For robustness, let&#x27;s use the mean parameters across all groups
        import statistics
        all_a = [p[&#x27;a&#x27;] for p in parameters.values()]
        all_b = [p[&#x27;b&#x27;] for p in parameters.values()]
        all_c = [p[&#x27;c&#x27;] for p in parameters.values()]

        params = {
            &#x27;a&#x27;: statistics.mean(all_a),
            &#x27;b&#x27;: statistics.mean(all_b),
            &#x27;c&#x27;: statistics.median(all_c)  # Use median for c as it has extreme outliers
        }
    else:
        params = parameters[group]

    # Apply the scaling law: sft_loss = a * (sft_data_size)^(-b) + c
    results = []
    for data_point in input_data:
        N = data_point[&#x27;sft_data_size&#x27;]
        predicted_loss = params[&#x27;a&#x27;] * (N ** (-params[&#x27;b&#x27;])) + params[&#x27;c&#x27;]
        results.append({&#x27;sft_loss&#x27;: predicted_loss})

    return results</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>