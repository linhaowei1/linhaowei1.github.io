<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Vocabulary Scaling Law - codex + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Vocabulary Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">codex</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.980329 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.977308</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.965221</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.980329 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0">from __future__ import annotations
import math
from typing import Dict, List


def _predict_one(x: Dict[str, float], coefs: list[float]) -&gt; float:
    # Safeguard for logs
    v = max(float(x.get(&quot;vocab_size&quot;, 0.0)), 1e-8)
    p = max(float(x.get(&quot;non_vocab_parameters&quot;, 0.0)), 1e-8)
    n = max(float(x.get(&quot;num_characters&quot;, 0.0)), 1e-8)

    lv = math.log(v)
    lp = math.log(p)
    ln = math.log(n)

    # Quadratic-in-logs model with pairwise interactions
    a0, c_lv, c_lp, c_ln, q_lv2, q_lp2, q_ln2, i_lv_lp, i_lv_ln, i_lp_ln = coefs
    y = (
        a0
        + c_lv * lv
        + c_lp * lp
        + c_ln * ln
        + q_lv2 * (lv * lv)
        + q_lp2 * (lp * lp)
        + q_ln2 * (ln * ln)
        + i_lv_lp * (lv * lp)
        + i_lv_ln * (lv * ln)
        + i_lp_ln * (lp * ln)
    )
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Coefficients per group for the quadratic-in-logs model:
    # y = a0 + c_lv*ln(V) + c_lp*ln(P) + c_ln*ln(N)
    #     + q_lv2*ln(V)^2 + q_lp2*ln(P)^2 + q_ln2*ln(N)^2
    #     + i_lv_lp*ln(V)ln(P) + i_lv_ln*ln(V)ln(N) + i_lp_ln*ln(P)ln(N)
    GROUP_COEFS: Dict[str, list[float]] = {
        # Fitted on the provided dataset (group == &#x27;all_data&#x27;)
        &quot;all_data&quot;: [
            43.65302341457793,   # a0
            0.7794957507056559,   # c_lv
            0.5846007124754145,   # c_lp
            -4.504394573930249,   # c_ln
            0.028553982023411387, # q_lv2
            0.025813565801902923, # q_lp2
            0.1373604041861016,   # q_ln2
            0.022592838215620374, # i_lv_lp
            -0.07386461582255775, # i_lv_ln
            -0.08135643667959318, # i_lp_ln
        ]
    }

    coefs = GROUP_COEFS.get(group)
    if coefs is None:
        # Fall back to using &#x27;all_data&#x27; if an unknown group is requested.
        coefs = GROUP_COEFS[&quot;all_data&quot;]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        pred = _predict_one(row, coefs)
        outputs.append({&quot;unigram_normalized_loss&quot;: pred})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.980329 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1">from __future__ import annotations

import math
from typing import Dict, List


def _features(non_vocab_parameters: float, num_characters: float, vocab_size: float) -&gt; List[float]:
    &quot;&quot;&quot;Construct second-order polynomial features in natural logs.

    Feature order:
      [1, lnN, lnD, lnV, lnN^2, lnD^2, lnV^2, lnN*lnD, lnN*lnV, lnD*lnV]
    &quot;&quot;&quot;
    lnN = math.log(non_vocab_parameters)
    lnD = math.log(num_characters)
    lnV = math.log(vocab_size)
    return [
        1.0,
        lnN,
        lnD,
        lnV,
        lnN * lnN,
        lnD * lnD,
        lnV * lnV,
        lnN * lnD,
        lnN * lnV,
        lnD * lnV,
    ]


# Coefficients fitted on the provided dataset (group: &quot;all_data&quot;).
# The functional form is identical for all groups; coefficients may differ.
_COEFFICIENTS_BY_GROUP: Dict[str, List[float]] = {
    # y = sum_i coef[i] * feature[i]
    # Features as defined in _features()
    &quot;all_data&quot;: [
        4.365302343251918e01,  # bias
        5.846007120296094e-01,  # lnN
        -4.504394571730862,  # lnD
        7.794957511982874e-01,  # lnV
        2.581356581906411e-02,  # (lnN)^2
        1.373604039639881e-01,  # (lnD)^2
        2.855398202949366e-02,  # (lnV)^2
        -8.135643667694171e-02,  # lnN*lnD
        2.259283817507405e-02,  # lnN*lnV
        -7.386461583708665e-02,  # lnD*lnV
    ]
}


def _get_coefficients(group: str) -&gt; List[float]:
    # Use group-specific coefficients when available; otherwise default to
    # the pooled fit (&quot;all_data&quot;). This keeps the functional form identical
    # across groups while allowing per-group constants if provided.
    return _COEFFICIENTS_BY_GROUP.get(group, _COEFFICIENTS_BY_GROUP[&quot;all_data&quot;])


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coefs = _get_coefficients(group)
    out: List[Dict[str, float]] = []

    for row in input_data:
        try:
            N = float(row[&quot;non_vocab_parameters&quot;])  # model params excluding embedding/vocab
            D = float(row[&quot;num_characters&quot;])        # training data size in characters
            V = float(row[&quot;vocab_size&quot;])            # vocabulary size
        except KeyError as e:
            raise KeyError(f&quot;Missing required key in input_data: {e}&quot;)

        if N &lt;= 0 or D &lt;= 0 or V &lt;= 0:
            raise ValueError(&quot;All inputs must be positive to compute logarithms.&quot;)

        feats = _features(N, D, V)
        # Linear combination of features and coefficients
        y_hat = sum(c * f for c, f in zip(coefs, feats))
        out.append({&quot;unigram_normalized_loss&quot;: float(y_hat)})

    return out</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.980329 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2">from math import log
from typing import Dict, List


# Quadratic-in-log scaling law with pairwise interactions.
# Form (same for all groups):
#   y = b0
#       + bV * ln(V) + bP * ln(P) + bN * ln(N)
#       + qV * ln(V)^2 + qP * ln(P)^2 + qN * ln(N)^2
#       + iPN * ln(P)*ln(N) + iVN * ln(V)*ln(N) + iVP * ln(V)*ln(P)
# Coefficients are allowed to vary per `group`.


_COEFFS_BY_GROUP: Dict[str, Dict[str, float]] = {
    # Fitted on provided dataset group &quot;all_data&quot;
    # RMSE ≈ 0.08762, R^2 ≈ 0.9879
    &quot;all_data&quot;: {
        &quot;lnV&quot;: 0.779495751194,
        &quot;lnP&quot;: 0.584600712350,
        &quot;lnN&quot;: -4.504394566402,
        &quot;lnV2&quot;: 0.028553981965,
        &quot;lnP2&quot;: 0.025813565755,
        &quot;lnN2&quot;: 0.137360403627,
        &quot;lnP_lnN&quot;: -0.081356436724,
        &quot;lnV_lnN&quot;: -0.073864615821,
        &quot;lnV_lnP&quot;: 0.022592838156,
        &quot;bias&quot;: 43.653023403128,
    },
}


def _predict_single(x: Dict[str, float], coeffs: Dict[str, float]) -&gt; float:
    V = float(x[&quot;vocab_size&quot;])          # vocabulary size
    P = float(x[&quot;non_vocab_parameters&quot;])  # non-vocabulary parameters
    N = float(x[&quot;num_characters&quot;])      # total characters in data

    # Guard against non-positive inputs for logs
    if V &lt;= 0 or P &lt;= 0 or N &lt;= 0:
        raise ValueError(&quot;All inputs must be positive for logarithms: V, P, N&quot;)

    lV = log(V)
    lP = log(P)
    lN = log(N)

    y = (
        coeffs[&quot;bias&quot;]
        + coeffs[&quot;lnV&quot;] * lV
        + coeffs[&quot;lnP&quot;] * lP
        + coeffs[&quot;lnN&quot;] * lN
        + coeffs[&quot;lnV2&quot;] * (lV * lV)
        + coeffs[&quot;lnP2&quot;] * (lP * lP)
        + coeffs[&quot;lnN2&quot;] * (lN * lN)
        + coeffs[&quot;lnP_lnN&quot;] * (lP * lN)
        + coeffs[&quot;lnV_lnN&quot;] * (lV * lN)
        + coeffs[&quot;lnV_lnP&quot;] * (lV * lP)
    )
    return float(y)


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Choose coefficients for the provided group; fallback to a default if unknown.
    coeffs = _COEFFS_BY_GROUP.get(group)
    if coeffs is None:
        # Fallback to the most general coefficients we have.
        coeffs = _COEFFS_BY_GROUP[&quot;all_data&quot;]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        y_hat = _predict_single(row, coeffs)
        outputs.append({&quot;unigram_normalized_loss&quot;: y_hat})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.980329 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict


# Quadratic-in-log scaling law:
#
#   y = c0
#       + c1*ln(N) + c2*ln(D) + c3*ln(V)
#       + c4*ln(N)ln(D) + c5*ln(N)ln(V) + c6*ln(D)ln(V)
#       + c7*[ln(N)]^2 + c8*[ln(D)]^2 + c9*[ln(V)]^2
#
# where:
#   y  = unigram_normalized_loss
#   N  = non_vocab_parameters
#   D  = num_characters
#   V  = vocab_size
#
# The functional form is shared across groups; coefficients may differ by group.


# Per-group coefficients learned from the provided dataset.
# Values are in natural-log space for inputs.
_COEFFICIENTS: Dict[str, Dict[str, float]] = {
    # Fitted on group == &#x27;all_data&#x27;
    &quot;all_data&quot;: {
        &quot;c0&quot;: 43.65302340313544,
        &quot;c1&quot;: 0.5846007123502681,    # ln(N)
        &quot;c2&quot;: -4.504394566402842,    # ln(D)
        &quot;c3&quot;: 0.7794957511937534,    # ln(V)
        &quot;c4&quot;: -0.0813564367242208,   # ln(N)ln(D)
        &quot;c5&quot;: 0.022592838156026952,  # ln(N)ln(V)
        &quot;c6&quot;: -0.07386461582128258,  # ln(D)ln(V)
        &quot;c7&quot;: 0.025813565754714596,  # [ln(N)]^2
        &quot;c8&quot;: 0.13736040362701235,   # [ln(D)]^2
        &quot;c9&quot;: 0.028553981965246167,  # [ln(V)]^2
    },
}


def _predict_one(x: Dict[str, float], coeffs: Dict[str, float]) -&gt; float:
    N = float(x[&quot;non_vocab_parameters&quot;])  # parameters excluding embeddings
    D = float(x[&quot;num_characters&quot;])        # total characters in training data
    V = float(x[&quot;vocab_size&quot;])            # vocabulary size

    if N &lt;= 0 or D &lt;= 0 or V &lt;= 0:
        raise ValueError(&quot;All inputs must be positive: non_vocab_parameters, num_characters, vocab_size.&quot;)

    lnN = math.log(N)
    lnD = math.log(D)
    lnV = math.log(V)

    c0 = coeffs[&quot;c0&quot;]
    c1 = coeffs[&quot;c1&quot;]
    c2 = coeffs[&quot;c2&quot;]
    c3 = coeffs[&quot;c3&quot;]
    c4 = coeffs[&quot;c4&quot;]
    c5 = coeffs[&quot;c5&quot;]
    c6 = coeffs[&quot;c6&quot;]
    c7 = coeffs[&quot;c7&quot;]
    c8 = coeffs[&quot;c8&quot;]
    c9 = coeffs[&quot;c9&quot;]

    y = (
        c0
        + c1 * lnN + c2 * lnD + c3 * lnV
        + c4 * lnN * lnD + c5 * lnN * lnV + c6 * lnD * lnV
        + c7 * (lnN ** 2) + c8 * (lnD ** 2) + c9 * (lnV ** 2)
    )
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;

    # Pick coefficients for the provided group; fall back to &#x27;all_data&#x27;.
    coeffs = _COEFFICIENTS.get(group, _COEFFICIENTS[&quot;all_data&quot;])

    outputs: list[dict[str, float]] = []
    for row in input_data:
        y = _predict_one(row, coeffs)
        outputs.append({&quot;unigram_normalized_loss&quot;: y})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.965221 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4">from __future__ import annotations

import math
from typing import Dict, List


# Coefficients per group for the scaling law:
# unigram_normalized_loss = a + b*ln(V) + c*ln(N) + d*ln(C) + e*[ln(C)]^2
# where:
#   V = vocab_size
#   N = non_vocab_parameters
#   C = num_characters
_COEFFICIENTS: Dict[str, Dict[str, float]] = {
    # Fitted on the provided dataset (group == &quot;all_data&quot;).
    # Values computed via ordinary least squares in log-space with a quadratic term for ln(C).
    &quot;all_data&quot;: {
        &quot;a&quot;: 57.12488879532268,
        &quot;b&quot;: 0.05518046027969967,
        &quot;c&quot;: -0.05243687841866118,
        &quot;d&quot;: -4.833457171218337,
        &quot;e&quot;: 0.0946221166190979,
    },
}


def _predict(coeffs: Dict[str, float], v: float, n: float, c: float) -&gt; float:
    ln_v = math.log(v)
    ln_n = math.log(n)
    ln_c = math.log(c)
    return (
        coeffs[&quot;a&quot;]
        + coeffs[&quot;b&quot;] * ln_v
        + coeffs[&quot;c&quot;] * ln_n
        + coeffs[&quot;d&quot;] * ln_c
        + coeffs[&quot;e&quot;] * (ln_c ** 2)
    )


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Fall back to the closest available group if the requested one is unknown.
    coeffs = _COEFFICIENTS.get(group, _COEFFICIENTS[&quot;all_data&quot;])

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        v = float(row[&quot;vocab_size&quot;])  # V
        n = float(row[&quot;non_vocab_parameters&quot;])  # N
        c = float(row[&quot;num_characters&quot;])  # C
        y = _predict(coeffs, v, n, c)
        outputs.append({&quot;unigram_normalized_loss&quot;: float(y)})
    return outputs</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
