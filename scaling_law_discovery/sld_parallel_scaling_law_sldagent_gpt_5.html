<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - Parallel Scaling Law - SLDAgent + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="sld_index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>Parallel Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">SLDAgent</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.999912 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.999760</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.999660</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">5</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999912 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Parallel scaling law for LLM loss with 4 parameters:
loss = L_inf + A * (n * (1 + gamma * log(k)))^(-alpha)
- L_inf: irreducible loss floor
- A: amplitude
- alpha: parameter scaling exponent (&gt;0)
- gamma: parallel efficiency coefficient (&gt;=0), diminishing returns via log(k)
Robust, simple fitting with Huber loss, bounded L-BFGS-B, and log-linear initialization.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points, dtype=float))
    n_raw = X[:, 0]
    k_raw = X[:, 1]
    P = np.atleast_2d(np.asarray(params, dtype=float))
    T = P.shape[0]
    K = min(P.shape[1], 4)

    L_inf = P[:, 0]
    A     = P[:, 1] if K &gt;= 2 else np.ones(T)
    alpha = P[:, 2] if K &gt;= 3 else np.full(T, 0.1)
    gamma = P[:, 3] if K &gt;= 4 else np.zeros(T)

    # Stabilize and normalize scales
    N0 = 1e9
    n = np.clip(n_raw, 1e-12, None) / N0
    k = np.clip(k_raw, 1.0, None)

    # Log-coupled parallel gain; clamp to avoid division by zero and enforce &gt;=1
    gk = 1.0 + np.maximum(gamma[None, :], 0.0) * np.log(k)[:, None]
    gk = np.maximum(gk, 1e-12)

    eff = (n[:, None] * gk) ** (-np.maximum(alpha[None, :], 1e-12))
    pred = L_inf[None, :] + A[None, :] * eff
    return pred[:, 0] if pred.shape[1] == 1 else pred


def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points, dtype=float))
    y = np.asarray(loss_values, dtype=float)
    y2d = y[:, None] if y.ndim == 1 else y
    N, T = y2d.shape

    # Robust Huber loss
    def huber(res, delta):
        a = np.abs(res)
        m = np.minimum(a, delta)
        return 0.5 * m**2 + delta * (a - m)

    # Log features
    ln_n = np.log(np.clip(X[:, 0], 1e-12, None)) - np.log(1e9)
    ln_k = np.log(np.clip(X[:, 1], 1.0, None))

    params_all = np.zeros((T, 4))
    rng = np.random.default_rng(19)

    for t in range(T):
        yt = y2d[:, t]
        y_min = float(np.min(yt))
        med = float(np.median(yt))
        mad = float(np.median(np.abs(yt - med)))
        delta = 1.345 * mad if mad &gt; 1e-8 else 0.01
        lam = 1e-4

        # Grid over L_inf near minimum loss for stable initialization
        L_candidates = np.linspace(max(y_min - 0.08, 0.0), max(y_min - 0.005, 0.0), 6)
        best_sse, init = np.inf, None

        A_mat = np.column_stack([np.ones(N), ln_n, ln_k])
        for Lc in L_candidates:
            diff = yt - Lc
            if np.any(diff &lt;= 1e-12):
                continue
            z = np.log(diff)
            try:
                b, *_ = np.linalg.lstsq(A_mat, z, rcond=None)
            except np.linalg.LinAlgError:
                continue
            b0, b1, b2 = b
            alpha0 = max(-b1, 1e-8)
            # Map k-slope to gamma via small-gamma approximation
            gamma0 = max((-b2 / alpha0), 0.0)
            A0 = float(np.exp(b0))
            p0 = np.array([[Lc, A0, alpha0, gamma0]])
            sse = float(np.mean((scaling_law_func(X, p0) - yt) ** 2))
            if np.isfinite(sse) and sse &lt; best_sse:
                best_sse, init = sse, (Lc, A0, alpha0, gamma0)

        if init is None:
            init = (max(y_min - 0.02, 0.0), max(np.max(yt) - max(y_min - 0.02, 0.0), 0.05), 0.1, 0.2)

        L0, A0, alpha0, gamma0 = init
        theta0 = np.array([L0, A0, alpha0, gamma0])

        # Bounds: positivity, moderate upper caps to avoid degeneracy
        bounds = [(0.0, None), (1e-10, None), (1e-10, 5.0), (0.0, 2.0)]

        def objective(theta):
            pred = scaling_law_func(X, theta[None, :])
            res = pred - yt
            return np.mean(huber(res, delta)) + lam * (theta[2]**2 + theta[3]**2)

        best_val = np.inf
        best_theta = theta0.copy()
        for r in range(4):
            noise = np.array([0.01, 0.02, 0.02, 0.02]) * rng.normal(size=4)
            start = np.clip(theta0 + (noise if r &gt; 0 else 0.0),
                            [b[0] if b[0] is not None else -np.inf for b in bounds],
                            [b[1] if b[1] is not None else np.inf for b in bounds])
            res = minimize(objective, start, method=&#x27;L-BFGS-B&#x27;, bounds=bounds, options={&#x27;maxiter&#x27;: 400})
            val = res.fun if res.success else np.inf
            if val &lt; best_val:
                best_val = val
                best_theta = res.x if res.success else start

        params_all[t] = best_theta

    return params_all[0] if T == 1 else params_all
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 4</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999799 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Scaling law for parallel LLM scaling with up to 4 parameters.
Model: loss = L_inf + c * exp(-alpha * (log(num_params) + k * log(parallel_size)))
Equivalent: loss = L_inf + c * (num_params * parallel_size**k)^(-alpha)
This captures diminishing returns with model size and parallel copies, with a common irreducible floor.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points))
    n = np.clip(X[:, 0].astype(float), 1.0, None)
    s = np.clip(X[:, 1].astype(float), 1.0, None)
    p = np.asarray(params)
    if p.ndim == 1:
        L, c, a, k = p
        w = np.log(n) + k * np.log(s)
        return L + c * np.exp(-a * w)
    else:
        p = p.reshape(-1, 4)
        L = p[:, 0][None, :]
        c = p[:, 1][None, :]
        a = p[:, 2][None, :]
        k = p[:, 3][None, :]
        ln_n = np.log(n)[:, None]
        ln_s = np.log(s)[:, None]
        return L + c * np.exp(-a * (ln_n + k * ln_s))

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values).astype(float).ravel()
    n = np.clip(X[:, 0].astype(float), 1.0, None)
    s = np.clip(X[:, 1].astype(float), 1.0, None)
    ln_n = np.log(n)
    ln_s = np.log(s)

    ymin = float(np.min(y))
    # Grid-init via linearization on log residuals
    best = None
    for k0 in (0.0, 0.25, 0.5, 0.75, 1.0):
        for eps in (1e-3, 1e-2, 5e-2):
            L0 = ymin - eps
            z = y - L0
            if np.any(z &lt;= 0):
                continue
            w = ln_n + k0 * ln_s
            w_mean = w.mean()
            zln = np.log(z)
            b1 = np.dot(w - w_mean, zln - zln.mean()) / max(1e-12, np.dot(w - w_mean, w - w_mean))
            a0 = max(1e-6, -b1)
            c0 = float(np.exp(zln.mean() + a0 * w_mean))
            p0 = np.array([L0, c0, a0, k0], dtype=float)
            pred = scaling_law_func(X, p0)
            mse = float(np.mean((pred - y) ** 2))
            if (best is None) or (mse &lt; best[0]):
                best = (mse, p0)
    if best is None:
        # Fallback conservative init
        p0 = np.array([max(0.0, ymin - 1e-3), 0.5, 0.1, 0.2], dtype=float)
    else:
        p0 = best[1]

    # Bounds: L_inf &lt; min(y); c&gt;0; alpha&gt;0; k&gt;=0
    bounds = [(0.0, ymin - 1e-6), (1e-8, 10.0), (1e-6, 3.0), (0.0, 2.0)]

    def objective(p):
        pred = scaling_law_func(X, p)
        return np.mean((pred - y) ** 2)

    res = minimize(objective, p0, method=&quot;L-BFGS-B&quot;, bounds=bounds)
    return (res.x if res.success else p0).astype(float)
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999745 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
import numpy as np

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    N = np.clip(X[:, 0], 1e-12, None)
    S = np.clip(X[:, 1], 1e-12, None)
    lnN = np.log(N) - np.log(1e9)
    lnS = np.log(S) - np.log(2.0)

    p = np.asarray(params, dtype=np.float64)
    if p.ndim == 1: p = p[None, :]
    if p.shape[1] != 4: raise ValueError(&quot;params must have length 4&quot;)
    c, A, a, b = p[:, 0], p[:, 1], p[:, 2], p[:, 3]
    Z = np.exp(-a[None, :] * lnN[:, None] - b[None, :] * lnS[:, None])
    y = c[None, :] + A[None, :] * Z
    return y[:, 0] if y.shape[1] == 1 else y

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    y = np.asarray(loss_values, dtype=np.float64)
    Y = y[:, None] if y.ndim == 1 else y
    n, T = Y.shape

    N = np.clip(X[:, 0], 1e-12, None)
    S = np.clip(X[:, 1], 1e-12, None)
    lnN = np.log(N) - np.log(1e9)
    lnS = np.log(S) - np.log(2.0)

    def solve_cA(a, b, yt):
        Z = np.exp(-a * lnN - b * lnS)
        z1, z2 = Z.sum(), (Z*Z).sum()
        rhs = np.array([yt.sum(), (yt*Z).sum()], dtype=np.float64)
        M = np.array([[n + 1e-12, z1], [z1, z2 + 1e-12]], dtype=np.float64)
        try:
            cA = np.linalg.solve(M, rhs)
        except np.linalg.LinAlgError:
            cA = np.linalg.lstsq(M, rhs, rcond=None)[0]
        c, A = max(cA[0], 0.0), max(cA[1], 0.0)
        return c, A, Z

    params = np.zeros((T, 4), dtype=np.float64)
    a_grid = np.geomspace(0.02, 2.0, 16)
    b_grid = np.geomspace(0.02, 1.2, 16)

    for t in range(T):
        yt = Y[:, t]
        best = (np.inf, 0.2, 0.2, 0.0, 0.0)
        Za = {}
        for a in a_grid:
            Za[a] = np.exp(-a * lnN)
        for a in a_grid:
            for b in b_grid:
                Z = Za[a] * np.exp(-b * lnS)
                z1, z2 = Z.sum(), (Z*Z).sum()
                rhs = np.array([yt.sum(), (yt*Z).sum()], dtype=np.float64)
                M = np.array([[n + 1e-12, z1], [z1, z2 + 1e-12]], dtype=np.float64)
                try:
                    cA = np.linalg.solve(M, rhs)
                except np.linalg.LinAlgError:
                    cA = np.linalg.lstsq(M, rhs, rcond=None)[0]
                c0, A0 = max(cA[0], 0.0), max(cA[1], 0.0)
                mse = float(np.mean((c0 + A0 * Z - yt)**2))
                if mse &lt; best[0]:
                    best = (mse, a, b, c0, A0)
        _, a_opt, b_opt, c_opt, A_opt = best
        params[t] = np.array([c_opt, A_opt, a_opt, b_opt], dtype=np.float64)

    return params[0] if T == 1 else params
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#4</span>
              <span class="run-label">Run 5</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999686 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points))
    P = np.clip(X[:, 0].astype(float) / 1e9, 1e-12, None)
    S = np.clip(X[:, 1].astype(float), 1e-12, None)
    lnP, lnS = np.log(P), np.log(S)
    par = np.asarray(params, dtype=float)
    if par.ndim == 1:
        if par.size &lt; 4: par = np.pad(par, (0, 4 - par.size))
        L, c0, a, b = par[:4]
        z = np.clip(c0 - a * lnP - b * lnS, -50.0, 50.0)
        return L + np.exp(z)
    else:
        if par.shape[1] &lt; 4:
            par = np.hstack([par, np.zeros((par.shape[0], 4 - par.shape[1]))])
        L, c0, a, b = par[:, 0], par[:, 1], par[:, 2], par[:, 3]
        z = np.clip(c0[None, :] - a[None, :] * lnP[:, None] - b[None, :] * lnS[:, None], -50.0, 50.0)
        return L[None, :] + np.exp(z)

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values, dtype=float)
    Y = y[:, None] if y.ndim == 1 else y
    N, T = Y.shape
    P = np.clip(X[:, 0].astype(float) / 1e9, 1e-12, None)
    S = np.clip(X[:, 1].astype(float), 1e-12, None)
    lnP, lnS = np.log(P), np.log(S)
    out = np.zeros((T, 4), dtype=float)
    bounds = [(0.0, 5.0), (-10.0, 10.0), (1e-12, 5.0), (1e-12, 5.0)]

    def huber_loss_grad(theta, yt, delta, lam):
        L, c0, a, b = theta
        z = np.clip(c0 - a * lnP - b * lnS, -50.0, 50.0)
        ez = np.exp(z)
        pred = L + ez
        r = pred - yt
        ar = np.abs(r)
        m = ar &lt;= delta
        huber = np.where(m, 0.5 * r * r, delta * (ar - 0.5 * delta))
        g = np.where(m, r, delta * np.sign(r))
        c = 1.0 / yt.size
        dL = c * np.sum(g)
        dc0 = c * np.sum(g * ez)
        da = c * np.sum(g * (-ez * lnP)) + 2 * lam * a
        db = c * np.sum(g * (-ez * lnS)) + 2 * lam * b
        loss = float(np.mean(huber) + lam * (a * a + b * b))
        return loss, np.array([dL, dc0, da, db], dtype=float)

    for t in range(T):
        yt = Y[:, t]
        ymin, ymax = float(np.min(yt)), float(np.max(yt))
        yr = max(ymax - ymin, 1e-9)
        L0 = max(0.0, ymin - 0.05 * yr)
        resid = np.clip(yt - L0, 1e-8, None)
        D = np.column_stack([np.ones(N), -lnP, -lnS])
        w, *_ = np.linalg.lstsq(D, np.log(resid), rcond=None)
        c00 = float(w[0]); a0 = float(max(w[1], 1e-12)); b0 = float(max(w[2], 1e-12))
        base = np.array([L0, c00, a0, b0], dtype=float)
        seeds = [base,
                 np.array([L0 + 0.02 * yr, c00, a0, b0]),
                 np.array([L0, c00 + 0.2, a0 * 0.9, b0 * 1.1])]
        delta = 0.02 * yr + 1e-4
        lam = 1e-8
        bestx, bestf = base, np.inf
        for s in seeds:
            res = minimize(lambda th: huber_loss_grad(th, yt, delta, lam)[0],
                           s,
                           jac=lambda th: huber_loss_grad(th, yt, delta, lam)[1],
                           method=&#x27;L-BFGS-B&#x27;,
                           bounds=bounds)
            if res.success and res.fun &lt; bestf:
                bestx, bestf = res.x, res.fun
        out[t] = bestx
    return out[0] if T == 1 else out
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#5</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.999660 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    X = np.atleast_2d(np.asarray(data_points))
    N, P = X[:, 0], X[:, 1]
    p = np.asarray(params)
    if p.ndim == 1: p = p[None, :]
    if p.shape[1] &lt; 4: p = np.pad(p, ((0,0),(0,4-p.shape[1])), &#x27;constant&#x27;)
    a, b, c, g = p[:, 0], p[:, 1], p[:, 2], p[:, 3]
    N0 = 1e9
    NN = np.maximum(N[:, None] / N0, 1e-12)
    PP = np.maximum(P[:, None], 1e-12)
    pred = c[None, :] + np.maximum(a, 0.0)[None, :] * NN ** (-np.maximum(b, 0.0)[None, :]) * PP ** (-np.maximum(g, 0.0)[None, :])
    return pred[:, 0] if pred.shape[1] == 1 else pred

def fit_scaling_law(data_points, loss_values):
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    if X.shape[1] != 2:
        raise ValueError(&quot;data_points must have 2 columns: [num_params, parallel_size]&quot;)
    Y = y[:, None] if y.ndim == 1 else y
    N, P = X[:, 0], X[:, 1]
    N0 = 1e9
    NN = np.maximum(N / N0, 1e-12)
    PP = np.maximum(P, 1e-12)
    logN = np.log(NN)
    logP = np.log(PP)
    T = Y.shape[1]
    params_opt = np.zeros((T, 4), dtype=float)

    def softplus(z): return np.log1p(np.exp(-np.abs(z))) + np.maximum(z, 0.0)
    def inv_softplus(x): return np.log(np.expm1(np.maximum(x, 1e-12)))

    def preds_from_theta(theta):
        a = np.exp(theta[0])
        b = softplus(theta[1])
        c = theta[2]
        g = softplus(theta[3])
        return c + a * NN**(-b) * PP**(-g)

    def obj_theta(theta, yt):
        pred = preds_from_theta(theta)
        return float(np.mean((pred - yt)**2))

    for t in range(T):
        yt = Y[:, t]
        y_min = float(np.min(yt))
        A = np.column_stack([np.ones(len(N)), logN, logP])

        best_sse = np.inf
        best = None
        c_grid = np.linspace(max(0.0, y_min - 0.35), max(0.0, y_min - 1e-3), 20)
        for c_try in c_grid:
            z = yt - c_try
            if np.any(z &lt;= 1e-12): continue
            w, *_ = np.linalg.lstsq(A, np.log(z), rcond=None)
            a0 = float(np.exp(w[0])); b0 = float(-w[1]); g0 = float(-w[2])
            if a0 &lt;= 0 or b0 &lt; 0 or g0 &lt; 0: continue
            pred0 = c_try + a0 * NN**(-b0) * PP**(-g0)
            sse = float(np.sum((pred0 - yt)**2))
            if sse &lt; best_sse:
                best_sse = sse
                best = np.array([a0, b0, c_try, g0], dtype=float)

        if best is None:
            c0 = max(0.0, y_min - 0.05)
            z = np.maximum(yt - c0, 1e-9)
            w, *_ = np.linalg.lstsq(A, np.log(z), rcond=None)
            a0 = float(max(np.exp(w[0]), 1e-12))
            b0 = float(max(-w[1], 1e-12))
            g0 = float(max(-w[2], 1e-12))
            best = np.array([a0, b0, c0, g0], dtype=float)

        theta0 = np.array([np.log(best[0]), inv_softplus(best[1]), best[2], inv_softplus(best[3])], dtype=float)
        bounds = [(None, None), (None, None), (0.0, y_min), (None, None)]
        inits = [theta0,
                 theta0 + np.array([0.1, -0.1, 0.0, 0.1]),
                 theta0 + np.array([-0.1, 0.1, 0.0, -0.1])]

        best_val, best_theta = np.inf, theta0
        for init in inits:
            res = minimize(obj_theta, init, args=(yt,), method=&#x27;L-BFGS-B&#x27;, bounds=bounds)
            if res.success and res.fun &lt; best_val:
                best_val, best_theta = res.fun, res.x

        # Closed-form amplitude refinement given (b,g,c)
        b_star = softplus(best_theta[1]); g_star = softplus(best_theta[3]); c_star = best_theta[2]
        q = NN**(-b_star) * PP**(-g_star)
        denom = float(np.dot(q, q))
        a_cf = float(max(np.dot(q, yt - c_star) / max(denom, 1e-20), 1e-12))
        params_opt[t, :] = np.array([a_cf, b_star, c_star, g_star], dtype=float)

    return params_opt[0] if T == 1 else params_opt
# EVOLVE-BLOCK-END</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
