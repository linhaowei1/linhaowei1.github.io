<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - U-shaped Scaling Law - SLDAgent + Gemini 3 Pro Preview</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>U-shaped Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">SLDAgent</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">Gemini 3 Pro Preview</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        0.203487
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">-0.592851</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">-1.000000</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        R² = 0.203487
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import least_squares

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Predicts scaling law using an Exponential Trend + Gaussian Bump model.
    Model: y = p0 + p1*exp(-p2*x) + p3*exp(-((x-p5)*p4)^2)
    
    This function captures:
    1. The underlying power-law scaling (linear or exponential in log-feature space).
    2. Non-monotonic deviations (U-shaped performance) often seen in LLMs (double descent).
    
    Parameters (6 total):
    p0: Asymptote / Bias
    p1: Trend Amplitude
    p2: Trend Decay Rate (positive for decay)
    p3: Bump Amplitude (can be negative for a dip)
    p4: Bump Precision (inverse width)
    p5: Bump Center
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x_val = X[:, 0]
    
    params = np.asarray(params)
    if params.ndim == 1:
        params = params[None, :]
    
    # Unpack parameters
    p0 = params[:, 0]
    p1 = params[:, 1]
    p2 = params[:, 2]
    p3 = params[:, 3]
    p4 = params[:, 4]
    p5 = params[:, 5]
    
    # Term 1: Exponential Trend
    # y_trend = p1 * exp(-p2 * x)
    # Clip exponent to prevent overflow/underflow
    arg_trend = -p2[None, :] * x_val[:, None]
    term_trend = p1[None, :] * np.exp(np.clip(arg_trend, -50.0, 50.0))
    
    # Term 2: Gaussian Bump
    # y_bump = p3 * exp(-((x-p5)*p4)^2)
    dist = x_val[:, None] - p5[None, :]
    arg_bump = -((dist * p4[None, :])**2)
    term_bump = p3[None, :] * np.exp(np.clip(arg_bump, -50.0, 50.0))
    
    pred = p0[None, :] + term_trend + term_bump
    
    return pred[:, 0] if pred.shape[1] == 1 else pred

def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fits the Exp+Gauss model using a hybrid Grid Search (Variable Projection) 
    and Trust Region Reflective optimization.
    
    Strategy:
    1. Grid search over non-linear parameters (decay p2, bump width p4, bump center p5).
    2. Solve linear parameters (p0, p1, p3) using Ridge Regression for stability.
    3. Refine all parameters using non-linear least squares with bounds.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x_val = X[:, 0]
    y_data = np.asarray(loss_values)
    
    if y_data.ndim == 1:
        y_data = y_data[:, None]
        
    N, T = y_data.shape
    P = 6
    params_opt = np.zeros((T, P))
    
    # Grid Configuration
    x_min, x_max = np.min(x_val), np.max(x_val)
    x_span = x_max - x_min if x_max &gt; x_min else 1.0
    
    # p2 (Trend Decay): Range from slight growth (-0.5) to strong decay (3.0)
    # Most scaling laws have alpha in [0.1, 1.0] -&gt; p2 in [0.2, 2.3]
    p2_grid = np.concatenate([
        np.linspace(-0.5, 0.1, 3), 
        np.linspace(0.2, 2.5, 6)
    ])
    
    # p5 (Bump Center): Spaced evenly across data range
    p5_grid = np.linspace(x_min, x_max, 9)
    
    # p4 (Bump Inverse Width): 
    # From width ~ span (p4 ~ 1/span) to width ~ span/20 (p4 ~ 20/span)
    p4_grid = np.geomspace(1.5/x_span, 25.0/x_span, 5)
    
    ones_col = np.ones(N)
    ridge_alpha = 1e-7 # Small regularization
    
    # Precompute trend features for efficiency
    # List of (N,) arrays
    trend_feats = [np.exp(np.clip(-p2 * x_val, -50, 50)) for p2 in p2_grid]
    
    for t in range(T):
        yt = y_data[:, t]
        
        # Default fallback initialization
        best_init = np.array([np.mean(yt), 0.0, 0.0, 0.0, 1.0, np.mean(x_val)])
        best_mse = np.inf
        
        # --- Stage 1: Variable Projection Grid Search ---
        for i, p2 in enumerate(p2_grid):
            feat_trend = trend_feats[i]
            
            for p5 in p5_grid:
                dist_sq = (x_val - p5)**2
                
                for p4 in p4_grid:
                    # Gaussian Feature
                    feat_bump = np.exp(np.clip(-(p4**2) * dist_sq, -50, 50))
                    
                    # Design Matrix A: [1, trend, bump]
                    A = np.column_stack([ones_col, feat_trend, feat_bump])
                    
                    # Ridge Regression for linear coeffs [p0, p1, p3]
                    AtA = A.T @ A
                    AtA[np.diag_indices(3)] += ridge_alpha
                    Aty = A.T @ yt
                    
                    try:
                        coeffs = np.linalg.solve(AtA, Aty)
                        pred = A @ coeffs
                        mse = np.mean((pred - yt)**2)
                        
                        if mse &lt; best_mse:
                            best_mse = mse
                            best_init = np.array([coeffs[0], coeffs[1], p2, coeffs[2], p4, p5])
                    except:
                        continue
        
        # --- Stage 2: Non-linear Refinement ---
        def residuals(p):
            # p: [p0, p1, p2, p3, p4, p5]
            trend = p[1] * np.exp(np.clip(-p[2] * x_val, -50, 50))
            bump = p[3] * np.exp(np.clip(-((x_val - p[5]) * p[4])**2, -50, 50))
            return p[0] + trend + bump - yt
        
        # Robust Bounds
        # p2: [-2, 5]
        # p4: [0.01, inf]
        # p5: [min-span, max+span]
        lb = [-np.inf, -np.inf, -2.0, -np.inf, 0.01, x_min - x_span]
        ub = [np.inf, np.inf, 5.0, np.inf, np.inf, x_max + x_span]
        
        try:
            res = least_squares(residuals, best_init, method=&#x27;trf&#x27;, 
                                bounds=(lb, ub), loss=&#x27;linear&#x27;,
                                ftol=1e-8, xtol=1e-8, max_nfev=600)
            params_opt[t] = res.x
        except:
            params_opt[t] = best_init

    return params_opt[0] if T == 1 else params_opt
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -0.403198
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Predicts scaling law curve using a Quadratic + Gaussian model.
    Model: y = p0*x^2 + p1*x + p2 + p3*exp(-(p4*(x-p5))^2)
    Supports batch prediction if params is (T, 6).
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x_val = X[:, 0]
    
    params = np.asarray(params)
    squeeze_output = False
    if params.ndim == 1:
        params = params[None, :]
        squeeze_output = True
    
    # params shape: (T, 6)
    # Transpose to (6, T) to unpack into (1, T) arrays for broadcasting
    p = params.T 
    p0 = p[0:1, :] # (1, T)
    p1 = p[1:2, :]
    p2 = p[2:3, :]
    p3 = p[3:4, :]
    p4 = p[4:5, :]
    p5 = p[5:6, :]
    
    x = x_val[:, None] # (N, 1)
    
    # Quadratic: p0*x^2 + p1*x + p2
    # Broadcast (1, T) and (N, 1) -&gt; (N, T)
    poly = p0 * x**2 + p1 * x + p2
    
    # Gaussian: p3 * exp(-(p4*(x-p5))^2)
    exponent = - (p4 * (x - p5))**2
    gauss = p3 * np.exp(exponent)
    
    pred = poly + gauss
    
    if squeeze_output:
        return pred[:, 0]
    return pred

def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fits the Quadratic + Gaussian model using Robust Variable Projection &amp; Multi-Start Optimization.
    1. Normalizes input data for numerical stability.
    2. Performs a grid search for Gaussian parameters (center, scale) using Ridge Regression 
       to handle ill-conditioning.
    3. Selects top candidates (including pure quadratic) and refines them using L-BFGS-B with bounds.
    4. Transforms parameters back to original scale.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x_raw = X[:, 0]
    
    y = np.asarray(loss_values)
    if y.ndim == 1:
        y2d = y[:, None]
    else:
        y2d = y
    N, T = y2d.shape
    
    # Normalize inputs
    x_mean = np.mean(x_raw) if N &gt; 0 else 0.0
    x_std = np.std(x_raw) if N &gt; 1 else 1.0
    if x_std &lt; 1e-9: x_std = 1.0
    x_norm = (x_raw - x_mean) / x_std
    
    # Precompute polynomial features [x^2, x, 1]
    X_poly = np.column_stack((x_norm**2, x_norm, np.ones(N)))
    
    # Grid search configuration
    # Centers: cover the normalized range plus padding
    z_min, z_max = np.min(x_norm), np.max(x_norm)
    z_span = z_max - z_min if z_max &gt; z_min else 1.0
    mus = np.linspace(z_min - 0.5*z_span, z_max + 0.5*z_span, 15)
    
    # Scales: logarithmic spacing, avoiding too narrow (overfitting) or too wide (flat)
    scales = np.logspace(np.log10(0.5), np.log10(15.0), 10)
    
    params_opt = []
    
    for t in range(T):
        yt = y2d[:, t]
        
        # Insufficient data
        if N &lt; 5:
            p_mean = np.mean(yt) if N &gt; 0 else 0.0
            params_opt.append(np.array([0.0, 0.0, p_mean, 0.0, 1.0, 0.0]))
            continue

        candidates = [] # List of (mse, params_norm)
        alpha_reg = 1e-5 # Regularization for initialization stability

        # 0. Pure Quadratic Candidate
        try:
            AtA = X_poly.T @ X_poly + alpha_reg * np.eye(3)
            Aty = X_poly.T @ yt
            w_q = np.linalg.solve(AtA, Aty)
            pred_q = X_poly @ w_q
            mse_q = np.mean((yt - pred_q)**2)
            # Param form: [a, b, c, h=0, s=1, mu=0]
            candidates.append((mse_q, np.array([w_q[0], w_q[1], w_q[2], 0.0, 1.0, 0.0])))
        except:
            pass

        # 1. Grid Search (Variable Projection)
        for s in scales:
            for mu in mus:
                g_feat = np.exp(-(s * (x_norm - mu))**2)
                A = np.column_stack((X_poly, g_feat)) # (N, 4)
                
                AtA = A.T @ A
                AtA[np.diag_indices_from(AtA)] += alpha_reg
                Aty = A.T @ yt
                
                try:
                    w = np.linalg.solve(AtA, Aty) # [a, b, c, h]
                    pred = A @ w
                    mse = np.mean((yt - pred)**2)
                    p_cand = np.array([w[0], w[1], w[2], w[3], s, mu])
                    candidates.append((mse, p_cand))
                except:
                    continue
        
        # Select top 3 distinct candidates
        candidates.sort(key=lambda x: x[0])
        top_candidates = candidates[:3]
        if not top_candidates: # Fallback
             top_candidates = [(np.inf, np.array([0., 0., np.mean(yt), 0., 1., 0.]))]

        # 2. Refinement with L-BFGS-B
        # Bounds: a,b,c,h unbounded. s positive. mu limited.
        bounds = [
            (None, None), (None, None), (None, None), (None, None), 
            (0.1, 50.0), (z_min - 3.0, z_max + 3.0)
        ]
        
        def objective(p):
            # p: [a, b, c, h, s, mu]
            poly = p[0] * x_norm**2 + p[1] * x_norm + p[2]
            gauss = p[3] * np.exp(-(p[4] * (x_norm - p[5]))**2)
            return np.mean((poly + gauss - yt)**2)
            
        best_refined_mse = np.inf
        best_p_refined = top_candidates[0][1]
        
        for init_mse, init_p in top_candidates:
            try:
                res = minimize(objective, init_p, method=&#x27;L-BFGS-B&#x27;, bounds=bounds, tol=1e-7)
                if res.fun &lt; best_refined_mse:
                    best_refined_mse = res.fun
                    best_p_refined = res.x
            except:
                pass
                
        # 3. Denormalize
        a, b, c, h, s, mu = best_p_refined
        
        p0 = a / (x_std**2)
        p1 = b / x_std - 2 * a * x_mean / (x_std**2)
        p2 = c - b * x_mean / x_std + a * (x_mean**2) / (x_std**2)
        p3 = h
        p4 = s / x_std
        p5 = x_mean + mu * x_std
        
        params_opt.append([p0, p1, p2, p3, p4, p5])
        
    return np.array(params_opt[0]) if T == 1 else np.array(params_opt)
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -0.858028
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Scaling law discovery for U-shaped/Double-Descent patterns.
Implements a Robust Poly-Gaussian model (Quadratic + Gaussian) using Median/IQR normalization
and Variable Projection with Soft-L1 loss optimization to handle outliers and non-convexity.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Model: y = p0*x^2 + p1*x + p2 + p3*exp(-((x-p5)*p4)^2)
    Params: [p0, p1, p2, p3, p4, p5]
    &quot;&quot;&quot;
    x = np.atleast_2d(data_points)[:, 0]
    p = np.atleast_2d(params)
    
    # Broadcast x:(N,1) and p:(T,6) -&gt; (N,T)
    x_in = x[:, None]
    
    # Quadratic Trend
    trend = p[:, 0] * (x_in**2) + p[:, 1] * x_in + p[:, 2]
    
    # Gaussian Bump (Robust arg clamping)
    # p4 is inverse width, p5 is center
    arg = (x_in - p[:, 5]) * p[:, 4]
    gauss = p[:, 3] * np.exp(-np.clip(arg**2, 0, 100))
    
    pred = trend + gauss
    return pred[:, 0] if params.ndim == 1 else pred

def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fits parameters using Robust Variable Projection + L-BFGS-B.
    Strategy: Normalize -&gt; Grid Search (Ridge) -&gt; Refine (Soft-L1) -&gt; Denormalize
    &quot;&quot;&quot;
    X = np.atleast_2d(data_points)[:, 0]
    Y = np.atleast_2d(loss_values)
    if loss_values.ndim == 1: Y = Y.T
    
    N, T = Y.shape
    params_out = np.zeros((T, 6))
    
    # 1. Robust Normalization (Median/IQR)
    if N &lt; 2:
        x_m, x_s = 0.0, 1.0
    else:
        q25, q50, q75 = np.percentile(X, [25, 50, 75])
        iqr = q75 - q25
        x_m = q50
        x_s = iqr / 1.35 if iqr &gt; 1e-12 else (np.std(X) + 1e-9)
    x_n = (X - x_m) / x_s
    
    # Precompute basis
    Z = np.column_stack([x_n**2, x_n, np.ones(N)])
    
    # Grid Search Config
    mus = np.linspace(-2.5, 2.5, 12)
    gammas = np.logspace(np.log10(0.5), np.log10(10.0), 8)
    # Regularization: Penalize Curvature(p0) and Amp(p3) to prefer simple models
    reg = 1e-5 * N * np.array([1.0, 0.1, 0.0, 1.0])

    for t in range(T):
        y = Y[:, t]
        
        # Best candidate tracking
        best_loss = np.inf
        best_p = np.array([0.0, 0.0, np.mean(y) if N&gt;0 else 0, 0.0, 1.0, 0.0])
        
        # A. Baseline Linear/Quad (p3=0)
        if N &gt;= 3:
            AtA = Z.T @ Z + np.diag(reg[:3])
            try:
                w = np.linalg.solve(AtA, Z.T @ y) # [q0, q1, q2]
                l = np.mean((Z @ w - y)**2)
                if l &lt; best_loss:
                    best_loss = l
                    best_p = np.array([w[0], w[1], w[2], 0.0, 1.0, 0.0])
            except: pass
            
        # B. Gaussian Grid Search
        if N &gt;= 6:
            for mu in mus:
                d2 = (x_n - mu)**2
                for g in gammas:
                    feat_g = np.exp(-d2 * g**2)
                    A = np.column_stack([Z, feat_g])
                    
                    AtA = A.T @ A + np.diag(reg)
                    try:
                        w = np.linalg.solve(AtA, A.T @ y) # [q0,q1,q2,q3]
                        l = np.mean((A @ w - y)**2)
                        if l &lt; best_loss:
                            best_loss = l
                            best_p = np.array([w[0], w[1], w[2], w[3], g, mu])
                    except: continue

        # 2. Refinement (Soft-L1 Loss, L-BFGS-B)
        def loss_fn(p):
            # p=[q0,q1,q2,q3,q4,q5]
            trend = p[0]*Z[:,0] + p[1]*Z[:,1] + p[2]
            bump = p[3] * np.exp(-np.clip(((x_n-p[5])*p[4])**2, 0, 100))
            resid = trend + bump - y
            # Soft L1: sqrt(r^2 + eps)
            return np.sum(np.sqrt(resid**2 + 1e-8)) + 1e-4*np.sum(p[:4]**2)
        
        # Bounds: p4 &gt; 0.1 (non-flat), p5 in range
        bounds = [(None,None)]*4 + [(0.1, 20.0), (-5.0, 5.0)]
        
        try:
            res = minimize(loss_fn, best_p, method=&#x27;L-BFGS-B&#x27;, bounds=bounds, tol=1e-5)
            p_fin = res.x if res.success else best_p
        except:
            p_fin = best_p
        
        # 3. Denormalize
        q0, q1, q2, q3, q4, q5 = p_fin
        
        p0 = q0 / x_s**2
        p1 = q1/x_s - 2*q0*x_m/x_s**2
        p2 = q2 - q1*x_m/x_s + q0*x_m**2/x_s**2
        p3 = q3
        p4 = q4 / x_s
        p5 = x_m + q5 * x_s
        
        params_out[t] = [p0, p1, p2, p3, p4, p5]
        
    return params_out[0] if loss_values.ndim == 1 else params_out
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -0.906517
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Quadratic + Gaussian scaling law model.
    y = (p0*x^2 + p1*x + p2) + p3 * exp(-(p4*(x-p5))^2)
    Captures global trend and local double-descent features.
    &quot;&quot;&quot;
    X = np.asarray(data_points)
    x = X[:, 0] if X.ndim &gt; 1 else X
    
    params = np.asarray(params)
    squeeze = False
    if params.ndim == 1:
        params = params[None, :]
        squeeze = True
        
    p0, p1, p2 = params[:, 0], params[:, 1], params[:, 2]
    p3, p4, p5 = params[:, 3], params[:, 4], params[:, 5]
    
    # x: (N, 1), params: (1, T) -&gt; (N, T)
    x_col = x[:, None]
    
    trend = p0 * x_col**2 + p1 * x_col + p2
    arg = p4 * (x_col - p5)
    bump = p3 * np.exp(-(arg**2))
    
    pred = trend + bump
    return pred[:, 0] if squeeze else pred

def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fits parameters using a Residual-Guided Hybrid Search.
    1. Fits a robust global quadratic trend.
    2. Identifies candidate bump locations from residuals.
    3. Performs variable projection (linear solve for weights, optimization for shape).
    4. Refines best candidates with L-BFGS-B.
    &quot;&quot;&quot;
    X = np.asarray(data_points)
    x = X[:, 0] if X.ndim &gt; 1 else X
    Y = np.asarray(loss_values)
    
    squeeze = False
    if Y.ndim == 1:
        Y = Y[:, None]
        squeeze = True
        
    N, T = Y.shape
    params_opt = np.zeros((T, 6))
    
    # Normalize Inputs
    x_mean, x_std = np.mean(x), np.std(x)
    if x_std &lt; 1e-9: x_std = 1.0
    xn = (x - x_mean) / x_std
    
    # Polynomial features [x^2, x, 1]
    X_poly = np.column_stack((xn**2, xn, np.ones(N)))
    
    # Grid for widths (geometric progression)
    p4_grid = np.geomspace(0.5, 15.0, 8)
    
    for t in range(T):
        yt = Y[:, t]
        y_mean, y_std = np.mean(yt), np.std(yt)
        if y_std &lt; 1e-9: y_std = 1.0
        yn = (yt - y_mean) / y_std
        
        candidates = []
        
        # 1. Baseline Quadratic Fit &amp; Residual Analysis
        try:
            # Ridge regression for baseline
            A_poly = X_poly
            ATA = A_poly.T @ A_poly + 1e-6 * np.eye(3)
            ATy = A_poly.T @ yn
            c_poly = np.linalg.solve(ATA, ATy)
            
            pred_poly = A_poly @ c_poly
            residuals = yn - pred_poly
            
            # Add baseline as candidate (bump height=0)
            candidates.append((np.mean(residuals**2), np.append(c_poly, 0.0), 1.0, 0.0))
            
            # Identify peaks in residuals
            # Use top few indices with largest absolute error to seed center search
            idx_sorted = np.argsort(np.abs(residuals))[::-1]
            top_idxs = idx_sorted[:5] # Check top 5 outliers
            heuristic_centers = xn[top_idxs]
            
            # Sparse global grid to ensure coverage
            global_centers = np.linspace(np.min(xn), np.max(xn), 5)
            centers = np.unique(np.concatenate((heuristic_centers, global_centers)))
            
            # 2. Hybrid Grid Search (VarPro)
            for mu in centers:
                for p4 in p4_grid:
                    # Gaussian feature
                    g_vec = np.exp(-(p4 * (xn - mu))**2)
                    A = np.column_stack((X_poly, g_vec))
                    
                    # Solve linear params [p0, p1, p2, p3]
                    ATA = A.T @ A
                    ATA[np.diag_indices(4)] += 1e-6 # Regularization
                    ATy = A.T @ yn
                    c = np.linalg.solve(ATA, ATy)
                    
                    pred = A @ c
                    mse = np.mean((pred - yn)**2)
                    candidates.append((mse, c, p4, mu))
        except np.linalg.LinAlgError:
            # Fallback
            candidates.append((np.inf, np.zeros(4), 1.0, 0.0))

        # 3. Refinement of Best Candidates
        candidates.sort(key=lambda x: x[0])
        best_final_mse = np.inf
        best_p_norm = np.zeros(6)
        
        # Optimize top 2 distinct candidates
        for i in range(min(2, len(candidates))):
            mse_init, c, p4_init, mu_init = candidates[i]
            p_init = np.array([c[0], c[1], c[2], c[3], p4_init, mu_init])
            
            def objective(p):
                # Unpack
                poly = p[0]*xn**2 + p[1]*xn + p[2]
                bump = p[3] * np.exp(-(p[4] * (xn - p[5]))**2)
                return np.mean((poly + bump - yn)**2)
            
            # Bounds: Width must be positive. Center can wander slightly.
            bounds = [(None,None)]*4 + [(0.1, 50.0), (np.min(xn)-1.0, np.max(xn)+1.0)]
            
            try:
                res = minimize(objective, p_init, method=&#x27;L-BFGS-B&#x27;, bounds=bounds, tol=1e-6)
                if res.fun &lt; best_final_mse:
                    best_final_mse = res.fun
                    best_p_norm = res.x
            except:
                if mse_init &lt; best_final_mse:
                    best_final_mse = mse_init
                    best_p_norm = p_init

        # 4. Denormalize Parameters
        a, b, c, h, p4n, mun = best_p_norm
        
        # Trend: y = y_std * (a*((x-xm)/xs)^2 + ...) + y_mean
        p0 = a * y_std / x_std**2
        p1 = b * y_std / x_std - 2 * p0 * x_mean
        p2 = c * y_std + y_mean - p1 * x_mean - p0 * x_mean**2
        
        # Gaussian: h*y_std * exp(-(p4n/xs * (x - (mun*xs+xm)))^2)
        p3 = h * y_std
        p4 = p4n / x_std
        p5 = mun * x_std + x_mean
        
        params_opt[t] = [p0, p1, p2, p3, p4, p5]

    return params_opt[0] if squeeze else params_opt
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -1.000000
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Scaling law discovery for LLM finetuning.
Model: Quadratic Trend + Gaussian Bump (6 parameters).
Features:
- Normalized coordinate system for robust optimization across different scales.
- Top-K Grid Search with Variable Projection (VarPro) for reliable initialization.
- Constrained Trust Region Reflective (TRF) optimization to enforce physical constraints.
- Specifically enforces positive bump height (p3 &gt;= 0) to model double descent degradation.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import least_squares

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Predicts scaling curve: y = p0*x^2 + p1*x + p2 + p3*exp(-((x-p5)*p4)^2)
    Params: [p0, p1, p2, p3, p4, p5]
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x = X[:, 0]
    
    p = np.asarray(params)
    if p.ndim == 1: p = p[None, :]
    
    # Unpack parameters:
    # p0, p1, p2: Quadratic trend
    # p3: Bump height
    # p4: Inverse width (1/sigma)
    # p5: Bump center
    
    # Broadcast x for vectorized computation: (1, N)
    x_in = x[None, :]
    
    # Quadratic Trend
    trend = p[:, 0:1] * (x_in**2) + p[:, 1:2] * x_in + p[:, 2:3]
    
    # Gaussian Bump
    # Clip exponent argument to prevent numerical overflow/underflow
    # Squared form inside exp ensures symmetry and stability
    arg = ((x_in - p[:, 5:6]) * p[:, 4:5])**2
    bump = p[:, 3:4] * np.exp(-np.clip(arg, 0, 100.0))
    
    pred = trend + bump
    
    # Return (N,) if single param set, else (N, M) -&gt; Transpose to (N, M) if M &gt; 1
    return pred[0] if pred.shape[0] == 1 else pred.T

def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fits parameters using Normalized Grid Search + Constrained TRF optimization.
    
    Strategy:
    1. Normalize input x to [-1, 1] range to standardize the grid search for width/center.
    2. Perform Grid Search over Gaussian parameters (center, width).
    3. Use Variable Projection (Linear Least Squares) to solve for linear params (trend + height) at each grid point.
    4. Enforce p3 &gt;= 0 (positive bump) to correctly model double descent &quot;peaks&quot; in error.
    5. Refine best candidates using constrained Non-Linear Least Squares (TRF).
    6. Denormalize parameters back to original scale.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    x_raw = X[:, 0]
    y_raw = np.asarray(loss_values)
    if y_raw.ndim == 1: y_raw = y_raw[:, None]
    
    N, T = y_raw.shape
    params_opt = np.zeros((T, 6))
    
    # 1. Normalize x for numerical stability
    x_min, x_max = np.min(x_raw), np.max(x_raw)
    x_mid = (x_min + x_max) / 2.0
    x_scale = (x_max - x_min) / 2.0 if (x_max - x_min) &gt; 1e-6 else 1.0
    x = (x_raw - x_mid) / x_scale
    
    # Pre-compute polynomial basis [x^2, x, 1]
    X_poly = np.vstack([x**2, x, np.ones(N)]).T
    
    # Grid Configuration
    # Centers in normalized coords [-1.5, 1.5] to catch edge effects
    mus = np.linspace(-1.5, 1.5, 20)
    # Widths (inverse sigma): from broad (0.5) to sharp (50.0) in normalized units
    p4s = np.logspace(np.log10(0.5), np.log10(50.0), 10)
    
    for t in range(T):
        yt = y_raw[:, t]
        candidates = []
        
        # A. Baseline Quadratic Fit (p3=0)
        try:
            if N &gt;= 3:
                c = np.polyfit(x, yt, 2)
                pred = np.polyval(c, x)
                mse = np.mean((pred - yt)**2)
                # p_model = [c0, c1, c2, 0, 1, 0]
                candidates.append((mse, np.array([c[0], c[1], c[2], 0.0, 1.0, 0.0])))
            else:
                candidates.append((np.var(yt), np.array([0.0, 0.0, np.mean(yt), 0.0, 1.0, 0.0])))
        except: pass
        
        # B. Grid Search (Variable Projection)
        if N &gt;= 5:
            for mu in mus:
                d2 = (x - mu)**2
                for p4 in p4s:
                    # Gaussian basis
                    g = np.exp(-np.clip(d2 * (p4**2), 0, 100))
                    A = np.column_stack([X_poly, g])
                    
                    try:
                        coeffs, resid, _, _ = np.linalg.lstsq(A, yt, rcond=None)
                        mse = resid[0]/N if resid.size &gt; 0 else np.mean((A @ coeffs - yt)**2)
                        
                        # Heuristic: Penalize negative bumps (dips) to prioritize &quot;bump&quot; solutions
                        # We want p3 &gt; 0 for double descent peaks
                        if coeffs[3] &lt; 0:
                            mse *= 2.0 
                            
                        candidates.append((mse, np.array([coeffs[0], coeffs[1], coeffs[2], coeffs[3], p4, mu])))
                    except: continue

        # C. Refine Best Candidate
        if not candidates:
            # Fallback
            params_opt[t] = np.array([0, 0, np.mean(yt), 0, 1, x_mid])
            continue
            
        candidates.sort(key=lambda x: x[0])
        best_p_norm = candidates[0][1]
        
        # Ensure starting point respects constraint p3 &gt;= 0
        if best_p_norm[3] &lt; 0: best_p_norm[3] = 0.0
        
        # Constraints: 
        # p3 &gt;= 0 (positive bump), p4 &gt;= 0.1 (minimum width), p5 within reasonable range
        lb = [-np.inf, -np.inf, -np.inf, 0.0, 0.1, -3.0]
        ub = [np.inf, np.inf, np.inf, np.inf, 200.0, 3.0]
        
        def resid_fn(p):
            t_val = p[0]*x**2 + p[1]*x + p[2]
            b_val = p[3] * np.exp(-np.clip(((x - p[5])*p[4])**2, 0, 100))
            return (t_val + b_val) - yt
            
        try:
            res = least_squares(resid_fn, best_p_norm, bounds=(lb, ub), method=&#x27;trf&#x27;, max_nfev=100)
            best_p_norm = res.x
        except: pass
        
        # D. Denormalize parameters to original scale
        A, B, C, H, p4n, mun = best_p_norm
        
        # Quadratic transform: A((x-m)/s)^2 + B((x-m)/s) + C
        p0 = A / (x_scale**2)
        p1 = B / x_scale - 2 * A * x_mid / (x_scale**2)
        p2 = C - B * x_mid / x_scale + A * (x_mid**2) / (x_scale**2)
        
        # Gaussian transform
        p3 = H
        p4 = p4n / x_scale
        p5 = x_mid + mun * x_scale
        
        params_opt[t] = np.array([p0, p1, p2, p3, p4, p5])
        
    return params_opt[0] if T==1 else params_opt
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>