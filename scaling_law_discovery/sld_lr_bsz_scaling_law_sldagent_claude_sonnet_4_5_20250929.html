<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - LR & Batch Size Scaling Law - SLDAgent + Claude Sonnet 4.5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>LR & Batch Size Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">SLDAgent</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">Claude Sonnet 4.5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        0.227188
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">-0.068944</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">-1.000000</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        R² = 0.227188
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Theoretically-grounded scaling law with adaptive hyperparameter dynamics
Combines Chinchilla scaling with gradient noise theory and critical batch effects
Key innovation: Adaptive optimal lr that depends on model/data scale
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import differential_evolution, minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    10-parameter scaling law with adaptive hyperparameter optimum:
    L = A + B/N^α + C/D^β + E*lr²/(bsz^γ + ε) + F*(log(lr) - lr_opt(N,D))² + G*log(lr)*log(bsz)
    
    Key features:
    1. Chinchilla power laws: B/N^α + C/D^β
    2. Gradient noise: E*lr²/(bsz^γ + ε) - captures noise-to-signal ratio
    3. Adaptive lr optimum: lr_opt depends on log(N) and log(D) 
    4. lr-bsz interaction: G*log(lr)*log(bsz) captures critical batch dynamics
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    params = np.asarray(params, dtype=np.float64)
    
    if params.ndim == 1:
        params = params[None, :]
    
    # Safe extraction with appropriate clipping
    lr = np.clip(X[:, 0], 1e-10, 1.0)
    bsz = np.clip(X[:, 1], 1.0, 1e6)
    data_size = np.clip(X[:, 2], 1e9, 1e12)
    model_params = np.clip(X[:, 3], 1e7, 1e10)
    
    # Extract 10 parameters with constraints
    A = params[:, 0]                                    # Irreducible loss
    B = np.clip(np.abs(params[:, 1]), 0.01, 12.0)     # Model coefficient
    alpha = np.clip(params[:, 2], 0.02, 0.4)          # Model exponent
    C = np.clip(np.abs(params[:, 3]), 0.01, 12.0)     # Data coefficient
    beta = np.clip(params[:, 4], 0.02, 0.4)           # Data exponent
    E = np.clip(np.abs(params[:, 5]), 0.0, 6.0)       # Noise coefficient
    gamma = np.clip(params[:, 6], 0.15, 0.85)         # Noise exponent
    F = np.clip(np.abs(params[:, 7]), 0.0, 4.0)       # LR penalty coefficient
    k_lr = np.clip(params[:, 8], -0.5, 0.0)           # LR optimum scaling factor
    G = np.clip(params[:, 9], -1.2, 1.2)              # LR-BSZ interaction
    
    # Log transformations for stability
    log_lr = np.log(lr)
    log_bsz = np.log(bsz)
    log_N = np.log(model_params)
    log_D = np.log(data_size)
    
    # Core Chinchilla scaling
    N_term = B[:, None] / (model_params[None, :] ** alpha[:, None])
    D_term = C[:, None] / (data_size[None, :] ** beta[:, None])
    
    # Gradient noise term: lr²/(bsz^γ + ε)
    # Captures: larger lr increases noise, larger bsz reduces it
    noise_term = E[:, None] * (lr[None, :] ** 2) / (bsz[None, :] ** gamma[:, None] + 100.0)
    
    # Adaptive optimal learning rate (theory: lr_opt ~ 1/sqrt(N*D))
    # Using k_lr as scaling: lr_opt_log = k_lr * (log_N + log_D)
    lr_opt_adaptive = k_lr[:, None] * (log_N[None, :] + log_D[None, :])
    
    # LR penalty (quadratic in log space around adaptive optimum)
    lr_penalty = F[:, None] * (log_lr[None, :] - lr_opt_adaptive) ** 2
    
    # LR-BSZ multiplicative interaction (critical batch size theory)
    lr_bsz_interaction = G[:, None] * log_lr[None, :] * log_bsz[None, :]
    
    # Total loss
    pred = (A[:, None] + N_term + D_term + noise_term + 
            lr_penalty + lr_bsz_interaction)
    
    return pred[0, :] if pred.shape[0] == 1 else pred.T


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Robust multi-stage optimization with adaptive weighting and extensive multi-start
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    y = np.asarray(loss_values, dtype=np.float64)
    
    if y.ndim == 1:
        y = y[:, None]
    
    # Compute robust statistics
    loss_min = np.percentile(y, 5)
    loss_max = np.percentile(y, 95)
    loss_median = np.median(y)
    
    # Well-informed parameter bounds (10 parameters)
    bounds = [
        (loss_min - 0.25, loss_min + 0.35),  # A: near minimum
        (0.08, 10.0),     # B: model coefficient
        (0.04, 0.35),     # alpha: model exponent (Chinchilla: ~0.07-0.2)
        (0.08, 10.0),     # C: data coefficient
        (0.04, 0.35),     # beta: data exponent
        (0.0, 5.0),       # E: noise coefficient
        (0.2, 0.75),      # gamma: noise exponent
        (0.0, 3.5),       # F: lr penalty
        (-0.4, -0.05),    # k_lr: lr optimum scaling (negative for inverse relationship)
        (-1.0, 1.0),      # G: lr-bsz interaction
    ]
    
    def objective(params):
        try:
            pred = scaling_law_func(X, params)
            if pred.ndim == 1:
                pred = pred[:, None]
            
            residuals = pred - y
            
            # Stratified weighting: emphasize different loss regions
            # More weight on low losses (well-trained models) and mid-range
            weights_low = np.exp(-3.0 * np.abs(y - loss_min) / (loss_max - loss_min))
            weights_mid = np.exp(-2.0 * np.abs(y - loss_median) / (loss_max - loss_min))
            weights = 0.6 * weights_low + 0.4 * weights_mid
            weights = weights / np.mean(weights)
            
            # Hybrid loss: 75% weighted MSE + 25% MAE for robustness
            mse = np.mean(weights * residuals ** 2)
            mae = np.mean(np.abs(residuals))
            loss = 0.75 * mse + 0.25 * mae
            
            # Tiered regularization: lighter on core terms, moderate on others
            reg_core = 5e-7 * (params[1]**2 + params[3]**2)
            reg_hp = 1e-6 * (params[5]**2 + params[7]**2)
            reg_inter = 8e-7 * params[9]**2
            
            return loss + reg_core + reg_hp + reg_inter
        except:
            return 1e10
    
    # Stage 1: Extended global search with differential evolution
    result_de = differential_evolution(
        objective,
        bounds,
        maxiter=200,
        popsize=22,
        tol=1e-9,
        atol=1e-9,
        seed=42,
        workers=1,
        polish=False,
        strategy=&#x27;best1bin&#x27;,
        updating=&#x27;deferred&#x27;
    )
    
    # Stage 2: Local refinement with L-BFGS-B
    result_local = minimize(
        objective,
        result_de.x,
        method=&#x27;L-BFGS-B&#x27;,
        bounds=bounds,
        options={&#x27;maxiter&#x27;: 600, &#x27;ftol&#x27;: 1e-12, &#x27;gtol&#x27;: 1e-10}
    )
    
    # Track best result
    best_result = result_local if result_local.success else result_de
    best_loss = best_result.fun
    
    # Stage 3: Extensive multi-start with systematic perturbations
    perturbation_scales = [0.98, 1.02, 0.96, 1.04, 0.94, 1.06, 0.92, 1.08, 0.97, 1.03]
    
    for scale in perturbation_scales:
        x0 = np.clip(
            best_result.x * scale,
            [b[0] for b in bounds],
            [b[1] for b in bounds]
        )
        
        result = minimize(
            objective,
            x0,
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds,
            options={&#x27;maxiter&#x27;: 400, &#x27;ftol&#x27;: 1e-12, &#x27;gtol&#x27;: 1e-10}
        )
        
        if result.success and result.fun &lt; best_loss:
            best_loss = result.fun
            best_result = result
    
    # Stage 4: Final polish with Powell (derivative-free, can escape shallow minima)
    try:
        result_powell = minimize(
            objective,
            best_result.x,
            method=&#x27;Powell&#x27;,
            options={&#x27;maxiter&#x27;: 150, &#x27;ftol&#x27;: 1e-11}
        )
        
        if result_powell.success and result_powell.fun &lt; best_loss:
            params_opt = result_powell.x
        else:
            params_opt = best_result.x
    except:
        params_opt = best_result.x
    
    return params_opt if y.shape[1] == 1 else params_opt[None, :]
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        R² = 0.223694
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Enhanced scaling law with physically-motivated hyperparameter modeling.
Incorporates asymmetric learning rate effects, gradient noise from batch size,
and cross-scale interactions based on training dynamics theory.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution, dual_annealing

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Extended Chinchilla-style scaling law with training dynamics:
    loss = A/N^alpha + B/D^beta + C + lr_effects + bsz_effects + interactions
    
    Key physics-inspired features:
    - Asymmetric lr penalty (too high causes divergence, too low causes slow convergence)
    - Batch size gradient noise: smaller batches add regularization
    - Data-parameter interaction: overtraining vs undertraining regimes
    - Learning rate schedule approximation via effective lr
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    lr, bsz, data_size, param_size = X[:, 0], X[:, 1], X[:, 2], X[:, 3]
    
    params = np.asarray(params, dtype=np.float64)
    if len(params) &lt; 13:
        params = np.pad(params, (0, 13 - len(params)), constant_values=0.0)
    
    # Core Chinchilla parameters with tighter control
    A = np.abs(params[0]) + 1e-10
    alpha = np.clip(params[1], 0.1, 0.8)  # Narrower range based on empirical data
    B = np.abs(params[2]) + 1e-10
    beta = np.clip(params[3], 0.1, 0.8)
    C = params[4]  # Irreducible loss
    
    # Learning rate parameters with asymmetry
    lr_opt = np.clip(np.abs(params[5]), 5e-5, 5e-3)  # Optimal lr
    lr_penalty_low = np.abs(params[6])  # Penalty for lr &lt; lr_opt
    lr_penalty_high = np.abs(params[7])  # Penalty for lr &gt; lr_opt (usually stronger)
    
    # Batch size gradient noise effects
    bsz_noise_coeff = params[8]  # Gradient noise benefit
    bsz_scale = np.clip(np.abs(params[9]), 32, 512)  # Characteristic batch size
    
    # Cross-scale interactions
    data_param_ratio_coeff = params[10]  # D/N ratio effect (compute-optimal)
    lr_data_interact = params[11]  # lr × data interaction
    lr_param_interact = params[12]  # lr × param interaction
    
    # Safe clipping with wider ranges
    param_size_safe = np.clip(param_size, 5e7, 2e9)
    data_size_safe = np.clip(data_size, 1e9, 2e11)
    lr_safe = np.clip(lr, 1e-5, 0.05)
    bsz_safe = np.clip(bsz, 8, 4096)
    
    # Base Chinchilla loss
    loss = C + A / (param_size_safe ** alpha) + B / (data_size_safe ** beta)
    
    # Asymmetric learning rate penalty
    log_lr_ratio = np.log(lr_safe / lr_opt)
    # Use different penalties for too high vs too low
    lr_penalty = np.where(
        log_lr_ratio &gt; 0,
        lr_penalty_high * log_lr_ratio ** 2,  # Too high: divergence risk
        lr_penalty_low * log_lr_ratio ** 2    # Too low: slow convergence
    )
    loss += lr_penalty
    
    # Batch size gradient noise effect
    # Smaller batches provide regularization, modeled as:
    # noise_effect ~ 1/sqrt(bsz) scaled by distance from characteristic batch size
    bsz_ratio = bsz_safe / bsz_scale
    loss += bsz_noise_coeff * (1.0 / np.sqrt(bsz_ratio) - 1.0)
    
    # Data-parameter ratio (compute-optimal allocation)
    # Penalty when D/N deviates from optimal ratio
    data_param_ratio = data_size_safe / param_size_safe
    log_ratio = np.log(data_param_ratio)
    loss += data_param_ratio_coeff * log_ratio ** 2
    
    # Learning rate interactions with scale
    # lr affects how well model can utilize data/parameters
    loss += lr_data_interact * np.log(lr_safe) * np.log(data_size_safe / 1e10)
    loss += lr_param_interact * np.log(lr_safe) * np.log(param_size_safe / 1e8)
    
    return loss


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Multi-stage optimization with adaptive strategy selection.
    Uses simulated annealing for exploration, then local refinement.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    y = np.asarray(loss_values, dtype=np.float64)
    
    # Data statistics for initialization
    min_loss = np.min(y)
    median_loss = np.median(y)
    p10_loss = np.percentile(y, 10)
    
    # Physics-informed initialization
    init_params = np.array([
        80.0,           # A - parameter coefficient
        0.35,           # alpha - parameter exponent
        40.0,           # B - data coefficient
        0.28,           # beta - data exponent
        p10_loss,       # C - baseline irreducible loss
        0.0008,         # lr_opt - optimal learning rate
        0.3,            # lr_penalty_low
        0.8,            # lr_penalty_high (stronger for too-high lr)
        0.02,           # bsz_noise_coeff
        128.0,          # bsz_scale
        0.0,            # data_param_ratio_coeff
        0.0,            # lr_data_interact
        0.0             # lr_param_interact
    ])
    
    def objective(params):
        try:
            pred = scaling_law_func(X, params)
            if not np.all(np.isfinite(pred)):
                return 1e10
            residuals = pred - y
            mse = np.mean(residuals ** 2)
            # Regularization to prefer simpler models
            reg = 1e-8 * (params[0]**2 + params[2]**2 + params[6]**2 + params[7]**2)
            return mse + reg
        except:
            return 1e10
    
    # Carefully designed bounds based on physical constraints
    bounds = [
        (1.0, 500),         # A
        (0.1, 0.8),         # alpha (tighter based on theory)
        (1.0, 500),         # B
        (0.1, 0.8),         # beta (tighter based on theory)
        (min_loss - 0.1, median_loss),  # C
        (1e-5, 0.01),       # lr_opt
        (0.01, 3.0),        # lr_penalty_low
        (0.01, 5.0),        # lr_penalty_high
        (-0.2, 0.2),        # bsz_noise_coeff
        (16, 1024),         # bsz_scale
        (-0.1, 0.1),        # data_param_ratio_coeff
        (-0.02, 0.02),      # lr_data_interact
        (-0.02, 0.02)       # lr_param_interact
    ]
    
    best_params = init_params
    best_score = objective(init_params)
    
    try:
        # Stage 1: Dual annealing for robust global optimization
        result_sa = dual_annealing(
            objective,
            bounds,
            maxiter=200,
            seed=42,
            no_local_search=True
        )
        
        if result_sa.fun &lt; best_score:
            best_params = result_sa.x
            best_score = result_sa.fun
        
        # Stage 2: Differential evolution as backup/refinement
        result_de = differential_evolution(
            objective,
            bounds,
            maxiter=120,
            popsize=15,
            seed=123,
            atol=1e-10,
            tol=1e-10,
            workers=1,
            init=&#x27;latinhypercube&#x27;,
            polish=False
        )
        
        if result_de.fun &lt; best_score:
            best_params = result_de.x
            best_score = result_de.fun
        
        # Stage 3: Local refinement with multiple methods
        for method in [&#x27;L-BFGS-B&#x27;, &#x27;TNC&#x27;]:
            result_local = minimize(
                objective,
                best_params,
                method=method,
                bounds=bounds,
                options={&#x27;maxiter&#x27;: 1500, &#x27;ftol&#x27;: 1e-13}
            )
            
            if result_local.success and result_local.fun &lt; best_score:
                best_params = result_local.x
                best_score = result_local.fun
        
        # Stage 4: Final polish with Nelder-Mead (unbounded, starts from best)
        result_nm = minimize(
            objective,
            best_params,
            method=&#x27;Nelder-Mead&#x27;,
            options={&#x27;maxiter&#x27;: 800, &#x27;xatol&#x27;: 1e-11, &#x27;fatol&#x27;: 1e-11}
        )
        
        if result_nm.fun &lt; best_score:
            best_params = result_nm.x
            
    except Exception as e:
        print(f&quot;Optimization warning: {e}, using best found parameters&quot;)
    
    return best_params
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #D2691E; color: white;">
                        R² = 0.217225
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Improved scaling law with multiplicative interactions and robust fitting.
Based on Chinchilla principles with enhanced optimizer dynamics modeling.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: L = (A/N^alpha + B/D^beta) * (1 + C*lr_term + E*bsz_term + H*lr_bsz_term) + F
    
    Key improvements:
    - Multiplicative form captures interaction between base loss and optimizer effects
    - More stable numerically
    - Theoretically motivated from optimization dynamics
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    params = np.asarray(params, dtype=np.float64)
    
    lr = X[:, 0]
    bsz = X[:, 1]
    D = X[:, 2]
    N = X[:, 3]
    
    # Unpack parameters (8 total - simplified)
    A = np.abs(params[0])       # Model size coefficient
    alpha = np.abs(params[1])   # Model size exponent
    B = np.abs(params[2])       # Data size coefficient
    beta = np.abs(params[3])    # Data size exponent
    C = np.abs(params[4])       # LR sensitivity
    E = np.abs(params[5])       # Batch size sensitivity
    H = np.abs(params[6])       # LR-BSZ interaction
    F = params[7]               # Irreducible loss offset
    
    # Numerical stability with tighter clipping
    N_safe = np.clip(N, 1e7, 1e10)
    D_safe = np.clip(D, 1e9, 1e12)
    lr_safe = np.clip(lr, 1e-5, 0.1)
    bsz_safe = np.clip(bsz, 8.0, 4096.0)
    
    # Core Chinchilla power laws
    base_loss = A / np.power(N_safe, alpha) + B / np.power(D_safe, beta)
    
    # Optimal LR scales with model size: lr_opt ~ N^(-0.5)
    lr_optimal = 0.003 * np.power(N_safe / 2e8, -0.5)
    lr_optimal = np.clip(lr_optimal, 5e-5, 0.02)
    
    # LR term: asymmetric penalty (worse when too high)
    lr_ratio = lr_safe / lr_optimal
    lr_log = np.log(lr_ratio)
    # Asymmetric: higher penalty for lr too high than too low
    lr_term = np.where(lr_log &gt; 0, lr_log**2, 0.7 * lr_log**2)
    
    # Optimal batch size scales with data and model
    bsz_optimal = 128.0 * np.power(D_safe / 2e10, 0.2) * np.power(N_safe / 2e8, 0.15)
    bsz_optimal = np.clip(bsz_optimal, 32.0, 1024.0)
    
    # BSZ term: symmetric in log space
    bsz_ratio = bsz_safe / bsz_optimal
    bsz_log = np.log(bsz_ratio)
    bsz_term = bsz_log**2
    
    # Interaction term: LR and BSZ interact (gradient noise effects)
    # When both are suboptimal in same direction, penalty increases
    lr_bsz_term = lr_log * bsz_log
    
    # Multiplicative form: optimizer effects scale with base loss
    # This is more theoretically sound - larger models are more sensitive
    optimizer_multiplier = 1.0 + C * lr_term + E * bsz_term + H * lr_bsz_term
    
    pred = base_loss * optimizer_multiplier + F
    
    return pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Robust two-stage fitting: global search + local refinement.
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    y = np.asarray(loss_values, dtype=np.float64)
    
    y_min = np.min(y)
    y_max = np.max(y)
    y_mean = np.mean(y)
    y_std = np.std(y)
    
    def objective(params):
        try:
            pred = scaling_law_func(X, params)
            pred = np.clip(pred, y_min - y_std, y_max + y_std)
            
            residuals = pred - y
            
            # Weighted combination: MAE for robustness, MSE for accuracy
            mae = np.mean(np.abs(residuals))
            mse = np.mean(residuals ** 2)
            loss = 0.4 * mae + 0.6 * mse
            
            # Regularization toward Chinchilla values
            reg = 0.005 * ((params[1] - 0.34)**2 + (params[3] - 0.28)**2)
            
            # Penalize extreme interactions
            reg += 0.002 * params[6]**2
            
            return loss + reg
        except:
            return 1e10
    
    # Parameter bounds: [A, alpha, B, beta, C, E, H, F]
    bounds = [
        (1.0, 60.0),            # A
        (0.15, 0.55),           # alpha (Chinchilla: ~0.34)
        (1.0, 60.0),            # B
        (0.15, 0.45),           # beta (Chinchilla: ~0.28)
        (0.0, 12.0),            # C: LR sensitivity
        (0.0, 8.0),             # E: BSZ sensitivity
        (0.0, 5.0),             # H: LR-BSZ interaction
        (y_min - 1.0, y_max),   # F: offset
    ]
    
    # Stage 1: Global search with multiple strategies
    best_result = None
    best_score = 1e10
    
    for seed_val in [42, 123, 456, 789, 2024]:
        result = differential_evolution(
            objective,
            bounds,
            seed=seed_val,
            maxiter=350,
            popsize=18,
            atol=1e-7,
            tol=1e-7,
            workers=1,
            strategy=&#x27;best1bin&#x27;,
            mutation=(0.6, 1.4),
            recombination=0.8,
            polish=False
        )
        
        if result.fun &lt; best_score:
            best_score = result.fun
            best_result = result
    
    # Stage 2: Local refinement
    if best_result and best_result.success:
        result_local = minimize(
            objective,
            best_result.x,
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds,
            options={&#x27;maxiter&#x27;: 4000, &#x27;ftol&#x27;: 1e-12, &#x27;gtol&#x27;: 1e-10}
        )
        
        if result_local.success and result_local.fun &lt; best_result.fun:
            return result_local.x
        return best_result.x
    
    # Fallback: theory-based initialization
    init_params = np.array([
        15.0,       # A (Chinchilla-based)
        0.34,       # alpha
        12.0,       # B
        0.28,       # beta
        2.5,        # C
        1.5,        # E
        0.8,        # H
        y_mean - (y_max - y_min) * 0.15,  # F
    ])
    
    result_fallback = minimize(
        objective,
        init_params,
        method=&#x27;L-BFGS-B&#x27;,
        bounds=bounds,
        options={&#x27;maxiter&#x27;: 4000, &#x27;ftol&#x27;: 1e-11}
    )
    
    if result_fallback.success:
        return result_fallback.x
    
    return init_params

# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -0.012828
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Optimized scaling law combining proven approaches from best performers.
Focus on numerical stability, smart initialization, and robust functional forms.
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize, differential_evolution

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: L = A/N^α + B/D^β + C*log²(lr_opt/lr) + E*(bsz/bsz₀)^γ + F*sqrt(N/D) + L_inf
    
    Combines best elements:
    - Standard power law for N and D (Chinchilla)
    - Squared log penalty for LR (stable and effective)
    - Normalized batch size with power law
    - Interaction term for model/data ratio
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    params = np.asarray(params, dtype=np.float64)
    
    # Extract and clip features
    lr = np.clip(X[:, 0], 1e-6, 1.0)
    bsz = np.clip(X[:, 1], 1.0, 1e6)
    data_size = np.clip(X[:, 2], 1e6, 1e15)
    param_size = np.clip(X[:, 3], 1e6, 1e12)
    
    # Extract 9 parameters
    A, alpha, B, beta, C, lr_opt_base, E, gamma, L_inf = params
    
    # Core Chinchilla-style power laws
    model_term = A * np.power(param_size, -alpha)
    data_term = B * np.power(data_size, -beta)
    
    # Learning rate term: squared log penalty (most stable)
    # Optimal LR scales with sqrt(1/N)
    lr_optimal = np.exp(lr_opt_base) * np.power(param_size, -0.5)
    lr_ratio = np.clip(lr_optimal / lr, 0.1, 10.0)
    lr_term = C * np.power(np.log(lr_ratio), 2)
    
    # Batch size term: normalized around typical value
    bsz_normalized = bsz / 256.0
    bsz_term = E * np.power(bsz_normalized, gamma)
    
    # Total loss (removed interaction term for simplicity)
    loss = model_term + data_term + lr_term + bsz_term + L_inf
    
    return loss


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Enhanced multi-stage optimization with adaptive strategy
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points, dtype=np.float64))
    y = np.asarray(loss_values, dtype=np.float64)
    
    # Robust normalization
    y_mean = np.mean(y)
    y_std = np.std(y)
    y_normalized = (y - y_mean) / (y_std + 1e-8)
    
    # Bounds: [A, alpha, B, beta, C, lr_opt_base, E, gamma, L_inf]
    bounds = [
        (1e-3, 100.0),     # A: model coefficient
        (0.01, 0.9),       # alpha: model exponent (0.1-0.5 typical)
        (1e-3, 100.0),     # B: data coefficient
        (0.01, 0.9),       # beta: data exponent
        (1e-4, 15.0),      # C: LR coefficient
        (-10.0, -2.0),     # lr_opt_base: log optimal LR base
        (-2.0, 2.0),       # E: batch size coefficient
        (-0.5, 0.5),       # gamma: batch size exponent
        (1.5, 3.5),        # L_inf: irreducible loss
    ]
    
    def objective(params):
        try:
            pred = scaling_law_func(X, params)
            pred_normalized = (pred - y_mean) / (y_std + 1e-8)
            
            # MSE with adaptive regularization
            mse = np.mean((pred_normalized - y_normalized) ** 2)
            reg = 1e-6 * np.sum(params ** 2)
            
            return mse + reg
        except:
            return 1e10
    
    # Smart initialization from data statistics
    lr_vals = X[:, 0]
    param_vals = X[:, 3]
    
    init_guess = np.array([
        12.0,                                    # A
        0.32,                                    # alpha
        4.5,                                     # B
        0.28,                                    # beta
        0.3,                                     # C
        np.log(np.median(lr_vals)) + 3.0,       # lr_opt_base
        0.05,                                    # E
        0.0,                                     # gamma
        y_mean,                                  # L_inf
    ])
    init_guess = np.clip(init_guess, [b[0] for b in bounds], [b[1] for b in bounds])
    
    best_params = None
    best_loss = np.inf
    
    # Stage 1: Differential evolution with larger population
    try:
        result = differential_evolution(
            objective,
            bounds,
            seed=42,
            maxiter=350,
            popsize=18,
            atol=1e-7,
            tol=1e-7,
            workers=1,
            polish=False
        )
        if result.fun &lt; best_loss:
            best_loss = result.fun
            best_params = result.x
    except:
        pass
    
    # Stage 2: Local refinement from DE result
    if best_params is not None:
        try:
            res = minimize(
                objective,
                best_params,
                method=&#x27;L-BFGS-B&#x27;,
                bounds=bounds,
                options={&#x27;maxiter&#x27;: 2000, &#x27;ftol&#x27;: 1e-11, &#x27;gtol&#x27;: 1e-8}
            )
            if res.fun &lt; best_loss:
                best_loss = res.fun
                best_params = res.x
        except:
            pass
    
    # Stage 3: Local optimization from smart init (backup)
    try:
        res = minimize(
            objective,
            init_guess,
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds,
            options={&#x27;maxiter&#x27;: 2000, &#x27;ftol&#x27;: 1e-11}
        )
        if res.fun &lt; best_loss:
            best_loss = res.fun
            best_params = res.x
    except:
        pass
    
    # Stage 4: Multiple random restarts for robustness
    for seed_val in [123, 456, 789]:
        try:
            np.random.seed(seed_val)
            random_init = np.array([
                np.random.uniform(b[0], b[1]) for b in bounds
            ])
            
            res = minimize(
                objective,
                random_init,
                method=&#x27;L-BFGS-B&#x27;,
                bounds=bounds,
                options={&#x27;maxiter&#x27;: 1500}
            )
            
            if res.fun &lt; best_loss:
                best_loss = res.fun
                best_params = res.x
        except:
            continue
    
    # Fallback
    if best_params is None:
        best_params = init_guess
    
    return best_params
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -1.000000
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4"># EVOLVE-BLOCK-START
&quot;&quot;&quot;
Enhanced scaling law with improved stability and better hyperparameter modeling.
Key improvements:
1. Additive log-space terms (more stable than quadratic penalties)
2. Better interaction modeling between LR and batch size
3. Normalized features for numerical stability
4. Robust multi-start optimization
&quot;&quot;&quot;
import numpy as np
from scipy.optimize import minimize

def scaling_law_func(data_points, params):
    &quot;&quot;&quot;
    Scaling law: L = A/N^alpha + B/D^beta + C*log(lr) + D*log(bsz) + E*log(lr)*log(bsz) + F*log(lr)^2 + G
    
    This captures:
    - Chinchilla power laws for model size and data
    - Direct logarithmic effects of LR and batch size
    - Interaction between LR and batch size (gradient noise)
    - Quadratic LR term to capture optimal learning rate
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    
    lr = X[:, 0]
    bsz = X[:, 1]
    data_size = X[:, 2]
    param_size = X[:, 3]
    
    # Ensure we have 10 parameters
    params = np.asarray(params)
    if len(params) &lt; 10:
        params = np.pad(params, (0, 10 - len(params)), constant_values=0.0)
    
    A, alpha, B, beta, C, D, E, F, G, H = params[:10]
    
    eps = 1e-10
    
    # Chinchilla-style power law terms
    term_param = A / (param_size ** np.abs(alpha) + eps)
    term_data = B / (data_size ** np.abs(beta) + eps)
    
    # Learning rate effects in log space
    log_lr = np.log(lr + eps)
    term_lr_linear = C * log_lr
    term_lr_quad = F * (log_lr ** 2)  # Captures optimal LR
    
    # Batch size effects in log space
    log_bsz = np.log(bsz + eps)
    term_bsz = D * log_bsz
    
    # Interaction: LR and batch size affect each other (gradient noise scaling)
    term_lr_bsz = E * log_lr * log_bsz
    
    # Additional stabilization term: ratio of data to parameters
    log_ratio = np.log((data_size / (param_size + eps)) + eps)
    term_ratio = H * log_ratio
    
    # Combine all terms
    pred = term_param + term_data + term_lr_linear + term_lr_quad + term_bsz + term_lr_bsz + term_ratio + G
    
    return pred


def fit_scaling_law(data_points, loss_values):
    &quot;&quot;&quot;
    Fit scaling law using multi-start L-BFGS-B optimization for robustness
    &quot;&quot;&quot;
    X = np.atleast_2d(np.asarray(data_points))
    y = np.asarray(loss_values)
    
    # Data statistics
    loss_min = np.min(y)
    loss_max = np.max(y)
    loss_median = np.median(y)
    loss_mean = np.mean(y)
    
    # Estimate optimal hyperparameters from low-loss region
    low_loss_mask = y &lt; np.percentile(y, 25)
    if np.any(low_loss_mask):
        lr_est = np.median(X[low_loss_mask, 0])
        bsz_est = np.median(X[low_loss_mask, 1])
    else:
        lr_est = np.median(X[:, 0])
        bsz_est = np.median(X[:, 1])
    
    # Initial parameters: [A, alpha, B, beta, C, D, E, F, G, H]
    init_params = np.array([
        0.5,                # A: param coefficient
        0.25,               # alpha: param exponent (~0.25-0.35 typical)
        0.8,                # B: data coefficient  
        0.28,               # beta: data exponent (~0.25-0.35 typical)
        -0.08,              # C: lr linear (negative - higher lr helps initially)
        -0.03,              # D: batch size (negative - larger batch helps)
        0.015,              # E: lr-bsz interaction (positive - they compound)
        0.02,               # F: lr quadratic (positive - too high lr hurts)
        loss_median,        # G: baseline loss
        -0.01               # H: data/param ratio effect
    ])
    
    # Bounds for physical constraints
    bounds = [
        (0.001, 5.0),       # A
        (0.05, 0.6),        # alpha
        (0.001, 5.0),       # B
        (0.05, 0.6),        # beta
        (-0.5, 0.5),        # C
        (-0.5, 0.5),        # D
        (-0.2, 0.2),        # E
        (-0.2, 0.2),        # F
        (1.8, 4.0),         # G
        (-0.1, 0.1)         # H
    ]
    
    def objective(params):
        pred = scaling_law_func(X, params)
        mse = np.mean((pred - y) ** 2)
        # Light regularization to keep exponents near typical Chinchilla values
        reg = 0.005 * ((params[1] - 0.3)**2 + (params[3] - 0.3)**2)
        # Regularize interaction terms to prevent overfitting
        reg += 0.001 * (params[6]**2 + params[7]**2 + params[9]**2)
        return mse + reg
    
    # Multi-start optimization to avoid local minima
    best_result = None
    best_loss = float(&#x27;inf&#x27;)
    
    # Try several random initializations
    np.random.seed(42)
    for i in range(5):
        if i == 0:
            # First try: use the smart initialization
            init = init_params.copy()
        else:
            # Subsequent tries: add random perturbations
            init = init_params + np.random.randn(10) * np.array([0.2, 0.05, 0.2, 0.05, 0.05, 0.05, 0.01, 0.01, 0.2, 0.01])
            # Clip to bounds
            init = np.clip(init, [b[0] for b in bounds], [b[1] for b in bounds])
        
        result = minimize(
            objective,
            init,
            method=&#x27;L-BFGS-B&#x27;,
            bounds=bounds,
            options={&#x27;maxiter&#x27;: 1000, &#x27;ftol&#x27;: 1e-10}
        )
        
        if result.success and result.fun &lt; best_loss:
            best_loss = result.fun
            best_result = result
    
    # If all optimizations failed, return smart initialization
    if best_result is None:
        return init_params
    
    return best_result.x
# EVOLVE-BLOCK-END</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>