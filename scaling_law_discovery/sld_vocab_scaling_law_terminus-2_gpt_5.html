<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - Vocabulary Scaling Law - terminus-2 + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>Vocabulary Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">terminus-2</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">GPT-5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        0.978030
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.533367</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">-1.000000</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.978030
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0">from __future__ import annotations
from typing import List, Dict
import math

# Coefficients learned from the observed dataset. Same functional form; group-specific coefficients.
_GROUP_COEFS = {&#x27;all_data&#x27;: {&#x27;mse&#x27;: 0.00731547465744217, &#x27;coef&#x27;: {&#x27;const&#x27;: -2.1279174866216723, &#x27;V_inv_sqrt&#x27;: -249.95274501751913, &#x27;P_inv_sqrt&#x27;: 85788.82318771542, &#x27;C_inv_sqrt&#x27;: -412035.65012517374, &#x27;logV&#x27;: 0.13411632826121078, &#x27;logP&#x27;: -0.5280171191793501, &#x27;logC&#x27;: 0.24657662157971197, &#x27;V_inv_sqrt_logP&#x27;: 14.031301495867208, &#x27;P_inv_sqrt_logC&#x27;: -3829.9875212486672, &#x27;C_inv_sqrt_logP&#x27;: 25651.188832628683}}}
_FEATURES = [&#x27;const&#x27;, &#x27;V_inv_sqrt&#x27;, &#x27;P_inv_sqrt&#x27;, &#x27;C_inv_sqrt&#x27;, &#x27;logV&#x27;, &#x27;logP&#x27;, &#x27;logC&#x27;, &#x27;V_inv_sqrt_logP&#x27;, &#x27;P_inv_sqrt_logC&#x27;, &#x27;C_inv_sqrt_logP&#x27;]

# Feature computation matches the training pipeline

def _compute_features(d: Dict[str, float]) -&gt; list[float]:
    V = float(d.get(&#x27;vocab_size&#x27;, 0.0))
    P = float(d.get(&#x27;non_vocab_parameters&#x27;, 0.0))
    C = float(d.get(&#x27;num_characters&#x27;, 0.0))
    eps = 1e-12
    V = V if V &gt; eps else eps
    P = P if P &gt; eps else eps
    C = C if C &gt; eps else eps
    feats = {
        &#x27;const&#x27;: 1.0,
        &#x27;V_inv_sqrt&#x27;: V**(-0.5),
        &#x27;P_inv_sqrt&#x27;: P**(-0.5),
        &#x27;C_inv_sqrt&#x27;: C**(-0.5),
        &#x27;logV&#x27;: math.log(V),
        &#x27;logP&#x27;: math.log(P),
        &#x27;logC&#x27;: math.log(C),
        &#x27;V_inv_sqrt_logP&#x27;: (V**(-0.5))*math.log(P),
        &#x27;P_inv_sqrt_logC&#x27;: (P**(-0.5))*math.log(C),
        &#x27;C_inv_sqrt_logP&#x27;: (C**(-0.5))*math.log(P),
    }
    return [feats[name] for name in _FEATURES]


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Select coefficients for the requested group; if unseen, average across known groups
    if group in _GROUP_COEFS:
        coefs = _GROUP_COEFS[group][&#x27;coef&#x27;]
    else:
        keys = list(next(iter(_GROUP_COEFS.values()))[&#x27;coef&#x27;].keys())
        avg = {k: 0.0 for k in keys}
        n = 0
        for rec in _GROUP_COEFS.values():
            for k, v in rec[&#x27;coef&#x27;].items():
                avg[k] += v
            n += 1
        for k in avg:
            avg[k] /= max(n, 1)
        coefs = avg

    beta = [coefs[name] for name in _FEATURES]

    outputs: list[dict[str, float]] = []
    for d in input_data:
        x = _compute_features(d)
        y = sum(b * xi for b, xi in zip(beta, x))
        outputs.append({&#x27;unigram_normalized_loss&#x27;: float(y)})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.966564
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1"># Auto-generated scaling law implementation
from typing import List, Dict

# Per-group parameters fitted from dataset
_PARAMS: Dict[str, Dict[str, float]] = {
    &#x27;all_data&#x27;: {&#x27;Linf&#x27;: -4.765198315721425, &#x27;a&#x27;: -1.9237509883501536, &#x27;alpha&#x27;: 0.05, &#x27;b&#x27;: 26201950506.048325, &#x27;beta&#x27;: 1.5, &#x27;c&#x27;: 1505.1149651298308, &#x27;gamma&#x27;: 0.3},
}

# Fallback default: average of parameters if group not found
_DEFAULT = None
if _PARAMS:
    vals = list(_PARAMS.values())
    _DEFAULT = {k: sum(d[k] for d in vals)/len(vals) for k in vals[0].keys()}


def _predict_one(x: Dict[str, float], p: Dict[str, float]) -&gt; float:
    V = float(x.get(&#x27;vocab_size&#x27;, 0.0))
    N = float(x.get(&#x27;non_vocab_parameters&#x27;, 0.0))
    D = float(x.get(&#x27;num_characters&#x27;, 0.0))
    if V &lt;= 0 or N &lt;= 0 or D &lt;= 0:
        # Guard against invalid inputs; return Linf in that case
        return float(p[&#x27;Linf&#x27;])
    return (
        float(p[&#x27;Linf&#x27;])
        + float(p[&#x27;a&#x27;]) * (V ** (-float(p[&#x27;alpha&#x27;])))
        + float(p[&#x27;b&#x27;]) * (N ** (-float(p[&#x27;beta&#x27;])))
        + float(p[&#x27;c&#x27;]) * (D ** (-float(p[&#x27;gamma&#x27;])))
    )


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    p = _PARAMS.get(group, _DEFAULT)
    if p is None:
        return [{&#x27;unigram_normalized_loss&#x27;: 0.0} for _ in input_data]
    return [{&#x27;unigram_normalized_loss&#x27;: float(_predict_one(x, p))} for x in input_data]</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.861121
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2">from __future__ import annotations
import math

# Coefficients per group for the scaling law:
# L = a + b*log(V) + c*log(P_nv) + d*log(N_chars)
_COEFS = {
  &quot;all_data&quot;: {
    &quot;a&quot;: 6.380591236628991,
    &quot;b&quot;: 0.06340183374111474,
    &quot;c&quot;: 0.016411064426657424,
    &quot;d&quot;: -0.5017006627222854,
    &quot;r2&quot;: 0.8762104080459034,
    &quot;n&quot;: 1080
  }
}

_DEF_GROUP = next(iter(_COEFS.keys())) if _COEFS else &#x27;all&#x27;


def _predict_one(sample: dict[str, float], group: str) -&gt; float:
    g = group if group in _COEFS else _DEF_GROUP
    params = _COEFS[g]
    a = params[&#x27;a&#x27;]; b = params[&#x27;b&#x27;]; c = params[&#x27;c&#x27;]; d = params[&#x27;d&#x27;]
    V = float(sample.get(&#x27;vocab_size&#x27;, 0.0))
    Pnv = float(sample.get(&#x27;non_vocab_parameters&#x27;, 0.0))
    N = float(sample.get(&#x27;num_characters&#x27;, 0.0))
    eps = 1e-12
    V = V if V &gt; 0 else eps
    Pnv = Pnv if Pnv &gt; 0 else eps
    N = N if N &gt; 0 else eps
    L = a + b*math.log(V) + c*math.log(Pnv) + d*math.log(N)
    return L


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    outputs: list[dict[str, float]] = []
    for row in input_data:
        pred = _predict_one(row, group)
        outputs.append({&#x27;unigram_normalized_loss&#x27;: float(pred)})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.861121
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3">from __future__ import annotations
import math

# Discovered scaling law (additive in log-variables):
# unigram_normalized_loss = C[group] + b1*ln(vocab_size) + b2*ln(non_vocab_parameters) + b3*ln(num_characters)
B = [0.06340183374111474, 0.016411064426657424, -0.5017006627222854]
C_INTERCEPT = {&#x27;all_data&#x27;: 6.380591236628991}
KNOWN_GROUPS = [&#x27;all_data&#x27;]


def _predict_one(x: dict[str, float], group: str) -&gt; float:
    b1, b2, b3 = B
    Cg = C_INTERCEPT.get(group, sum(C_INTERCEPT.values())/len(C_INTERCEPT) if C_INTERCEPT else 0.0)
    v = float(x.get(&#x27;vocab_size&#x27;, 0.0))
    nv = float(x.get(&#x27;non_vocab_parameters&#x27;, 0.0))
    nc = float(x.get(&#x27;num_characters&#x27;, 0.0))
    # Guard small/invalid inputs for log
    v = max(v, 1e-12)
    nv = max(nv, 1e-12)
    nc = max(nc, 1e-12)
    y = Cg + b1 * math.log(v) + b2 * math.log(nv) + b3 * math.log(nc)
    return float(y)


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is shared across groups; only the
                intercept C[group] varies.

    Returns:
        A list of dictionaries, each containing the predicted &#x27;unigram_normalized_loss&#x27;.
    &quot;&quot;&quot;
    out = []
    for x in input_data:
        y = _predict_one(x, group)
        out.append({&#x27;unigram_normalized_loss&#x27;: y})
    return out</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #B22222; color: white;">
                        R² = -1.000000
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4"># Auto-generated scaling law implementation
# This file intentionally defines a single public function: law

# Fitted parameters per group
_PER_GROUP = {
  &quot;all_data&quot;: {
    &quot;L&quot;: 2.7706746033627237e-30,
    &quot;a&quot;: 0.3867856666583771,
    &quot;alpha&quot;: 1.256210639553385,
    &quot;b&quot;: 0.4451697330289151,
    &quot;beta&quot;: 1.2204180459981504,
    &quot;c&quot;: 0.06814610472029942,
    &quot;gamma&quot;: 1.9437720332434425
  }
}
_GLOBAL = {
  &quot;L&quot;: 2.7706746033627237e-30,
  &quot;a&quot;: 0.3867856666583771,
  &quot;alpha&quot;: 1.256210639553385,
  &quot;b&quot;: 0.4451697330289151,
  &quot;beta&quot;: 1.2204180459981504,
  &quot;c&quot;: 0.06814610472029942,
  &quot;gamma&quot;: 1.9437720332434425
}

# Numerical stability offsets used during fitting
_N_OFFSET = 1e3
_D_OFFSET = 1e3
_V_OFFSET = 1.0

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    params = _PER_GROUP.get(group, _GLOBAL)
    L = params[&#x27;L&#x27;]; a = params[&#x27;a&#x27;]; alpha = params[&#x27;alpha&#x27;]
    b = params[&#x27;b&#x27;]; beta = params[&#x27;beta&#x27;]; c = params[&#x27;c&#x27;]; gamma = params[&#x27;gamma&#x27;]
    out: list[dict[str, float]] = []
    for x in input_data:
        N = float(x.get(&#x27;non_vocab_parameters&#x27;, 0.0))
        D = float(x.get(&#x27;num_characters&#x27;, 0.0))
        V = float(x.get(&#x27;vocab_size&#x27;, 0.0))
        N_eff = (0.0 if N &lt; 0.0 else N) + _N_OFFSET
        D_eff = (0.0 if D &lt; 0.0 else D) + _D_OFFSET
        V_eff = (1.0 if V &lt; 1.0 else V) + _V_OFFSET
        y = L + a*(N_eff ** (-alpha)) + b*(D_eff ** (-beta)) + c*(V_eff ** (-gamma))
        out.append({&#x27;unigram_normalized_loss&#x27;: float(y)})
    return out</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>