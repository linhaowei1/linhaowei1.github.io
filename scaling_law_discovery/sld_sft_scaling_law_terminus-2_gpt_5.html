<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SLD - SFT Scaling Law - terminus-2 + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #f8f9fa;
        --accent-primary: #2563eb;
        --accent-secondary: #3b82f6;
        --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
        --text-primary: #1f2937;
        --text-secondary: #4b5563;
        --border-subtle: rgba(0, 0, 0, 0.1);
        --glass-bg: rgba(0, 0, 0, 0.02);
        --success: #10b981;
      }

      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }

      body {
        font-family:
          "Sora",
          -apple-system,
          BlinkMacSystemFont,
          sans-serif;
        background: var(--bg-primary);
        min-height: 100vh;
        color: var(--text-primary);
      }

      .bg-pattern {
        display: none;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
        position: relative;
        z-index: 1;
      }

      .back-link {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        color: var(--accent-primary);
        text-decoration: none;
        font-size: 0.9rem;
        margin-bottom: 1.5rem;
        transition: color 0.2s;
      }

      .back-link:hover {
        color: var(--accent-secondary);
      }

      .header {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 16px;
        padding: 2rem;
        margin-bottom: 2rem;
        backdrop-filter: blur(10px);
      }

      .header h1 {
        font-size: 1.75rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        background: var(--accent-gradient);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
      }

      .meta-row {
        display: flex;
        flex-wrap: wrap;
        gap: 1.5rem;
        margin-top: 1rem;
      }

      .meta-item {
        display: flex;
        align-items: center;
        gap: 0.5rem;
      }

      .meta-label {
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .meta-value {
        font-weight: 600;
        color: var(--text-primary);
      }

      .r2-badge {
        display: inline-block;
        padding: 0.3rem 0.6rem;
        border-radius: 6px;
        font-weight: 600;
        font-size: 0.85rem;
        font-family: "JetBrains Mono", monospace;
      }

      .section-title {
        font-size: 1.25rem;
        font-weight: 600;
        margin-bottom: 1rem;
        color: var(--text-primary);
      }

      .runs-container {
        display: flex;
        flex-direction: column;
        gap: 1rem;
      }

      .run-card {
        background: var(--glass-bg);
        border: 1px solid var(--border-subtle);
        border-radius: 12px;
        overflow: hidden;
        transition: border-color 0.2s;
      }

      .run-card:hover {
        border-color: rgba(99, 102, 241, 0.3);
      }

      .run-card.best-run {
        border-color: var(--success);
        box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
      }

      .run-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.25rem;
        background: rgba(255, 255, 255, 0.02);
        cursor: pointer;
        transition: background 0.2s;
      }

      .run-header:hover {
        background: rgba(255, 255, 255, 0.04);
      }

      .run-info {
        display: flex;
        align-items: center;
        gap: 1rem;
      }

      .run-badge {
        padding: 0.25rem 0.6rem;
        border-radius: 6px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(255, 255, 255, 0.1);
        color: var(--text-secondary);
      }

      .run-badge.best-badge {
        background: var(--success);
        color: white;
      }

      .run-label {
        font-weight: 500;
        color: var(--text-primary);
      }

      .expand-icon {
        color: var(--text-muted);
        font-size: 0.8rem;
        transition: transform 0.2s;
      }

      .run-header.expanded .expand-icon {
        transform: rotate(180deg);
      }

      .run-content {
        border-top: 1px solid var(--border-subtle);
      }

      .code-container {
        overflow: hidden;
      }

      .code-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 0.75rem 1.25rem;
        background: rgba(0, 0, 0, 0.2);
        border-bottom: 1px solid var(--border-subtle);
        font-size: 0.8rem;
        color: var(--text-muted);
      }

      .copy-btn {
        padding: 0.35rem 0.75rem;
        background: rgba(99, 102, 241, 0.2);
        border: 1px solid rgba(99, 102, 241, 0.3);
        border-radius: 6px;
        color: var(--accent-primary);
        font-size: 0.75rem;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.2s;
        font-family: inherit;
      }

      .copy-btn:hover {
        background: rgba(99, 102, 241, 0.3);
      }

      .code-container pre {
        margin: 0;
        padding: 1.25rem;
        font-family: "JetBrains Mono", monospace;
        font-size: 0.8rem;
        line-height: 1.6;
        overflow-x: auto;
        background: transparent !important;
      }

      .footer {
        text-align: center;
        margin-top: 3rem;
        padding-top: 2rem;
        border-top: 1px solid var(--border-subtle);
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      .footer a {
        color: var(--accent-primary);
        text-decoration: none;
      }

      @media (max-width: 768px) {
        .container {
          padding: 1rem;
        }

        .header h1 {
          font-size: 1.25rem;
        }

        .meta-row {
          flex-direction: column;
          gap: 0.75rem;
        }

        .run-info {
          flex-wrap: wrap;
          gap: 0.5rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="bg-pattern"></div>

    <div class="container">
      <a href="index.html" class="back-link"> ← Back to Leaderboard </a>

      <div class="header">
        <h1>SFT Scaling Law</h1>
        <div class="meta-row">
          <div class="meta-item">
            <span class="meta-label">Agent:</span>
            <span class="meta-value">terminus-2</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Model:</span>
            <span class="meta-value">GPT-5</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Best R²:</span>
            <span class="r2-badge" style="background-color: #006400; color: white"> 0.960281 </span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Mean R²:</span>
            <span class="meta-value">0.856388</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Min R²:</span>
            <span class="meta-value">0.787239</span>
          </div>
          <div class="meta-item">
            <span class="meta-label">Runs:</span>
            <span class="meta-value">3</span>
          </div>
        </div>
      </div>

      <h2 class="section-title">All Runs (sorted by R²)</h2>

      <div class="runs-container">
        <div class="run-card best-run">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge best-badge">Best</span>
              <span class="run-label">Run 1</span>
              <span class="r2-badge" style="background-color: #006400; color: white"> R² = 0.960281 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: block">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-0"># Auto-generated scaling law for SFT loss
# Model: A + B * N^-alpha
from typing import List, Dict

# Fitted parameters per group
_PARAMS = {
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -9287.970911, &#x27;B&#x27;: 9293.959488, &#x27;alpha&#x27;: 3.076250129e-05},
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -10371.5707, &#x27;B&#x27;: 10376.30869, &#x27;alpha&#x27;: 2.53885626e-05},
    &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -4625.015479, &#x27;B&#x27;: 4628.407534, &#x27;alpha&#x27;: 2.984110982e-05},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -9172.408439, &#x27;B&#x27;: 9177.192211, &#x27;alpha&#x27;: 2.313061965e-05},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -9623.28162, &#x27;B&#x27;: 9627.486398, &#x27;alpha&#x27;: 2.473385708e-05},
    &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -7.36673275, &#x27;B&#x27;: 10.05976737, &#x27;alpha&#x27;: 0.01050226284},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -4121.931225, &#x27;B&#x27;: 4125.391992, &#x27;alpha&#x27;: 2.950457285e-05},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -5878.067704, &#x27;B&#x27;: 5881.88829, &#x27;alpha&#x27;: 3.241559695e-05},
    &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -2801.316556, &#x27;B&#x27;: 2804.267032, &#x27;alpha&#x27;: 3.640117085e-05},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -4611.474391, &#x27;B&#x27;: 4615.685187, &#x27;alpha&#x27;: 3.135204722e-05},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -8313.964541, &#x27;B&#x27;: 8318.18321, &#x27;alpha&#x27;: 2.713277306e-05},
    &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -18.85652913, &#x27;B&#x27;: 22.83678187, &#x27;alpha&#x27;: 0.007851560092},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -8710.157573, &#x27;B&#x27;: 8715.880715, &#x27;alpha&#x27;: 3.200248092e-05},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -9243.220356, &#x27;B&#x27;: 9248.631552, &#x27;alpha&#x27;: 3.62034338e-05},
    &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 0.2505127082, &#x27;B&#x27;: 5.861960896, &#x27;alpha&#x27;: 0.1201854396},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -4109.920415, &#x27;B&#x27;: 4114.374298, &#x27;alpha&#x27;: 4.817980936e-05},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -8915.743973, &#x27;B&#x27;: 8920.986972, &#x27;alpha&#x27;: 3.744345395e-05},
    &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 0.7814640543, &#x27;B&#x27;: 2.620750818, &#x27;alpha&#x27;: 0.1152038048},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -4047.521923, &#x27;B&#x27;: 4050.525548, &#x27;alpha&#x27;: 2.525409335e-05},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -5808.928716, &#x27;B&#x27;: 5812.996425, &#x27;alpha&#x27;: 3.872644109e-05},
    &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -1.456883583, &#x27;B&#x27;: 3.745412801, &#x27;alpha&#x27;: 0.02195676682},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -5046.306355, &#x27;B&#x27;: 5050.402958, &#x27;alpha&#x27;: 3.105100761e-05},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -8546.627786, &#x27;B&#x27;: 8551.417352, &#x27;alpha&#x27;: 3.32394917e-05},
    &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -1.12612954, &#x27;B&#x27;: 4.260565516, &#x27;alpha&#x27;: 0.03532388588},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -6.628198975, &#x27;B&#x27;: 8.840212818, &#x27;alpha&#x27;: 0.004229133986},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -1042.934868, &#x27;B&#x27;: 1045.09753, &#x27;alpha&#x27;: 2.66621148e-05},
    &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: 0.2693294718, &#x27;B&#x27;: 1.788104434, &#x27;alpha&#x27;: 0.04220831611},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -2046.453987, &#x27;B&#x27;: 2050.553311, &#x27;alpha&#x27;: 8.082852091e-05},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -2558.786766, &#x27;B&#x27;: 2562.122418, &#x27;alpha&#x27;: 3.215005554e-05},
    &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -34.04468734, &#x27;B&#x27;: 37.94761142, &#x27;alpha&#x27;: 0.005395576769},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -3272.79782, &#x27;B&#x27;: 3276.026208, &#x27;alpha&#x27;: 3.526798902e-05},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -2859.850037, &#x27;B&#x27;: 2863.264817, &#x27;alpha&#x27;: 3.330684106e-05},
    &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -1.180043896, &#x27;B&#x27;: 4.866217417, &#x27;alpha&#x27;: 0.04883425147},
    &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -10281.29052, &#x27;B&#x27;: 10287.47069, &#x27;alpha&#x27;: 2.879731311e-05},
    &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: -8699.204248, &#x27;B&#x27;: 8704.021771, &#x27;alpha&#x27;: 3.22787079e-05},
    &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -2263.843178, &#x27;B&#x27;: 2267.336925, &#x27;alpha&#x27;: 6.509264453e-05},
    &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -3875.638003, &#x27;B&#x27;: 3878.923652, &#x27;alpha&#x27;: 3.02155981e-05},
    &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 0.4167409862, &#x27;B&#x27;: 1.823379391, &#x27;alpha&#x27;: 0.1674599731},
    &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -2315.534964, &#x27;B&#x27;: 2317.66734, &#x27;alpha&#x27;: 2.92828973e-05},
    &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {&#x27;A&#x27;: -4336.333336, &#x27;B&#x27;: 4340.085568, &#x27;alpha&#x27;: 3.098564388e-05},
    &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {&#x27;A&#x27;: 0.4009177682, &#x27;B&#x27;: 1.775741828, &#x27;alpha&#x27;: 0.1343979639},
    &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {&#x27;A&#x27;: -2123.447508, &#x27;B&#x27;: 2126.042054, &#x27;alpha&#x27;: 4.260045172e-05},
}

def _predict_one(sft_data_size: float, p: dict) -&gt; float:
    # Ensure positive size
    n = max(float(sft_data_size), 1e-12)
    return float(p[&#x27;A&#x27;] + p[&#x27;B&#x27;] * (n ** (-p[&#x27;alpha&#x27;])))

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # If unseen group, back off to global average of parameters
    if group in _PARAMS:
        p = _PARAMS[group]
    else:
        # simple average parameters
        if not hasattr(law, &#x27;_avg_params&#x27;):
            import numpy as _np
            A = _np.mean([v[&#x27;A&#x27;] for v in _PARAMS.values()])
            B = _np.mean([v[&#x27;B&#x27;] for v in _PARAMS.values()])
            alpha = _np.mean([v[&#x27;alpha&#x27;] for v in _PARAMS.values()])
            law._avg_params = {&#x27;A&#x27;: float(A), &#x27;B&#x27;: float(B), &#x27;alpha&#x27;: float(alpha)}
        p = law._avg_params

    outputs: list[dict[str, float]] = []
    for row in input_data:
        n = row.get(&#x27;sft_data_size&#x27;)
        if n is None:
            raise KeyError(&quot;Each input row must contain &#x27;sft_data_size&#x27;.&quot;)
        pred = _predict_one(n, p)
        outputs.append({&#x27;sft_loss&#x27;: float(pred)})
    return outputs</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#2</span>
              <span class="run-label">Run 2</span>
              <span class="r2-badge" style="background-color: #228b22; color: white"> R² = 0.821644 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-1"># Auto-generated scaling law for SFT loss vs data size
from __future__ import annotations
from math import pow

# Per-group parameters for L(N) = c + a * N^{-b}
_PARAMS = {
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.4827993951275662,
    &quot;a&quot;: 8.681233620552247,
    &quot;b&quot;: 0.17615205560077954,
    &quot;mse&quot;: 0.07572095110708876,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.5778526375054923,
    &quot;a&quot;: 8.132271163266724,
    &quot;b&quot;: 0.17780779263551502,
    &quot;mse&quot;: 0.09155548707084517,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.2749505667194287,
    &quot;a&quot;: 4.096753821370224,
    &quot;b&quot;: 0.18127272693009286,
    &quot;mse&quot;: 0.007576015148309798,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.3969925089074628,
    &quot;a&quot;: 6.40984847550739,
    &quot;b&quot;: 0.17199807099464345,
    &quot;mse&quot;: 0.04227240896528709,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.4749899427965494,
    &quot;a&quot;: 7.316034511850357,
    &quot;b&quot;: 0.17951634849788112,
    &quot;mse&quot;: 0.06685341699938115,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.1984324837502354,
    &quot;a&quot;: 2.8225175602427934,
    &quot;b&quot;: 0.18381610159857534,
    &quot;mse&quot;: 0.002350416955268903,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.5983096713993608,
    &quot;a&quot;: 3.625465436911771,
    &quot;b&quot;: 0.18232212054329097,
    &quot;mse&quot;: 0.006276539391354531,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.873264704567136,
    &quot;a&quot;: 5.702649719858272,
    &quot;b&quot;: 0.17983169580523745,
    &quot;mse&quot;: 0.01956385652134642,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.380007205548204,
    &quot;a&quot;: 3.0382321918197386,
    &quot;b&quot;: 0.18059759917861193,
    &quot;mse&quot;: 0.004495478358400602,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.8824405987821344,
    &quot;a&quot;: 4.3105173431135455,
    &quot;b&quot;: 0.16798665859019904,
    &quot;mse&quot;: 0.016099566418512953,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.7013636723381862,
    &quot;a&quot;: 6.83969648610096,
    &quot;b&quot;: 0.17912089400734008,
    &quot;mse&quot;: 0.040609922074825354,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.3966611005609038,
    &quot;a&quot;: 4.908488983299831,
    &quot;b&quot;: 0.18345726653962038,
    &quot;mse&quot;: 0.00725928806266427,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.402782652932343,
    &quot;a&quot;: 8.376545770083204,
    &quot;b&quot;: 0.17972746603444834,
    &quot;mse&quot;: 0.044879946929858,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.2764984487592691,
    &quot;a&quot;: 10.213711557771816,
    &quot;b&quot;: 0.1847929973487988,
    &quot;mse&quot;: 0.09375044998301889,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 0.9710400825952036,
    &quot;a&quot;: 6.95185109881479,
    &quot;b&quot;: 0.19363752005641285,
    &quot;mse&quot;: 0.006138814059146752,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.3945609121941243,
    &quot;a&quot;: 5.826039279936208,
    &quot;b&quot;: 0.1781279206165522,
    &quot;mse&quot;: 0.014543204325175108,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.16518805426565897,
    &quot;a&quot;: 10.136677046755027,
    &quot;b&quot;: 0.18675428613221712,
    &quot;mse&quot;: 0.07801476549607378,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.1065786999405036,
    &quot;a&quot;: 3.072980337237203,
    &quot;b&quot;: 0.18460659464051513,
    &quot;mse&quot;: 0.0005493395674912767,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.4345452517670585,
    &quot;a&quot;: 3.028618372301197,
    &quot;b&quot;: 0.1808380053964771,
    &quot;mse&quot;: 0.004029167599996951,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.634715119130116,
    &quot;a&quot;: 6.7608938134760015,
    &quot;b&quot;: 0.1844253259847985,
    &quot;mse&quot;: 0.028949249451991333,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.2108912294465461,
    &quot;a&quot;: 1.981892390506441,
    &quot;b&quot;: 0.18507486951364943,
    &quot;mse&quot;: 0.0010254072451437843,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.6032673720312067,
    &quot;a&quot;: 4.698389125373991,
    &quot;b&quot;: 0.17197678324723842,
    &quot;mse&quot;: 0.018425011918658536,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.4487475721624149,
    &quot;a&quot;: 8.612529868566897,
    &quot;b&quot;: 0.18513602069713941,
    &quot;mse&quot;: 0.05488526088852023,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.318657032305419,
    &quot;a&quot;: 3.1918344343120673,
    &quot;b&quot;: 0.1840127387732732,
    &quot;mse&quot;: 0.0022594662870228117,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.6583758241931825,
    &quot;a&quot;: 1.0527934808943984,
    &quot;b&quot;: 0.18172580896242374,
    &quot;mse&quot;: 0.0003657389558883888,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 1.7214619335229422,
    &quot;a&quot;: 0.8501645122933167,
    &quot;b&quot;: 0.17553433626221163,
    &quot;mse&quot;: 0.0009104202480365186,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.187363539503907,
    &quot;a&quot;: 1.4987769857971536,
    &quot;b&quot;: 0.18477038158174838,
    &quot;mse&quot;: 0.00047565093841222937,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.583323676667614,
    &quot;a&quot;: 4.8827336950093425,
    &quot;b&quot;: 0.18333559931283497,
    &quot;mse&quot;: 0.008313217244721836,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 2.0551210337798635,
    &quot;a&quot;: 2.4427896526776167,
    &quot;b&quot;: 0.17715640026992513,
    &quot;mse&quot;: 0.0038503896974422433,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 0.9166373518594958,
    &quot;a&quot;: 5.753481901950828,
    &quot;b&quot;: 0.1851212657710932,
    &quot;mse&quot;: 0.010790900408354289,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.4726763734534132,
    &quot;a&quot;: 3.4206192214207842,
    &quot;b&quot;: 0.18366684343063902,
    &quot;mse&quot;: 0.0045625286793028385,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 1.905904106139712,
    &quot;a&quot;: 2.9000173722337452,
    &quot;b&quot;: 0.17523941384449754,
    &quot;mse&quot;: 0.008772571224160345,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.0603143890912172,
    &quot;a&quot;: 4.462514518829667,
    &quot;b&quot;: 0.1860974601465054,
    &quot;mse&quot;: 0.003732898104365934,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.499554116407968,
    &quot;a&quot;: 9.023130844642328,
    &quot;b&quot;: 0.17585201323649569,
    &quot;mse&quot;: 0.08812713809218636,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.46457851812916895,
    &quot;a&quot;: 8.5707377758404,
    &quot;b&quot;: 0.1817309876468499,
    &quot;mse&quot;: 0.0740879352217463,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.2540722578538999,
    &quot;a&quot;: 4.36437086595112,
    &quot;b&quot;: 0.18391632922421508,
    &quot;mse&quot;: 0.007258446809941537,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.4471135954239664,
    &quot;a&quot;: 3.4628046853454775,
    &quot;b&quot;: 0.17403832928764254,
    &quot;mse&quot;: 0.006941254099221423,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.45810999439596933,
    &quot;a&quot;: 1.955554864376512,
    &quot;b&quot;: 0.18850642412886137,
    &quot;mse&quot;: 0.0001945310979496464,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.0907259526778699,
    &quot;a&quot;: 2.000945824397046,
    &quot;b&quot;: 0.18014107601933568,
    &quot;mse&quot;: 0.001727331273734328,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;c&quot;: 1.6669969283388792,
    &quot;a&quot;: 3.9878042798753763,
    &quot;b&quot;: 0.1778290229582325,
    &quot;mse&quot;: 0.008247131168222439,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;c&quot;: 0.5448930641881546,
    &quot;a&quot;: 2.0501491852544573,
    &quot;b&quot;: 0.18876257345373862,
    &quot;mse&quot;: 0.00029128786119094033,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;c&quot;: 1.1972462755987916,
    &quot;a&quot;: 2.661511171116643,
    &quot;b&quot;: 0.17821433575400167,
    &quot;mse&quot;: 0.003410986481257676,
    &quot;n&quot;: 12
  }
}

def _predict_loss(N: float, params: dict[str, float]) -&gt; float:
    # ensure positive N
    if N &lt;= 0 or not (N == N):
        return float(&#x27;nan&#x27;)
    c = float(params.get(&#x27;c&#x27;, 0.0))
    a = float(params.get(&#x27;a&#x27;, 0.0))
    b = float(params.get(&#x27;b&#x27;, 0.5))
    return c + a * (N ** (-b))

def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    # Resolve parameters for the provided group key (supports tuple, list, or string)
    params = _PARAMS.get(group)
    if params is None:
        # try string forms
        keys_to_try = [str(group)]
        try:
            if not isinstance(group, (str, bytes)):
                keys_to_try.append(str(tuple(group)))
        except Exception:
            pass
        for k in keys_to_try:
            params = _PARAMS.get(k)
            if params is not None:
                break
    if params is None:
        # fallback: average params across groups
        if _PARAMS:
            import statistics
            cs = [v[&#x27;c&#x27;] for v in _PARAMS.values()]
            aas = [v[&#x27;a&#x27;] for v in _PARAMS.values()]
            bs = [v[&#x27;b&#x27;] for v in _PARAMS.values()]
            params = {&#x27;c&#x27;: statistics.fmean(cs), &#x27;a&#x27;: statistics.fmean(aas), &#x27;b&#x27;: statistics.fmean(bs)}
        else:
            params = {&#x27;c&#x27;: 0.0, &#x27;a&#x27;: 0.0, &#x27;b&#x27;: 0.5}
    out = []
    # support possible alternative key names
    for row in input_data:
        if &quot;sft_data_size&quot; in row:
            N = float(row[&quot;sft_data_size&quot;])
        elif &quot;data_size&quot; in row:
            N = float(row[&quot;data_size&quot;])
        elif &quot;N&quot; in row:
            N = float(row[&quot;N&quot;])
        else:
            # attempt to pull the first numeric value
            N = None
            for k, v in row.items():
                if isinstance(v, (int, float)):
                    N = float(v)
                    break
            if N is None:
                N = float(&#x27;nan&#x27;)
        pred = _predict_loss(N, params)
        out.append({&#x27;sft_loss&#x27;: float(pred)})
    return out</code></pre>
            </div>
          </div>
        </div>

        <div class="run-card">
          <div class="run-header" onclick="toggleRun(this)">
            <div class="run-info">
              <span class="run-badge">#3</span>
              <span class="run-label">Run 3</span>
              <span class="r2-badge" style="background-color: #daa520; color: white"> R² = 0.787239 </span>
            </div>
            <span class="expand-icon">▼</span>
          </div>
          <div class="run-content" style="display: none">
            <div class="code-container">
              <div class="code-header">
                <span>Python</span>
                <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
              </div>
              <pre><code class="language-python" id="code-2"># Auto-generated scaling law for SFT loss vs data size
from __future__ import annotations
from math import pow

# Fitted parameters per group for the law:
# L(N) = L_inf + A * N^(-alpha)
_PARAMS = {
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 4.1793489034329725e-20,
    &quot;A&quot;: 6.973887891988893,
    &quot;alpha&quot;: 0.081341579969044,
    &quot;mse&quot;: 0.030743888348882354,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 5.883079522069716e-16,
    &quot;A&quot;: 5.923745119438586,
    &quot;alpha&quot;: 0.10520864135386986,
    &quot;mse&quot;: 0.05049249549339201,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-124M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.2330261467896494e-20,
    &quot;A&quot;: 3.7815959443927847,
    &quot;alpha&quot;: 0.06407311292435097,
    &quot;mse&quot;: 0.0013062020699845377,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.2115004548850216e-18,
    &quot;A&quot;: 5.4161940454283455,
    &quot;alpha&quot;: 0.07203581409877267,
    &quot;mse&quot;: 0.01625972280178637,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.2695866557369864e-17,
    &quot;A&quot;: 5.3506894918550945,
    &quot;alpha&quot;: 0.10952377275114691,
    &quot;mse&quot;: 0.036835097370031274,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;MBZUAI/LaMini-GPT-774M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 6.668374080348387e-21,
    &quot;A&quot;: 2.88150676365687,
    &quot;alpha&quot;: 0.0539025527718289,
    &quot;mse&quot;: 0.00013461062353177402,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 5.501435576368134e-20,
    &quot;A&quot;: 3.726687484240208,
    &quot;alpha&quot;: 0.05133622894510909,
    &quot;mse&quot;: 0.0009110207012089926,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.4132832812521193e-26,
    &quot;A&quot;: 4.601802094371978,
    &quot;alpha&quot;: 0.08937942184884487,
    &quot;mse&quot;: 0.006796620975964945,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-1.3B&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.423435602267005e-20,
    &quot;A&quot;: 3.1670522137832107,
    &quot;alpha&quot;: 0.0501048228642509,
    &quot;mse&quot;: 0.0006835440956639627,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.610802906709126e-17,
    &quot;A&quot;: 4.497775766125655,
    &quot;alpha&quot;: 0.04919729778903829,
    &quot;mse&quot;: 0.005015498498160805,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.348802984257992e-22,
    &quot;A&quot;: 5.237426600944778,
    &quot;alpha&quot;: 0.1000412247174401,
    &quot;mse&quot;: 0.018155642203818274,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;cerebras/Cerebras-GPT-256M&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 6.475596350068448e-23,
    &quot;A&quot;: 4.456019624245517,
    &quot;alpha&quot;: 0.0690574151700614,
    &quot;mse&quot;: 0.0007262970705774059,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.2959852247174561e-21,
    &quot;A&quot;: 6.796594790085481,
    &quot;alpha&quot;: 0.0855017030154742,
    &quot;mse&quot;: 0.014590039674770308,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.1659370286402894e-16,
    &quot;A&quot;: 7.594463261439606,
    &quot;alpha&quot;: 0.13330975424655475,
    &quot;mse&quot;: 0.056185185324805854,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 0.25051130094754676,
    &quot;A&quot;: 5.861960773835969,
    &quot;alpha&quot;: 0.12018535548857547,
    &quot;mse&quot;: 0.0037079423898107194,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 6.4911964594333156e-21,
    &quot;A&quot;: 5.1213143392652265,
    &quot;alpha&quot;: 0.07407829967451605,
    &quot;mse&quot;: 0.0035588510622728106,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 9.750963077899339e-17,
    &quot;A&quot;: 7.683917595492025,
    &quot;alpha&quot;: 0.14310655452002652,
    &quot;mse&quot;: 0.048345250585162335,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/bart-large&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 0.7814634104310457,
    &quot;A&quot;: 2.6207508355114477,
    &quot;alpha&quot;: 0.11520372579215718,
    &quot;mse&quot;: 6.40157761487044e-05,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 6.12910632776623e-14,
    &quot;A&quot;: 3.217103534074292,
    &quot;alpha&quot;: 0.0490507140388579,
    &quot;mse&quot;: 0.0004827374136280498,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.832939179598597e-20,
    &quot;A&quot;: 5.229994665907221,
    &quot;alpha&quot;: 0.10805298142346467,
    &quot;mse&quot;: 0.012542874254628038,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-1.3b&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 4.2312065248521274e-17,
    &quot;A&quot;: 2.349129117760962,
    &quot;alpha&quot;: 0.04176287734523659,
    &quot;mse&quot;: 2.8524991491276095e-05,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.0197599888952298e-18,
    &quot;A&quot;: 4.468174311531377,
    &quot;alpha&quot;: 0.05761166109349805,
    &quot;mse&quot;: 0.0056736754061609785,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 5.563786947697396e-15,
    &quot;A&quot;: 6.499200600754544,
    &quot;alpha&quot;: 0.1233184573699429,
    &quot;mse&quot;: 0.028689612424312425,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-350m&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.0105155652800226e-15,
    &quot;A&quot;: 3.241838818207868,
    &quot;alpha&quot;: 0.05546399768730424,
    &quot;mse&quot;: 0.00010119066683621969,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 9.622218431655403e-13,
    &quot;A&quot;: 2.2339677922861707,
    &quot;alpha&quot;: 0.019148365263688585,
    &quot;mse&quot;: 2.8620341700751262e-05,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 4.6641236377906274e-14,
    &quot;A&quot;: 2.17707994930431,
    &quot;alpha&quot;: 0.014498526976677223,
    &quot;mse&quot;: 0.00026131662343541954,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;facebook/opt-6.7b&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 0.269329386441078,
    &quot;A&quot;: 1.7881045126980408,
    &quot;alpha&quot;: 0.042208313187313336,
    &quot;mse&quot;: 2.1376271193012684e-05,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.455535148478193e-24,
    &quot;A&quot;: 4.57114901047889,
    &quot;alpha&quot;: 0.06361718986332089,
    &quot;mse&quot;: 0.0010108168080930104,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 9.517467031000367e-21,
    &quot;A&quot;: 3.4396037440312734,
    &quot;alpha&quot;: 0.03165062209138569,
    &quot;mse&quot;: 0.0008017992848500326,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 8.99631294455016e-21,
    &quot;A&quot;: 4.734453334406631,
    &quot;alpha&quot;: 0.09261262581521647,
    &quot;mse&quot;: 0.0022927464043197157,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.4562094313996466e-22,
    &quot;A&quot;: 3.492798569196681,
    &quot;alpha&quot;: 0.052811814552779335,
    &quot;mse&quot;: 0.0004994391426252324,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.0352991946075001e-19,
    &quot;A&quot;: 3.5492577974949895,
    &quot;alpha&quot;: 0.036881264793715444,
    &quot;mse&quot;: 0.0025252116437143994,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;google/mt5-large&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 4.548214147267365e-23,
    &quot;A&quot;: 3.926297383655625,
    &quot;alpha&quot;: 0.07816268968188453,
    &quot;mse&quot;: 0.00017179343960424252,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 5.164356218599464e-20,
    &quot;A&quot;: 7.198398207778583,
    &quot;alpha&quot;: 0.08172045065773158,
    &quot;mse&quot;: 0.037661811955924634,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.782838501769481e-15,
    &quot;A&quot;: 6.33904927480447,
    &quot;alpha&quot;: 0.11725594450359499,
    &quot;mse&quot;: 0.04049234172260986,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;gpt2&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.19411219632461e-17,
    &quot;A&quot;: 3.9462672122831934,
    &quot;alpha&quot;: 0.06811657142788795,
    &quot;mse&quot;: 0.001116325426678392,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 3.6355061460707474e-19,
    &quot;A&quot;: 3.543052166455486,
    &quot;alpha&quot;: 0.0522551179370743,
    &quot;mse&quot;: 0.0015015110569161615,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 0.4167409848191003,
    &quot;A&quot;: 1.8233793907359293,
    &quot;alpha&quot;: 0.16745997264108628,
    &quot;mse&quot;: 0.00017658025868276737,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-base&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 2.7928490722104062e-24,
    &quot;A&quot;: 2.2598720896244022,
    &quot;alpha&quot;: 0.044573869717399746,
    &quot;mse&quot;: 0.00018275726524061436,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;flan&#x27;)&quot;: {
    &quot;L_inf&quot;: 1.7341701634487937e-22,
    &quot;A&quot;: 4.052493004920058,
    &quot;alpha&quot;: 0.052691030655664196,
    &quot;mse&quot;: 0.001428159543216654,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;gigaword&#x27;)&quot;: {
    &quot;L_inf&quot;: 0.40091754011564584,
    &quot;A&quot;: 1.7757417179384685,
    &quot;alpha&quot;: 0.13439790681006297,
    &quot;mse&quot;: 0.00016924967811668228,
    &quot;n&quot;: 12
  },
  &quot;(&#x27;t5-small&#x27;, &#x27;wikiword&#x27;)&quot;: {
    &quot;L_inf&quot;: 6.740126125023492e-21,
    &quot;A&quot;: 2.790573720093778,
    &quot;alpha&quot;: 0.05079953102151449,
    &quot;mse&quot;: 0.000637766583775489,
    &quot;n&quot;: 12
  }
}

_DEFAULT_GROUP = next(iter(_PARAMS.keys())) if _PARAMS else &#x27;default&#x27;

def _get_params(group: str):
    g = group if group in _PARAMS else _DEFAULT_GROUP
    p = _PARAMS[g]
    return float(p[&#x27;L_inf&#x27;]), float(p[&#x27;A&#x27;]), float(p[&#x27;alpha&#x27;])


def law(input_data: list[dict[str, float]], group: str) -&gt; list[dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    Linf, A, alpha = _get_params(group)
    out = []
    for row in input_data:
        N = float(row.get(&#x27;sft_data_size&#x27;, 0.0))
        if N &lt;= 0:
            pred = float(Linf + A)
        else:
            pred = float(Linf + A * (N ** (-alpha)))
        out.append({&#x27;sft_loss&#x27;: pred})
    return out</code></pre>
            </div>
          </div>
        </div>
      </div>

      <footer class="footer">
        <p>
          SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> |
          <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a>
        </p>
      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
      function toggleRun(header) {
        const content = header.nextElementSibling;
        const isExpanded = content.style.display === "block";
        content.style.display = isExpanded ? "none" : "block";
        header.classList.toggle("expanded", !isExpanded);
      }

      function copyCode(event, codeId) {
        event.stopPropagation();
        const code = document.getElementById(codeId).textContent;
        navigator.clipboard.writeText(code).then(() => {
          const btn = event.target;
          btn.textContent = "Copied!";
          setTimeout(() => (btn.textContent = "Copy"), 2000);
        });
      }

      Prism.highlightAll();
    </script>
  </body>
</html>
