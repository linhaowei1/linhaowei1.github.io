<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SLD - Vocabulary Scaling Law - opencode + GPT-5</title>
    <link rel="icon" type="image/png" href="assets/sld_logo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Sora:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
    <style>
        :root {
            --bg-primary: #ffffff;
            --bg-secondary: #f8f9fa;
            --accent-primary: #2563eb;
            --accent-secondary: #3b82f6;
            --accent-gradient: linear-gradient(135deg, #2563eb 0%, #3b82f6 50%, #60a5fa 100%);
            --text-primary: #1f2937;
            --text-secondary: #4b5563;
            --border-subtle: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --success: #10b981;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Sora', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-primary);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .bg-pattern {
            display: none;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
            position: relative;
            z-index: 1;
        }
        
        .back-link {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent-primary);
            text-decoration: none;
            font-size: 0.9rem;
            margin-bottom: 1.5rem;
            transition: color 0.2s;
        }
        
        .back-link:hover {
            color: var(--accent-secondary);
        }
        
        .header {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            backdrop-filter: blur(10px);
        }
        
        .header h1 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: var(--accent-gradient);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 1.5rem;
            margin-top: 1rem;
        }
        
        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .meta-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .meta-value {
            font-weight: 600;
            color: var(--text-primary);
        }
        
        .r2-badge {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-weight: 600;
            font-size: 0.85rem;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .section-title {
            font-size: 1.25rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: var(--text-primary);
        }
        
        .runs-container {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .run-card {
            background: var(--glass-bg);
            border: 1px solid var(--border-subtle);
            border-radius: 12px;
            overflow: hidden;
            transition: border-color 0.2s;
        }
        
        .run-card:hover {
            border-color: rgba(99, 102, 241, 0.3);
        }
        
        .run-card.best-run {
            border-color: var(--success);
            box-shadow: 0 0 20px rgba(16, 185, 129, 0.1);
        }
        
        .run-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 1.25rem;
            background: rgba(255, 255, 255, 0.02);
            cursor: pointer;
            transition: background 0.2s;
        }
        
        .run-header:hover {
            background: rgba(255, 255, 255, 0.04);
        }
        
        .run-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }
        
        .run-badge {
            padding: 0.25rem 0.6rem;
            border-radius: 6px;
            font-size: 0.75rem;
            font-weight: 600;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-secondary);
        }
        
        .run-badge.best-badge {
            background: var(--success);
            color: white;
        }
        
        .run-label {
            font-weight: 500;
            color: var(--text-primary);
        }
        
        .expand-icon {
            color: var(--text-muted);
            font-size: 0.8rem;
            transition: transform 0.2s;
        }
        
        .run-header.expanded .expand-icon {
            transform: rotate(180deg);
        }
        
        .run-content {
            border-top: 1px solid var(--border-subtle);
        }
        
        .code-container {
            overflow: hidden;
        }
        
        .code-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 0.75rem 1.25rem;
            background: rgba(0, 0, 0, 0.2);
            border-bottom: 1px solid var(--border-subtle);
            font-size: 0.8rem;
            color: var(--text-muted);
        }
        
        .copy-btn {
            padding: 0.35rem 0.75rem;
            background: rgba(99, 102, 241, 0.2);
            border: 1px solid rgba(99, 102, 241, 0.3);
            border-radius: 6px;
            color: var(--accent-primary);
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-family: inherit;
        }
        
        .copy-btn:hover {
            background: rgba(99, 102, 241, 0.3);
        }
        
        .code-container pre {
            margin: 0;
            padding: 1.25rem;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.8rem;
            line-height: 1.6;
            overflow-x: auto;
            background: transparent !important;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border-subtle);
            color: var(--text-secondary);
            font-size: 0.85rem;
        }
        
        .footer a {
            color: var(--accent-primary);
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .header h1 {
                font-size: 1.25rem;
            }
            
            .meta-row {
                flex-direction: column;
                gap: 0.75rem;
            }
            
            .run-info {
                flex-wrap: wrap;
                gap: 0.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="bg-pattern"></div>
    
    <div class="container">
        <a href="sld_index.html" class="back-link">
            ← Back to Leaderboard
        </a>
        
        <div class="header">
            <h1>Vocabulary Scaling Law</h1>
            <div class="meta-row">
                <div class="meta-item">
                    <span class="meta-label">Agent:</span>
                    <span class="meta-value">opencode</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Model:</span>
                    <span class="meta-value">GPT-5</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Best R²:</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        0.963340
                    </span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Mean R²:</span>
                    <span class="meta-value">0.889365</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Min R²:</span>
                    <span class="meta-value">0.860336</span>
                </div>
                <div class="meta-item">
                    <span class="meta-label">Runs:</span>
                    <span class="meta-value">5</span>
                </div>
            </div>
        </div>
        
        <h2 class="section-title">All Runs (sorted by R²)</h2>
        
        <div class="runs-container">
            
        <div class="run-card best-run">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge best-badge">Best</span>
                    <span class="run-label">Run 1</span>
                    <span class="r2-badge" style="background-color: #006400; color: white;">
                        R² = 0.963340
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: block;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-0')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-0">from __future__ import annotations
from typing import List, Dict

# Discovered functional form (shared across groups):
#   L = L0_g + A_g * V^(-alpha) + B_g * Pnv^(-beta) + C_g * C^(-gamma)
# where
#   V   = vocab_size
#   Pnv = non_vocab_parameters
#   C   = num_characters
# Exponents are shared across groups; coefficients are per-group.

# Exponents (selected via grid search minimizing RMSE)
_ALPHA = 0.2
_BETA = 0.2
_GAMMA = 0.4

# Per-group coefficients fitted on the provided dataset
# Format: group -&gt; (L0, A, B, C)
_COEFS: Dict[str, tuple[float, float, float, float]] = {
    # Only one group was present in the dataset; use it as default.
    &quot;all_data&quot;: (
        -5.547737600980133,   # L0
        -1.8596813255288938,  # A (vocab term)
        17.1014092331671,     # B (non-vocab parameters term)
        9830.897391235507,    # C (num_characters term)
    ),
}

_DEFAULT_GROUP = &quot;all_data&quot;


def _predict_one(vocab_size: float, non_vocab_parameters: float, num_characters: float, coefs: tuple[float, float, float, float]) -&gt; float:
    # Guard against non-positive inputs for power operations
    eps = 1e-12
    V = max(float(vocab_size), eps)
    Pnv = max(float(non_vocab_parameters), eps)
    C = max(float(num_characters), eps)

    L0, A, B, Cc = coefs
    return (
        L0
        + A * (V ** (-_ALPHA))
        + B * (Pnv ** (-_BETA))
        + Cc * (C ** (-_GAMMA))
    )


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coefs = _COEFS.get(group)
    if coefs is None:
        # Fallback to default if unseen group; preserves functional form
        coefs = _COEFS[_DEFAULT_GROUP]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        V = float(row.get(&quot;vocab_size&quot;, 0.0))
        Pnv = float(row.get(&quot;non_vocab_parameters&quot;, 0.0))
        C = float(row.get(&quot;num_characters&quot;, 0.0))
        pred = _predict_one(V, Pnv, C, coefs)
        outputs.append({&quot;unigram_normalized_loss&quot;: float(pred)})
    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#2</span>
                    <span class="run-label">Run 2</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.900907
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-1')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-1">from __future__ import annotations
from typing import Dict, List

# Per-group coefficients for the scaling law. The functional form is identical
# across groups; only these constants vary by group.
#
# Formula:
#   y_hat = L_inf + A * V^{-alpha_vocab} * P^{-beta_params} * C^{-gamma_chars}
# where
#   y_hat  = predicted unigram-normalized loss
#   V      = vocab_size
#   P      = non_vocab_parameters
#   C      = num_characters
#
# If an unknown group is requested, we fall back to &quot;all_data&quot; if present,
# otherwise to the first available set of coefficients.
COEFFS: Dict[str, Dict[str, float]] = {
    &quot;all_data&quot;: {
        &quot;L_inf&quot;: -5.342768253504336,
        &quot;A&quot;: 1488483.062515263,
        &quot;alpha_vocab&quot;: 0.011056223114896735,
        &quot;beta_params&quot;: 0.12289913666523904,
        &quot;gamma_chars&quot;: 0.5218377213267072,
    }
}


def _select_group_coeffs(group: str) -&gt; Dict[str, float]:
    if group in COEFFS:
        return COEFFS[group]
    if &quot;all_data&quot; in COEFFS:
        return COEFFS[&quot;all_data&quot;]
    # Fallback to any available coefficients
    return next(iter(COEFFS.values()))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys: &#x27;vocab_size&#x27;,
                    &#x27;non_vocab_parameters&#x27;, &#x27;num_characters&#x27;.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups, but
                the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s):
        {&#x27;unigram_normalized_loss&#x27;: float}.
    &quot;&quot;&quot;
    coeffs = _select_group_coeffs(group)
    L_inf = float(coeffs[&quot;L_inf&quot;])
    A = float(coeffs[&quot;A&quot;])
    a_v = float(coeffs[&quot;alpha_vocab&quot;])
    b_p = float(coeffs[&quot;beta_params&quot;])
    g_c = float(coeffs[&quot;gamma_chars&quot;])

    # Numerical safety threshold to avoid zero/negative bases in power operations
    eps = 1e-12

    out: List[Dict[str, float]] = []
    for row in input_data:
        V = float(row.get(&quot;vocab_size&quot;, 0.0))
        P = float(row.get(&quot;non_vocab_parameters&quot;, 0.0))
        C = float(row.get(&quot;num_characters&quot;, 0.0))

        V = V if V &gt; eps else eps
        P = P if P &gt; eps else eps
        C = C if C &gt; eps else eps

        y_hat = L_inf + A * (V ** (-a_v)) * (P ** (-b_p)) * (C ** (-g_c))
        out.append({&quot;unigram_normalized_loss&quot;: float(y_hat)})

    return out</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#3</span>
                    <span class="run-label">Run 3</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.861121
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-2')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-2">import math
from typing import List, Dict

# Coefficients fitted on the provided dataset (group: &#x27;all_data&#x27;).
# Functional form (shared across groups):
#   unigram_normalized_loss = A + a * ln(vocab_size) + b * ln(non_vocab_parameters) + c * ln(num_characters)
# If an unknown group is requested, we fall back to &#x27;all_data&#x27;.

COEFFICIENTS: Dict[str, Dict[str, float]] = {
    &quot;all_data&quot;: {
        &quot;A&quot;: 6.380591236628991,
        &quot;a&quot;: 0.06340183374111474,
        &quot;b&quot;: 0.016411064426657424,
        &quot;c&quot;: -0.5017006627222854,
    }
}


def _get_group_coeffs(group: str) -&gt; Dict[str, float]:
    if group in COEFFICIENTS:
        return COEFFICIENTS[group]
    # Fallback to &#x27;all_data&#x27; if group not present
    if &quot;all_data&quot; in COEFFICIENTS:
        return COEFFICIENTS[&quot;all_data&quot;]
    # As a last resort (should not happen), pick an arbitrary group&#x27;s coeffs
    return next(iter(COEFFICIENTS.values()))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values. Expected keys:
                    - &#x27;vocab_size&#x27;
                    - &#x27;non_vocab_parameters&#x27;
                    - &#x27;num_characters&#x27;
        group: The name of the experimental group for which to make predictions.
                The functional form of the law is the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s):
            - &#x27;unigram_normalized_loss&#x27;
    &quot;&quot;&quot;
    coeffs = _get_group_coeffs(group)
    A = float(coeffs[&quot;A&quot;])
    a = float(coeffs[&quot;a&quot;])
    b = float(coeffs[&quot;b&quot;])
    c = float(coeffs[&quot;c&quot;])

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        V = float(row[&quot;vocab_size&quot;])  # assumes &gt; 0
        P = float(row[&quot;non_vocab_parameters&quot;])  # assumes &gt; 0
        N = float(row[&quot;num_characters&quot;])  # assumes &gt; 0
        if V &lt;= 0 or P &lt;= 0 or N &lt;= 0:
            raise ValueError(&quot;All inputs must be positive for logarithms.&quot;)
        y = A + a * math.log(V) + b * math.log(P) + c * math.log(N)
        outputs.append({&quot;unigram_normalized_loss&quot;: float(y)})

    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#4</span>
                    <span class="run-label">Run 4</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.861121
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-3')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-3">from __future__ import annotations

import math
from typing import Dict, List

# Fitted coefficients by experimental group for the scaling law:
# unigram_normalized_loss = c0 + cV * ln(vocab_size) + cP * ln(non_vocab_parameters) + cN * ln(num_characters)
# If an unknown group is provided, fall back to the &#x27;default&#x27; coefficients.
_COEFFICIENTS: Dict[str, Dict[str, float]] = {
    # Derived from the provided dataset (group == &#x27;all_data&#x27;)
    &quot;all_data&quot;: {
        &quot;c0&quot;: 6.380591236628991,
        &quot;cV&quot;: 0.06340183374111474,
        &quot;cP&quot;: 0.016411064426657424,
        &quot;cN&quot;: -0.5017006627222854,
    },
}

# Default to the only observed group&#x27;s coefficients
_DEFAULT_GROUP = &quot;all_data&quot;


def _get_coeffs(group: str) -&gt; Dict[str, float]:
    return _COEFFICIENTS.get(group, _COEFFICIENTS[_DEFAULT_GROUP])


def _safe_log(x: float) -&gt; float:
    # Guard against non-positive inputs; clip to a tiny positive value
    return math.log(max(float(x), 1e-12))


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    The functional form is shared across groups, while coefficients differ per group.

    Model:
        unigram_normalized_loss = c0
                                  + cV * ln(vocab_size)
                                  + cP * ln(non_vocab_parameters)
                                  + cN * ln(num_characters)

    Args:
        input_data: A list of dicts with keys:
            - &#x27;vocab_size&#x27;
            - &#x27;non_vocab_parameters&#x27;
            - &#x27;num_characters&#x27;
        group: Experimental group name controlling which coefficient set to use.

    Returns:
        A list of dicts with key &#x27;unigram_normalized_loss&#x27; for each input row.
    &quot;&quot;&quot;
    co = _get_coeffs(group)
    c0 = co[&quot;c0&quot;]
    cV = co[&quot;cV&quot;]
    cP = co[&quot;cP&quot;]
    cN = co[&quot;cN&quot;]

    outputs: List[Dict[str, float]] = []
    for row in input_data:
        V = row.get(&quot;vocab_size&quot;, float(&quot;nan&quot;))
        Pnv = row.get(&quot;non_vocab_parameters&quot;, float(&quot;nan&quot;))
        N = row.get(&quot;num_characters&quot;, float(&quot;nan&quot;))

        y = c0 + cV * _safe_log(V) + cP * _safe_log(Pnv) + cN * _safe_log(N)
        outputs.append({&quot;unigram_normalized_loss&quot;: float(y)})

    return outputs</code></pre>
                </div>
            </div>
        </div>
        
        <div class="run-card ">
            <div class="run-header" onclick="toggleRun(this)">
                <div class="run-info">
                    <span class="run-badge ">#5</span>
                    <span class="run-label">Run 5</span>
                    <span class="r2-badge" style="background-color: #228B22; color: white;">
                        R² = 0.860336
                    </span>
                </div>
                <span class="expand-icon">▼</span>
            </div>
            <div class="run-content" style="display: none;">
                <div class="code-container">
                    <div class="code-header">
                        <span>Python</span>
                        <button class="copy-btn" onclick="copyCode(event, 'code-4')">Copy</button>
                    </div>
                    <pre><code class="language-python" id="code-4">from __future__ import annotations
from math import log
from typing import Dict, List

# Fitted on the provided dataset (group = &quot;all_data&quot;).
# Functional form (same for all groups):
#   y = a
#       + b * ln(V)
#       + c * ln(P_nv)
#       + d * ln(C)
#       + e * ln(V) * ln(P_nv)
#       + f * ln(V) * ln(C)
# where
#   y  = unigram_normalized_loss (to be predicted)
#   V  = vocab_size
#   P_nv = non_vocab_parameters
#   C  = num_characters
# Coefficients may differ per experimental group; unseen groups fall back to &quot;all_data&quot;.

_COEFS_BY_GROUP: Dict[str, Dict[str, float]] = {
    # Values derived via least-squares on /app/data
    # keys: a, b, c, d, e, f as described above
    &quot;all_data&quot;: {
        &quot;a&quot;: -0.3185102834051369,
        &quot;b&quot;: 0.7540070032843006,
        &quot;c&quot;: -0.07846372542853836,
        &quot;d&quot;: -0.1351093746275669,
        &quot;e&quot;: 0.009780758365806914,
        &quot;f&quot;: -0.03777531897782867,
    },
}

_DEFAULT_GROUP = &quot;all_data&quot;


def _predict_one(x: Dict[str, float], coefs: Dict[str, float]) -&gt; float:
    V = float(x[&quot;vocab_size&quot;])   # Vocabulary size
    P = float(x[&quot;non_vocab_parameters&quot;])  # Non-vocab params
    C = float(x[&quot;num_characters&quot;])  # Training characters

    # Guard against non-positive inputs before log
    if V &lt;= 0 or P &lt;= 0 or C &lt;= 0:
        raise ValueError(&quot;All inputs must be positive to compute logarithms.&quot;)

    lv = log(V)
    lp = log(P)
    lc = log(C)

    a = coefs[&quot;a&quot;]
    b = coefs[&quot;b&quot;]
    c = coefs[&quot;c&quot;]
    d = coefs[&quot;d&quot;]
    e = coefs[&quot;e&quot;]
    f = coefs[&quot;f&quot;]

    y = (
        a
        + b * lv
        + c * lp
        + d * lc
        + e * lv * lp
        + f * lv * lc
    )
    return float(y)


def law(input_data: List[Dict[str, float]], group: str) -&gt; List[Dict[str, float]]:
    &quot;&quot;&quot;
    Predicts output variables based on input variables according to a discovered scaling law.

    Args:
        input_data: A list of dictionaries, where each dictionary is a single data
                    point containing input variable names as keys and their
                    corresponding values.
        group: The name of the experimental group for which to make predictions.
                The functional form of the law must be the same for all groups,
                but the constant parameters/coefficients can differ per group.

    Returns:
        A list of dictionaries, corresponding to the input_data list, with each
        dictionary containing the predicted output variable(s).
    &quot;&quot;&quot;
    coefs = _COEFS_BY_GROUP.get(group, _COEFS_BY_GROUP[_DEFAULT_GROUP])
    preds: List[Dict[str, float]] = []
    for row in input_data:
        y = _predict_one(row, coefs)
        preds.append({&quot;unigram_normalized_loss&quot;: y})
    return preds</code></pre>
                </div>
            </div>
        </div>
        
        </div>
        
        <footer class="footer">
            <p>SLDBench | <a href="https://arxiv.org/abs/2507.21184" target="_blank">arXiv:2507.21184</a> | <a href="https://github.com/linhaowei1/SLD" target="_blank">GitHub</a></p>
        </footer>
    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        function toggleRun(header) {
            const content = header.nextElementSibling;
            const isExpanded = content.style.display === 'block';
            content.style.display = isExpanded ? 'none' : 'block';
            header.classList.toggle('expanded', !isExpanded);
        }
        
        function copyCode(event, codeId) {
            event.stopPropagation();
            const code = document.getElementById(codeId).textContent;
            navigator.clipboard.writeText(code).then(() => {
                const btn = event.target;
                btn.textContent = 'Copied!';
                setTimeout(() => btn.textContent = 'Copy', 2000);
            });
        }
        
        Prism.highlightAll();
    </script>
</body>
</html>